[
  {
    "objectID": "posts/2023-04-19-text2sql-resdsql.html",
    "href": "posts/2023-04-19-text2sql-resdsql.html",
    "title": "Purpose",
    "section": "",
    "text": "We will attempt to understand the ResdSQL paper and its implementation in github\nSo the two main features of this paper are - Ranking-enhanced Encoding : Instead of using the whole schema, the encoder is injected with the most relevant schema items. we train an additional cross-encoder to classify the tables and columns simultaneously based on the input question, and then rank and filter them according to the classification probabilities to form a ranked schema sequence - Skeleton-first Decoding : The decoder first generates the skeleton (SQL keywords) and then the actual SQL query. Since skeleton parsing is much easier than SQL parsing, the first generated skeleton could implicitly guide the subsequent SQL parsing via the masked self-attention mechanism in the decoder."
  },
  {
    "objectID": "posts/2023-04-19-text2sql-resdsql.html#implementation",
    "href": "posts/2023-04-19-text2sql-resdsql.html#implementation",
    "title": "Purpose",
    "section": "Implementation",
    "text": "Implementation\nWe will identify the steps performed by the scripts in github repository.\n1. Run the contents of preprocess.sh\nMinor changes (remove the –db_path parameter to use the default)\npython preprocessing.py \\\n    --mode \"train\" \\\n    --table_path \"./data/spider/tables.json\" \\\n    --input_dataset_path \"./data/spider/train_spider.json\" \\\n    --output_dataset_path \"./data/preprocessed_data/preprocessed_train_spider.json\" \\\n    --target_type \"sql\"\n\npython preprocessing.py \\\n    --mode \"eval\" \\\n    --table_path \"./data/spider/tables.json\" \\\n    --input_dataset_path \"./data/spider/dev.json\" \\\n    --output_dataset_path \"./data/preprocessed_data/preprocessed_dev.json\" \\\n    --target_type \"sql\"\nThe preprocessing adds the following to the dataset and saves it in a new json file. - norm_sql : normalized SQL query - sql_skeleton : SQL skeleton - nat_sql : nat_sql if it exists (for train and dev, not test) - norm_nat_sql : normalized nat_sql if it exists - natsql_skeleton : nat_sql skeleton - pk : primary keys - fk : foreign keys - db_schema: database schema with original and semantic table and column names - db_contents: column value matches. See the query ‘What are the names of the heads who are born outside the California state’ in the generated file preprocessed_train_spider.json"
  },
  {
    "objectID": "posts/2021-11-28-sklearn-intro.html",
    "href": "posts/2021-11-28-sklearn-intro.html",
    "title": "sklearn intro",
    "section": "",
    "text": "Repeating the contents of http://appliedprogramming.net/machine-learning/introduction.html\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\nfrom sklearn import datasets\n\nimport warnings\nwarnings.filterwarnings('ignore')"
  },
  {
    "objectID": "posts/2021-11-28-sklearn-intro.html#clustering",
    "href": "posts/2021-11-28-sklearn-intro.html#clustering",
    "title": "sklearn intro",
    "section": "Clustering",
    "text": "Clustering\n\nx_train, x_test, y_train, y_test = train_test_split(x_iris, y_iris, test_size=0.25)\n\nscaler = StandardScaler().fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)\n\n\nfrom sklearn import cluster\nclf_sepal = cluster.KMeans(init='k-means++', n_clusters=3, random_state=33)\nclf_sepal.fit(x_train[:, 0:2])\n\nKMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=300,\n    n_clusters=3, n_init=10, n_jobs=1, precompute_distances='auto',\n    random_state=33, tol=0.0001, verbose=0)\n\n\nPrint the labels assigned\n\nprint(clf_sepal.labels_)\n\n[1 0 0 1 1 2 0 0 0 2 0 1 2 1 0 0 2 1 2 2 0 0 0 2 2 1 0 1 2 0 1 2 2 2 1 0 1\n 0 2 1 2 2 0 0 0 0 2 1 2 1 2 2 2 0 1 0 0 0 2 0 0 1 2 1 2 0 0 0 2 0 2 2 2 0\n 0 2 0 1 1 2 0 2 1 1 2 2 1 0 1 0 0 0 2 1 0 2 0 1 2 1 1 2 0 0 0 0 0 1 2 2 0\n 1]\n\n\n\ncolormarkers = [['red', 's'], ['greenyellow', 'o'], ['blue', 'x']]\nstep = 0.01\nmargin = 0.1\nsl_min, sl_max = x_train[:, 0].min() - margin, x_train[:, 0].max() + margin\nsw_min, sw_max = x_train[:, 1].min() - margin, x_train[:, 1].max() + margin\n\n# meshgrid returns two vectors one for x and y of length xy, which reprsent coordinates for the xy points. \nsl, sw = np.meshgrid(np.arange(sl_min, sl_max, step),\n                     np.arange(sw_min, sw_max, step))\nzs = clf_sepal.predict(np.c_[sl.ravel(), sw.ravel()]).reshape(sl.shape)\ncentroids_s = clf_sepal.cluster_centers_\n\nDisplay the data points and the calculated regions\n\nfig, ax = plt.subplots(figsize=(6,6))\nax.imshow(zs, interpolation='nearest',  extent=(sl.min(), sl.max(), sw.min(), sw.max()))\nax.set_xlim(sl_min, sl_max)\nax.set_ylim(sw_min, sw_max)\nax.set(xlabel='Sepal Length', ylabel='Sepal Width', title='KMeans clustering')\nhues = [colormarkers[o][0] for o in y_train]\nmarkers = [colormarkers[o][1] for o in y_train]\nsns.scatterplot(x_train[:,0], x_train[:,1], hue=hues, markers=markers, legend=False)\n\n\n\n\n\n\n\n\n\nSupervised Learning: Regression\n\nfrom sklearn.datasets import load_boston\nfrom sklearn.linear_model import SGDRegressor\nboston = load_boston()\nprint(f'shape - {boston.data.shape}')\nprint(f'boston feature names - {boston.feature_names}')\n\nshape - (506, 13)\nboston feature names - ['CRIM' 'ZN' 'INDUS' 'CHAS' 'NOX' 'RM' 'AGE' 'DIS' 'RAD' 'TAX' 'PTRATIO'\n 'B' 'LSTAT']\n\n\n\nx_train = boston.data\ny_train = boston.target\nx_train = StandardScaler().fit_transform(x_train)\ny_train = StandardScaler().fit_transform(np.expand_dims(y_train, axis=1))\ny_train.shape\n\n(506, 1)\n\n\n\nimport sklearn\ndef train_and_evaluate(model, x_train, y_train, folds):\n    model.fit(x_train, y_train)\n    print(f'score on training set {model.score(x_train, y_train):.2f}')\n    cv = sklearn.cross_validation.KFold(x_train.shape[0], folds, shuffle=True, random_state=33)\n    scores = sklearn.cross_validation.cross_val_score(model, x_train, y_train, cv=cv)\n    print(f'Avg score using {folds} cross validation {np.mean(scores):.2f}')\n\n\nmodel = SGDRegressor(loss='squared_loss', penalty='l2', random_state=33)\ntrain_and_evaluate(model, x_train, y_train, 5)\n\nscore on training set 0.73\nAvg score using 5 cross validation 0.70"
  },
  {
    "objectID": "posts/2024-08-12-paper-llm-reasoning.html",
    "href": "posts/2024-08-12-paper-llm-reasoning.html",
    "title": "Paper Summary: COT Prompting Elicits Reasoning in Large Language Models",
    "section": "",
    "text": "Paper - https://arxiv.org/abs/2201.11903\n\nWe explore how generating a chain of thought – a series of intermediate reasoning steps – significantly improves the ability of large language models to perform complex reasoning. In particular, we show how such reasoning abilities emerge naturally in sufficiently large language models via a simple method called chain of thought prompting, where a few chain of thought demonstrations are provided as exemplars in prompting. Experiments on three large language models show that chain of thought prompting improves performance on a range of arithmetic, commonsense, and symbolic reasoning tasks. The empirical gains can be striking. For instance, prompting a 540B-parameter language model with just eight chain of thought exemplars achieves state of the art accuracy on the GSM8K benchmark of math word problems, surpassing even finetuned GPT-3 with a verifier.\n\nIn other words, when we use fewshot prompting, if we provide the sample answers in the chain of thought format instead of just providing the answer, LLMs are able to perform complex reasoning.\nLet us see a few examples of Q & A, where the answers follow the chain-of-thought (COT) pattern.\n\nExamples\nQ: Roger has 5 tennis balls. He buys 2 more cans of tennis balls. Each can has 3 tennis balls. How many tennis balls does he have now?\nA: Roger started with 5 balls. 2 cans of 3 tennis balls each is 6 tennis balls. 5 + 6 = 11. The answer is 11.\n\nQ: The fox walked from the city into the forest, what was it looking for? Answer Choices: (a) pretty flowers (b) hen house (c) natural habitat (d) storybook\nA: The answer must be something in the forest. Of the above choices, only natural habitat is in the forest. So the answer is (b)\n\n\nResults\nWhat are main take-aways?\n\nCOT prompting does not positively impact performance for small models, and only yields performance gains when used with models of  100B parameters.\nIt has larger performance gains for more-complicated problems.\nCOT prompting via GPT-3 175B and PaLM 540B compares favorably to prior state of the art, which typically finetunes a task-specific model on a labeled training dataset."
  },
  {
    "objectID": "posts/2023-02-15-codex.html",
    "href": "posts/2023-02-15-codex.html",
    "title": "notes",
    "section": "",
    "text": "Here I am exploring the capabiliteis of Text to SQL of OpenAI codex vs fine-tuned t5-3b model (picard).\nhttps://openai.com/blog/openai-codex/\n\nimport os\nimport openai\nfrom typing import Dict, List\nimport json\nimport requests\n\nopenai.api_key = os.getenv(\"OPENAI_API_KEY\")\n\ndef get_schema_string_for_codex(schema_json:Dict):\n  # accepts schema json where key is table name and value is list of columns\n  tables = []\n  for table, columns in schema_json.items():\n    cols = \", \".join(columns)\n    table_string = f\"# Table {table}, columns = [{cols}]\"\n    tables.append(table_string)\n\n  schema_str = \"# SQL\\n\\n\"\n  schema_str += \"\\n\".join(tables)\n  return schema_str\n\n\ndef get_codex_sql(schema, query, print_prompt=True):\n  prompt = \"\\n\\n\".join([schema, query])\n  if print_prompt:\n    print(prompt)\n  response = openai.Completion.create(\n    model=\"code-davinci-002\",\n    prompt=prompt,\n    temperature=0,\n    max_tokens=150,\n    top_p=1.0,\n    frequency_penalty=0.0,\n    presence_penalty=0.0,\n    stop=[\"#\", \";\"]\n  )\n  return response.choices[0].text\n\n\ndef get_schema_string_for_picard(schema_json:Dict, db_name:str):\n  tables = []\n  for table, columns in schema_json.items():\n    cols = \", \".join(columns)\n    table_string = f\"{table} : {cols}\"\n    tables.append(table_string)\n  schema_str = f'| {db_name} | ' + ' | '.join(tables)\n  return schema_str\n\ndef get_picard_sql(schema_str, query, print_prompt=True):\n  payload = json.dumps({\n    \"question\": query,\n    \"db_schema\": schema_str\n  })\n\n  if print_prompt:\n    print(schema_str)\n  headers = {\n    'Content-Type': 'application/json'\n  }\n\n  picard_ip = os.getenv('PICARD_IP')\n  if not picard_ip:\n    raise ValueError('PICARD_IP not set')\n\n  url = f'http://{picard_ip}:8000/ask-with-schema/'\n  response = requests.request(\"POST\", url, headers=headers, data=payload)\n  return response.json()[0]\n\n\n\nschema = {\n    \"albums\": [\"AlbumId\", \"Title\", \"ArtistId\"],\n    \"artists\": [\"ArtistId\", \"Name\"],\n    \"media_types\": [\"MediaTypeId\", \"Name\"],\n    \"playlists\": [\"PlaylistId\", \"Name\"],\n    \"playlist_track\": [\"PlaylistId\", \"TrackId\"],\n    \"tracks\": [\"TrackId\", \"Name\", \"AlbumId\", \"MediaTypeId\", \"GenreId\", \"Composer\", \"Milliseconds\", \"Bytes\", \"UnitPrice\"]\n}\n\nquery = 'generate sql query to list all albums by Adele'\nquery = 'genereate sql to find artists with longest average track length'\nquery = 'generate sql to find the most expensive albums'\nquery = 'generate sql to find duration of tracks from album abc in playlist xyz'\nquery = 'generate sql to find total duration of tracks from album abc in playlist xyz'\n\n\nschema = {\n    \"well\" : [\"id, country, field, latitude, longitude, uwi, well_name\"],\n    \"well_bore\": [\"id, spud_date, ubhi, well_bore_name, well_id\"],\n    \"section\": [\"id, max_dls, max_inclination, min_dls, min_inclination, section_bottom_depth_md, section_caption, section_diameter, section_number, section_top_depth_md, well_bore_id\"],\n    \"operation\": [\"id, operation_code, operation_enddate_time, operation_end_depth, operation_start_datetime, operation_start_depth\"],\n    \"operating_parameters\": ['id', 'avg_rop', 'flow_rate_high', 'flow_rate_low', 'rpm_high', 'rpm_low', 'wob_high', 'wob_low', 'operation_id'],\n    \"run\": [\"id, run_end_depth, run_number, runs_tart_depth, section_id, operation_id\"],\n    \"bit\": [\"id, bit_run_number, bit_type, grading_out, iadc_number, manufacturer, model_number, primary_od, secondary_od, serial_number, run_id\"]\n}\nquery = \"generete sql to find the count of bit types used in each well\"\nquery = \"Give SQL query for Count number of bits for every section of the well bore Matzen 569\"\nquery = \"give sql query to give distance drilled per hour by section number with wellbore name Prottes\"\nquery = \"grading out of bit in each section with wellbore name Matzen\"\nquery = \"get avg_rop by section name with WellboreName Bockfliess\"\nquery = 'find wells with latitude greater than 30'\nquery = 'find wells with well bores with spud date greater than 2010-01-01'\nquery = 'find avg_rop, section diameter in each section with well bore name Prottes'\n\n\nschema_codex = get_schema_string_for_codex(schema)\nprint(get_codex_sql(schema_codex, query))\n\n# SQL\n\n# Table well, columns = [id, country, field, latitude, longitude, uwi, well_name]\n# Table well_bore, columns = [id, spud_date, ubhi, well_bore_name, well_id]\n# Table section, columns = [id, max_dls, max_inclination, mindls, min_inclination, section_bottom_depth_md, section_caption, section_diameter, section_number, section_top_depth_md, well_bore_id]\n# Table operation, columns = [id, operation_code, operation_enddate_time, operation_end_depth, operation_start_datetime, operation_start_depth]\n# Table run, columns = [id, run_end_depth, run_number, runs_tart_depth, section_id, operation_id]\n# Table bit, columns = [id, bit_run_number, bit_type, grading_out, iadc_number, manufacturer, model_number, primary_od, secondary_od, serial_number, run_id]\n\nGive SQL query for Count number of bits for every section of the well bore Matzen 569\n/1-1\n\nSELECT COUNT(*) FROM bit\nINNER JOIN run ON bit.run_id = run.id\nINNER JOIN section ON run.section_id = section.id\nINNER JOIN well_bore ON section.well_bore_id = well_bore.id\nINNER JOIN well ON well_bore.well_id = well.id\nWHERE well.well_name = 'Matzen 569/1-1'\n\nGive SQL query for Count number of bits for every section of the well bore Matzen 569/1-1\n\nSELECT COUNT(*) FROM bit\nINNER JOIN run ON bit\n\n\n\nschema_picard = get_schema_string_for_picard(schema, 'wells')\nprint('\\n' + query + '\\n\\n' + get_picard_sql(schema_picard, query))\n\n| wells | well : id, country, field, latitude, longitude, uwi, well_name | well_bore : id, spud_date, ubhi, well_bore_name, well_id | section : id, max_dls, max_inclination, min_dls, min_inclination, section_bottom_depth_md, section_caption, section_diameter, section_number, section_top_depth_md, well_bore_id | operation : id, operation_code, operation_enddate_time, operation_end_depth, operation_start_datetime, operation_start_depth | operating_parameters : id, avg_rop, flow_rate_high, flow_rate_low, rpm_high, rpm_low, wob_high, wob_low, operation_id | run : id, run_end_depth, run_number, runs_tart_depth, section_id, operation_id | bit : id, bit_run_number, bit_type, grading_out, iadc_number, manufacturer, model_number, primary_od, secondary_od, serial_number, run_id\n\nfind avg_rop, section diameter in each section with well bore name Prottes\n\nselect t1.avg_rop, t1.section_diameter from operating_parameters as t1 join section as t2 on t1.section_id = t2.section_id join well_bore as t3 on t3.id = t2.well_bore_id where t3.well_bore_name = \"Prottes\"\n\n\n\nResults\n\n\n\n\n\n\n\n\n\n\nquery\ncodex_sql\nco_res\npicard_sql\npi_res\n\n\n\n\ngenerate sql query to list all albums by Adele\nSELECT * FROM albums JOIN artists ON artists.ArtistId = albums.ArtistId WHERE artists.Name = ‘Adele’\n\nselect t1.title from albums as t1 join artists as t2 on t1.ArtistId = t2.ArtistId where t2.Name = “Adele”\n\n\n\ngenereate sql to find artists with longest average track length\nSELECT a.Name, AVG(t.Milliseconds) AS AverageTrackLength FROM artists a JOIN albums al ON a.ArtistId = al.ArtistId JOIN tracks t ON al.AlbumId = t.AlbumId GROUP BY a.Name ORDER BY AverageTrackLength DESC LIMIT 1 FROM artists a JOIN albums al ON a.ArtistId = al.ArtistId JOIN tracks t ON al.AlbumId = t.AlbumId GROUP BY a.Name ORDER BY AverageTrackLength DESC LIMIT 1\n\nselect t1.Name from artists as t1 join tracks as t2 on t1.ArtistId = t2.ArtistId group by t2.ArtistId order by avg(milliseconds) desc limit 1\n\n\n\ngenerate sql to find the most expensive albums\nselect albums.title, tracks.unitprice from albums join tracks on albums.albumid = tracks.albumid order by tracks.unitprice desc limit 1\n\nselect title from albums order by unitprice desc limit 1\n\n\n\ngenerate sql to find duration of tracks from album abc in playlist xyz\nSELECT SUM(Milliseconds) FROM tracks WHERE AlbumId = (SELECT AlbumId FROM albums WHERE Title = ‘abc’) AND TrackId IN (SELECT TrackId FROM playlist_track WHERE PlaylistId = (SELECT PlaylistId FROM playlists WHERE Name = ‘xyz’))\n\nselect t1.milliseconds from tracks as t1 join playlist_track as t2 on t1.trackId = t2.TrackId join albums as t3 on t3.albumId = t2.AlbumId join playlists as t4 on t4.playlistId = t1.playlistId where t3.albumId = “ABC” and t4.name = “xyz”\n\n\n\ngenerate sql to find total duration of tracks from album abc in playlist xyz\nselect sum(milliseconds) from tracks where albumid = (select albumid from albums where title = ‘abc’) and trackid in (select trackid from playlist_track where playlistid = (select playlistid from playlists where name = ‘xyz’))\n\nselect sum(t1.milliseconds) from tracks as t1 join playlist_track as t2 on t1.trackId = t2.TrackId join albums as t3 on t3.albumId = t2.AlbumId join playlists as t4 on t4.playlistId = t1.playlistId where t3.albumId = “ABC” and t4.name = “xyz”"
  },
  {
    "objectID": "posts/2024-06-28-openstreetmaps-geocoding.html",
    "href": "posts/2024-06-28-openstreetmaps-geocoding.html",
    "title": "Open Street Maps for Geocoding locally",
    "section": "",
    "text": "We have a need to geocode (get latlong from an address component) a large number of addresses. Doing it using google maps api would be expensive. Hence trying out Open Street Maps (OSM)\nNominatum is an api service for OSM.\nMore details on importing the data - https://nominatim.org/release-docs/4.4/admin/Import/\nWe start the docker container and import the data, as described here\ndocker run -it \\\n  -e PBF_URL=https://download.geofabrik.de/asia/india-latest.osm.pbf \\\n  -e REPLICATION_URL=https://download.geofabrik.de/asia/india-updates/ \\\n  -e IMPORT_STYLE=street \\\n  -p 8080:8080 \\\n  -v nominatim-data:/var/lib/postgresql/14/main \\\n  -v nominatim-flatnode:/nominatim/flatnode \\\n  -e IMPORT_WIKIPEDIA=false \\\n  --name nominatim \\\n  mediagis/nominatim:4.4\nThe import took around 5 hours (as it was India data only) The docker memory usage of 9GB. The nominatim-data volume is around 24 GB and nominatim-flatnode is around 96 GB.\nWe can start the container again using the following command\ndocker start nominatim\nWe can start searching for locations using\nimport requests\nbase_url = 'http://localhost:8080'\naddress = 'Mumabai'\nresponse = requests.post(f'{base_url}/search.php?q={address}')\n\nUseful tips\nWe can use hosted Neonatim for testing the api - https://nominatim.openstreetmap.org/\nDatabase layout - https://nominatim.org/release-docs/latest/develop/Database-Layout/\nHow to access the postgres tables?\n# Go to bash in neonatim container\ndocker exec -it nominatim bash\n\n# change to neonatim user\nsu nominatim\n\n# start psql\npsql"
  },
  {
    "objectID": "posts/2024-05-04-trilium-glcoud.html",
    "href": "posts/2024-05-04-trilium-glcoud.html",
    "title": "Run Trilium server in google cloud run",
    "section": "",
    "text": "Purpose\nTrilium can be used as a personal knowledge base. It can be run locally or synchronized across multiple devices as a server. By using google cloud run as the server, we can have a reliable and scalable solution with the following advantages.\n\nCost-effective: Cloud Run is serverless. So no hassles of maintaining a server or VM. We pay only for the resources used. We can scale the number of nodes to zero when not in use.\nStorage: A recent feature of Cloud Run is the ability to mount a google cloud storage bucket as a volume.\n\n\n\nSteps\n# set the project name and region. Change these values as per your requirement\nexport PROJECT_ID=project_xyz\nexport REGION=asia-southeast1\nexport BUCKET_NAME=bucket_name\n\n# switch to the project\ngcloud config set project $PROJECT_ID\n\n# create a cloud storage bucket\ngsutil mb -l $REGION gs://$BUCKET_NAME\n\n# deploy trilium to cloud run\ngcloud beta run deploy trilium --image zadam/trilium:0.63-latest \\\n--execution-environment gen2 \\\n--add-volume=name=trilium_data,type=cloud-storage,bucket=$BUCKET_NAME \\\n--add-volume-mount=volume=trilium_data,mount-path=/home/node/trilium-data \\\n--allow-unauthenticated --max-instances 1 \\\n--memory 512Mi \\\n--region $REGION --project $PROJECT_ID\nOnce deployment is successful, we get a url in shell, something like https://trilium-xyz1234-as.a.run.app\n\n\nAccess\n\nOpen the url in a browser. Now you can set a strong password and start using trilium."
  },
  {
    "objectID": "posts/2023-01-30-finetune-nlp-pytorch.html",
    "href": "posts/2023-01-30-finetune-nlp-pytorch.html",
    "title": "notes",
    "section": "",
    "text": "Repeating steps from https://huggingface.co/course/chapter3/4?fw=pt\nfrom transformers import AutoTokenizer, AutoModelForSequenceClassification, DataCollatorWithPadding\nfrom datasets import load_dataset\nfrom transformers import Trainer, TrainingArguments\ncheckpoint = 'bert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint)\nraw_datasets = load_dataset('glue', 'mrpc')\n\ndef tokenize_function(examples):\n    return tokenizer(examples['sentence1'], examples['sentence2'], truncation=True)\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\ndata_collator = DataCollatorWithPadding(tokenizer)\n\n# modify dataset to be used with pytorch model\ntokenized_datasets = tokenized_datasets.remove_columns(['sentence1', 'sentence2', 'idx'])\ntokenized_datasets = tokenized_datasets.rename_column('label', 'labels')\ntokenized_datasets.set_format('torch')\nprint(f\"dataset column names - {tokenized_datasets['train'].column_names}\")\n\n\n# create dataloaders\nfrom torch.utils.data import DataLoader\ntrain_dataloader = DataLoader(tokenized_datasets['train'], shuffle=True, batch_size=8,collate_fn=data_collator)\neval_dataloader = DataLoader(tokenized_datasets['validation'], batch_size=8, collate_fn=data_collator)\n\nbatch = next(iter(train_dataloader))\nprint({k:v.shape for k,v in batch.items()})\n\n# load model\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n# outputs = model(**batch)\n# print(f\"loss - {outputs.loss}. logits.shape - {outputs.logits.shape}\")\n\n# optimizer\nfrom transformers import AdamW\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\n# scheduler\nfrom transformers import get_scheduler\nnum_epochs = 3\nnum_training_steps = num_epochs * len(train_dataloader)\nlr_scheduler = get_scheduler('linear', optimizer=optimizer,num_warmup_steps=0,num_training_steps=num_training_steps)\nprint(f'num_training_steps - {num_training_steps}')\n\n# detect device\nimport torch\ndevice = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n\n# training loop\nfrom tqdm.auto import tqdm\nprogress_bar = tqdm(range(num_training_steps))\nmodel.train()\nfor epoch in range(num_epochs):\n    for batch in train_dataloader:\n        batch = {k:v.to(device) for k,v in batch.items()}\n        outputs = model(**batch)\n        loss = outputs.loss\n        loss.backward()\n\n        optimizer.step()\n        lr_scheduler.step()\n        optimizer.zero_grad()\n        progress_bar.update(1)\n\n# evaluation loop\nimport evaluate\nmetric = evaluate.load('glue','mrpc')\nfor batch in eval_dataloader:\n    batch = {k:v.to(device) for k, v in batch.items()}\n    with torch.no_grad():\n        outputs = model(**batch)\n    logits = outputs.logits\n    predictions = torch.argmax(logits, dim=-1)\n    metric.add_batch(predictions=predictions, references=batch['labels'])\nmetric.compute()\n\nSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\nFound cached dataset glue (/Users/achinta/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n\n\n\n\n\nLoading cached processed dataset at /Users/achinta/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-b8ca0e77d9b1a107.arrow\nLoading cached processed dataset at /Users/achinta/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-2656b493beabb728.arrow\nLoading cached processed dataset at /Users/achinta/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-e8576c3577f28c58.arrow\nYou're using a BertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n\n\ndataset column names - ['labels', 'input_ids', 'token_type_ids', 'attention_mask']\n{'labels': torch.Size([8]), 'input_ids': torch.Size([8, 72]), 'token_type_ids': torch.Size([8, 72]), 'attention_mask': torch.Size([8, 72])}\n\n\nSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.bias', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.dense.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\nnum_training_steps - 1377\n\n\n/Users/achinta/miniforge3/envs/ml/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\n\n\n\n\n{'accuracy': 0.8578431372549019, 'f1': 0.8999999999999999}\nThe ‘accelerate’ version of the code can be seen in https://huggingface.co/course/chapter3/4?fw=pt\n{'labels': torch.Size([8]),\n 'input_ids': torch.Size([8, 75]),\n 'token_type_ids': torch.Size([8, 75]),\n 'attention_mask': torch.Size([8, 75])}"
  },
  {
    "objectID": "posts/2023-01-30-finetune-nlp-pytorch.html#the-datasets-library",
    "href": "posts/2023-01-30-finetune-nlp-pytorch.html#the-datasets-library",
    "title": "notes",
    "section": "5 The datasets library",
    "text": "5 The datasets library\n\n3.1 time to slice and dice\n\n\n\nhuggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\nTo disable this warning, you can either:\n    - Avoid using `tokenizers` before the fork if possible\n    - Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n-rw-r--r--  1 achinta  staff    80M Oct  2  2018 drugsComTrain_raw.tsv\n-rw-r--r--  1 achinta  staff    27M Oct  2  2018 drugsComTest_raw.tsv\n\n\nUsing custom data configuration default-4eaca5caac99961c\nFound cached dataset csv (/Users/achinta/.cache/huggingface/datasets/csv/default-4eaca5caac99961c/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n\n\n\n\n\nCPU times: user 67.3 ms, sys: 37.3 ms, total: 105 ms\nWall time: 1.37 s"
  },
  {
    "objectID": "posts/2024-07-01-object-detection-finetune.html",
    "href": "posts/2024-07-01-object-detection-finetune.html",
    "title": "Object Detction Finetuning",
    "section": "",
    "text": "I was trying to finetune a object detection model on a custom dataset. I was looking for example code for the same, but most examples I could find were for classification. What could be the reason for this?\n\nFeatures: After feature extraction, classification is straightforward as it is just a fully connected layer on top of the extracted features. But for object detection (say YOLO), the features we extract are in the shape S X S X B X (5 + C), where S is the grid size, B is the number of bounding boxes per grid cell, 5 is the bounding box coordinates and objectness score, and C is the number of classes. Here S X S is the grid size, to which we want to divide the image.\nLoss Computation: After bounding box generation during training time, the loss computation is also different. We need to compute the loss for the bounding box coordinates, objectness score, and class prediction.\nDataset Formats: There are several formats in which the labels and bounding boxes are represented. Roboflow, makes it easy to convert between these formats.\nAt inference time, from all the bounding boxes generated, we need to select the bounding boxes with the highest objectness score and then apply non-max suppression to remove overlapping bounding boxes."
  },
  {
    "objectID": "posts/2024-08-20-llm-leaderboards.html",
    "href": "posts/2024-08-20-llm-leaderboards.html",
    "title": "LLM Leaderboards and benchmarks",
    "section": "",
    "text": "LLM Leaderboards\n\n\n\nLeaderboard\nDescription\n\n\n\n\nChatbot Arena Leaderboard\na benchmark platform for large language models (LLMs) that features anonymous, randomized battles in a crowdsourced manner.\n\n\nMixEval Leaderboard\n\n\n\nAlpacaEval Leaderboard\n\n\n\nOpen LLM Leaderboard\n\n\n\nBerkeley Function-Calling Leaderboard\n\n\n\n\n\n\nEmbedding Leaderboard\n\n\n\nLeaderboard\n\n\n\n\nMassive Text Embedding Benchmark\n\n\n\n\n\nInference Provider Leaderboard\n\n\n\nLeaderboard\n\n\n\n\nMartian Provider Leaderboard"
  },
  {
    "objectID": "posts/2023-01-23-huggingface-course.html",
    "href": "posts/2023-01-23-huggingface-course.html",
    "title": "1. Transformer Models",
    "section": "",
    "text": "from transformers import pipeline\n\n# to start with we will classify a single sentnence\nclassifier = pipeline(\"sentiment-analysis\")\nprint(classifier(\"I watched a good movie yesterday\"))\n\nNo model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n[{'label': 'POSITIVE', 'score': 0.9990124702453613}]\n# classify multiple sentences\nclassifier(['that was a good movie', 'He is unwell'])\n\n[{'label': 'POSITIVE', 'score': 0.9998570680618286},\n {'label': 'NEGATIVE', 'score': 0.9989678859710693}]\n# zero shot classification\n# we havent trained the model on the labels we are using\nzero_shot_classifier = pipeline(\"zero-shot-classification\")\nzero_shot_classifier(\"this is a very interesting course on algebra\", candidate_labels=[\"mathematics\", \"physics\", \"chemistry\", \"biology\"])\n\nNo model was supplied, defaulted to facebook/bart-large-mnli and revision c626438 (https://huggingface.co/facebook/bart-large-mnli).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n{'sequence': 'this is a very interesting course on algebra',\n 'labels': ['mathematics', 'biology', 'physics', 'chemistry'],\n 'scores': [0.9866520166397095,\n  0.004770115949213505,\n  0.004415604285895824,\n  0.004162236116826534]}\n# text generation\ngenerator = pipeline('text-generation')\ngenerator(\"newtons first law states that\")\n\nNo model was supplied, defaulted to gpt2 and revision 6c0e608 (https://huggingface.co/gpt2).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n/Users/achinta/miniforge3/envs/ml/lib/python3.9/site-packages/transformers/generation_utils.py:1296: UserWarning: Neither `max_length` nor `max_new_tokens` has been set, `max_length` will default to 50 (`self.config.max_length`). Controlling `max_length` via the config is deprecated and `max_length` will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n  warnings.warn(\n\n\n[{'generated_text': 'newtons first law states that students under the age of 18 \"shall be admitted to any of these colleges and universities which may be established\" with their respective states of residence and where they may obtain college degrees or certificates.\" Section 1-106 sets forth'}]\n# text generation by specifying a model\ngenerator = pipeline('text-generation', model='distilgpt2')\ngenerator('in this course, we will teach you how to', max_length=30, num_return_sequences=3)\n\nSetting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n\n\n[{'generated_text': 'in this course, we will teach you how to use your hands to manipulate your feet to push the button in many directions, and try to help you'},\n {'generated_text': 'in this course, we will teach you how to use them in a way for your students. So if you have any questions or concerns, do you'},\n {'generated_text': 'in this course, we will teach you how to be very confident in what you do during training sessions, during training sessions, and in your training sessions'}]\n# Fill Mask\nunmasker = pipeline('fill-mask')\nunmasker(\"sun rises in the &lt;mask&gt;\", top_k=3)\n\nNo model was supplied, defaulted to distilroberta-base and revision ec58a5b (https://huggingface.co/distilroberta-base).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n[{'score': 0.296585351228714,\n  'token': 6360,\n  'token_str': ' sky',\n  'sequence': 'sun rises in the sky'},\n {'score': 0.06161285191774368,\n  'token': 12351,\n  'token_str': ' Arctic',\n  'sequence': 'sun rises in the Arctic'},\n {'score': 0.0532655231654644,\n  'token': 3778,\n  'token_str': ' sun',\n  'sequence': 'sun rises in the sun'}]\n# named entity recognnition\nner = pipeline('ner', grouped_entities=True)\nner(\"My name is Kiran and I work at Amazon\")\n\nNo model was supplied, defaulted to dbmdz/bert-large-cased-finetuned-conll03-english and revision f2482bf (https://huggingface.co/dbmdz/bert-large-cased-finetuned-conll03-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n/Users/achinta/miniforge3/envs/ml/lib/python3.9/site-packages/transformers/pipelines/token_classification.py:135: UserWarning: `grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to `aggregation_strategy=\"simple\"` instead.\n  warnings.warn(\n\n\n[{'entity_group': 'PER',\n  'score': 0.9954788,\n  'word': 'Kiran',\n  'start': 11,\n  'end': 16},\n {'entity_group': 'ORG',\n  'score': 0.99733573,\n  'word': 'Amazon',\n  'start': 31,\n  'end': 37}]\n# question answering\nquestion_answerer = pipeline('question-answering')\nquestion_answerer(question=\"What is the capital of India?\", context=\"India is a country in South Asia. Its capital is New Delhi\")\n\nNo model was supplied, defaulted to distilbert-base-cased-distilled-squad and revision 626af31 (https://huggingface.co/distilbert-base-cased-distilled-squad).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\n\n\n{'score': 0.9939645528793335, 'start': 49, 'end': 58, 'answer': 'New Delhi'}\n# summarizer = pipeline('summarization')\n# summarizer('a stitch in time saves nine', min_length=100, max_length=200)\n# !pip install sentencepiece\nfrom transformers import pipeline\ntranslator = pipeline('translation', model='Helsinki-NLP/opus-mt-fr-en')\ntranslator('Bonjour, comment allez-vous?')\n\n/Users/achinta/miniforge3/envs/ml/lib/python3.9/site-packages/transformers/models/marian/tokenization_marian.py:194: UserWarning: Recommended: pip install sacremoses.\n  warnings.warn(\"Recommended: pip install sacremoses.\")\n\n\n[{'translation_text': 'Hello, how are you?'}]"
  },
  {
    "objectID": "posts/2023-01-23-huggingface-course.html#encoder-and-decoder-models",
    "href": "posts/2023-01-23-huggingface-course.html#encoder-and-decoder-models",
    "title": "1. Transformer Models",
    "section": "Encoder and Decoder models",
    "text": "Encoder and Decoder models\nIn encoder models, attention layers can access all words in the input sequence. Pretraining involves corruping an input sequence and predicting the original sequence (say masking). They are best suited for tasks that require a full understanding of the entire sequence, such as sentence classification.\nDecoder models use only the decoder of the model. At each stage, the attention layer can access only words positioned before it in the sentence. These models are called auto-regresive models.\nSequence-to-sequence models, use both parts of the Transformer architecture. At each stage, the attention layers of the encoder can access all the words in the initial sentence, whereas the attention layers of the decoder can only access the words positioned before a given word in the input."
  },
  {
    "objectID": "posts/2023-01-23-huggingface-course.html#loading-a-model",
    "href": "posts/2023-01-23-huggingface-course.html#loading-a-model",
    "title": "1. Transformer Models",
    "section": "Loading a model",
    "text": "Loading a model\n\nfrom transformers import AutoModel\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\nmodel = AutoModel.from_pretrained(checkpoint)\n\nSome weights of the model checkpoint at distilbert-base-uncased-finetuned-sst-2-english were not used when initializing DistilBertModel: ['classifier.weight', 'pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n- This IS expected if you are initializing DistilBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing DistilBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n\n\n\nfrom transformers import AutoTokenizer\nraw_inputs = [\n    \"I've been waiting for a HuggingFace course my whole life.\",\n    \"I hate this so much!\",\n]\n\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\ninputs = tokenizer(raw_inputs, padding=True, truncation=True, return_tensors=\"pt\")\ninputs\n\n{'input_ids': tensor([[  101,  1045,  1005,  2310,  2042,  3403,  2005,  1037, 17662, 12172,\n          2607,  2026,  2878,  2166,  1012,   102],\n        [  101,  1045,  5223,  2023,  2061,  2172,   999,   102,     0,     0,\n             0,     0,     0,     0,     0,     0]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1],\n        [1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0]])}\n\n\n\n# if task is sequence classification\nfrom transformers import AutoModelForSequenceClassification\ncheckpoint = \"distilbert-base-uncased-finetuned-sst-2-english\"\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint)\noutputs = model(**inputs)\nprint(outputs.logits.shape)\nprint(f'outputs - {outputs.logits}')\n\n# to output the probabilities, we need pass it thorugh a softmax\nimport torch\nprobs = torch.softmax(outputs.logits, dim=-1)\nprint(f'probabilities - {probs}')\n\nprint(model.config.id2label)\n\ntorch.Size([2, 2])\noutputs - tensor([[-1.5607,  1.6123],\n        [ 4.1692, -3.3464]], grad_fn=&lt;AddmmBackward0&gt;)\nprobabilities - tensor([[4.0195e-02, 9.5981e-01],\n        [9.9946e-01, 5.4418e-04]], grad_fn=&lt;SoftmaxBackward0&gt;)\n{0: 'NEGATIVE', 1: 'POSITIVE'}\n\n\n\nModels\n\nfrom transformers import BertConfig, BertModel\n\nconfig = BertConfig()\nmodel = BertModel(config)\n\nprint(config)\n\nBertConfig {\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.23.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\n\n\nSubword tokenization algorithms rely on the principle that frequently used words should not be split into smaller subwords, but rare words should be decomposed into meaningful subwords.\n\n\nTokenizers\n\ntokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\ntext = \"The medicine is arsenic album, ars albaam, allium sepa\"\ninput_ids = tokenizer(text, return_tensors=\"pt\").input_ids\nprint(input_ids[0])\n\n# create the text from input ids\nprint(tokenizer.decode(input_ids[0]))\n\n# print each token\ntokens = [token for token in tokenizer.convert_ids_to_tokens(input_ids[0])]\nprint(tokens)\n\n\n# print the vocab size\nprint(tokenizer.vocab_size)\n\ntensor([  101,  1109,  5182,  1110,   170, 22972,  1596,  1312,   117,   170,\n         1733,  2393,  2822,  2312,   117,  1155,  3656, 14516,  4163,   102])\n[CLS] The medicine is arsenic album, ars albaam, allium sepa [SEP]\n['[CLS]', 'The', 'medicine', 'is', 'a', '##rsen', '##ic', 'album', ',', 'a', '##rs', 'al', '##ba', '##am', ',', 'all', '##ium', 'se', '##pa', '[SEP]']\n28996\n\n\nWe noticed that for unknown words, the tokenizer will split them into subwords that are not meaningful. For example, the word “huggingface” is split into “hug”, “##ging”, “##face”. This is because the tokenizer was trained on a vocabulary that did not contain the word “huggingface”.\nBut there is a way to simpler way to get tokens.\n\ntokens = tokenizer.tokenize(text)\nprint(tokens)\n\n# convert to ids\ntoken_ids = tokenizer.convert_tokens_to_ids(tokens)\nprint(token_ids)\n\n['The', 'medicine', 'is', 'a', '##rsen', '##ic', 'album', ',', 'a', '##rs', 'al', '##ba', '##am', ',', 'all', '##ium', 'se', '##pa']\n[1109, 5182, 1110, 170, 22972, 1596, 1312, 117, 170, 1733, 2393, 2822, 2312, 117, 1155, 3656, 14516, 4163]\n\n\nAttention masks are tensors with the exact same shape as the input IDs tensor, filled with 0s and 1s: 1s indicate the corresponding tokens should be attended to, and 0s indicate the corresponding tokens should not be attended to (i.e., they should be ignored by the attention layers of the model)."
  },
  {
    "objectID": "posts/2023-01-23-huggingface-course.html#processing-the-data",
    "href": "posts/2023-01-23-huggingface-course.html#processing-the-data",
    "title": "1. Transformer Models",
    "section": "3.2 Processing the data",
    "text": "3.2 Processing the data\n\nimport torch\nfrom transformers import AdamW, AutoTokenizer, AutoModelForSequenceClassification\n\ncheckpoint = 'bert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n\nsequences = [\n    'I have been waiting for a Hugging face course my whole life.',\n    'This course is amazing'\n]\nbatch = tokenizer(sequences, padding=True, truncation=True, return_tensors='pt')\nprint(batch.keys())\n\nbatch['labels'] = torch.tensor([1, 1])\noptimizer = AdamW(model.parameters(), lr=5e-5)\n\nSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.LayerNorm.bias', 'cls.predictions.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.dense.bias']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n\n\n/Users/achinta/miniforge3/envs/ml/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n  warnings.warn(\n\n\n\nloss = model(**batch).loss\nloss.backward()\noptimizer.step()\n\n\n# download and cache datasets\n# mrpc dataset is a dataset for paraphrase detection. \nfrom datasets import load_dataset\nraw_datasets = load_dataset('glue','mrpc')\nraw_datasets\n\nFound cached dataset glue (/Users/achinta/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n\n\n\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 3668\n    })\n    validation: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 408\n    })\n    test: Dataset({\n        features: ['sentence1', 'sentence2', 'label', 'idx'],\n        num_rows: 1725\n    })\n})\n\n\n\nraw_train_dataset = raw_datasets['train']\nraw_train_dataset[0]\n\n{'sentence1': 'Amrozi accused his brother , whom he called \" the witness \" , of deliberately distorting his evidence .',\n 'sentence2': 'Referring to him as only \" the witness \" , Amrozi accused his brother of deliberately distorting his evidence .',\n 'label': 1,\n 'idx': 0}\n\n\n\nraw_train_dataset.features\n\n{'sentence1': Value(dtype='string', id=None),\n 'sentence2': Value(dtype='string', id=None),\n 'label': ClassLabel(names=['not_equivalent', 'equivalent'], id=None),\n 'idx': Value(dtype='int32', id=None)}\n\n\n\nfrom transformers import AutoTokenizer\ncheckpoint = 'bert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\ntokenized_sentences_1 = tokenizer(raw_datasets['train']['sentence1'])\nprint(tokenized_sentences_1['input_ids'][0])\n\n# we need sentence pairs, and the tokenizer understands that\ninputs = tokenizer(\"This is the first sentence.\", \"This is the second one.\")\nprint(inputs.keys())\n\nprint(tokenizer.convert_ids_to_tokens(inputs['input_ids']))\n# Here token_type_ids is used to separate the two sentences\n\n[101, 2572, 3217, 5831, 5496, 2010, 2567, 1010, 3183, 2002, 2170, 1000, 1996, 7409, 1000, 1010, 1997, 9969, 4487, 23809, 3436, 2010, 3350, 1012, 102]\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask'])\n['[CLS]', 'this', 'is', 'the', 'first', 'sentence', '.', '[SEP]', 'this', 'is', 'the', 'second', 'one', '.', '[SEP]']\n\n\n\n# We can tokenize the entire dataset in one go using\ntokenized_dataset = tokenizer(raw_datasets['train']['sentence1'], raw_datasets['train']['sentence2'], padding=True, truncation=True)\n\n# to tokenize in batches, we define a function to be applied to each sample. We can also handle any other preprocessing we want to do\ndef tokenize_function(examples):\n    return tokenizer(examples['sentence1'], examples['sentence2'], padding=True, truncation=True)\n\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\nprint(f\"raw train dataset has keys - {raw_datasets['train'][0].keys()}\")\nprint(f\"tokenized train dataset has keys - {tokenized_datasets['train'][0].keys()}\")\n\nLoading cached processed dataset at /Users/achinta/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-7570128720f579c6.arrow\nLoading cached processed dataset at /Users/achinta/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-7b7428962528a4a4.arrow\nLoading cached processed dataset at /Users/achinta/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-3dcdb0892050254a.arrow\n\n\nraw train dataset has keys - dict_keys(['sentence1', 'sentence2', 'label', 'idx'])\ntokenized train dataset has keys - dict_keys(['sentence1', 'sentence2', 'label', 'idx', 'input_ids', 'token_type_ids', 'attention_mask'])\n\n\n\n# lets find the size of input_ids for a few samples\nimport random\nsamples = random.sample(list(tokenized_datasets[\"train\"]), k=10)\nsamples = [{k: v for k, v in sample.items() if k not in [\"idx\", \"sentence1\", \"sentence2\"]} for sample in samples]\n[len(sample['input_ids']) for sample in samples]\n\n[96, 100, 96, 89, 89, 89, 96, 89, 103, 103]\n\n\n\n# lets use the data collator to pad the dataset to the max length in the dataset (not the max length of the dataset)\nfrom transformers import DataCollatorWithPadding\n\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)    \nbatch = data_collator(samples)\nprint(batch.keys())\n[len(batch['input_ids'][i]) for i in range(len(batch['input_ids']))]\n{k: v.shape for k, v in batch.items()}\n\ndict_keys(['input_ids', 'token_type_ids', 'attention_mask', 'labels'])\n\n\n{'input_ids': torch.Size([10, 103]),\n 'token_type_ids': torch.Size([10, 103]),\n 'attention_mask': torch.Size([10, 103]),\n 'labels': torch.Size([10])}\n\n\n\n3.3 Finetuning the model\nLets sumamrize the steps we did till now\n\nfrom datasets import load_dataset\nfrom transformers import AutoTokenizer, DataCollatorWithPadding, AutoModelForSequenceClassification, Trainer\nraw_datasets = load_dataset('glue','mrpc')\ncheckpoint = 'bert-base-uncased'\ntokenizer = AutoTokenizer.from_pretrained(checkpoint)\n\ndef tokenize_function(examples):\n    return tokenizer(examples['sentence1'], examples['sentence2'], padding=True, truncation=True)\n\ntokenized_datasets = raw_datasets.map(tokenize_function, batched=True)\ndata_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n\nfrom transformers import TrainingArguments\ntraining_args = TrainingArguments('test-trainer')\nmodel = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)\n\nFound cached dataset glue (/Users/achinta/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad)\n\n\n\n\n\nloading configuration file config.json from cache at /Users/achinta/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"bert-base-uncased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.23.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading file vocab.txt from cache at /Users/achinta/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/vocab.txt\nloading file tokenizer.json from cache at /Users/achinta/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer.json\nloading file added_tokens.json from cache at None\nloading file special_tokens_map.json from cache at None\nloading file tokenizer_config.json from cache at /Users/achinta/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/tokenizer_config.json\nloading configuration file config.json from cache at /Users/achinta/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"bert-base-uncased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.23.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nLoading cached processed dataset at /Users/achinta/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-df486dc2eb69ac71.arrow\nLoading cached processed dataset at /Users/achinta/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-782aec776148990b.arrow\nLoading cached processed dataset at /Users/achinta/.cache/huggingface/datasets/glue/mrpc/1.0.0/dacbe3125aa31d7f70367a07a8a9e72a5a0bfeb5fc42e75c9db75b96da6053ad/cache-8daf6f80b8639cc1.arrow\nPyTorch: setting up devices\nThe default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\nloading configuration file config.json from cache at /Users/achinta/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/config.json\nModel config BertConfig {\n  \"_name_or_path\": \"bert-base-uncased\",\n  \"architectures\": [\n    \"BertForMaskedLM\"\n  ],\n  \"attention_probs_dropout_prob\": 0.1,\n  \"classifier_dropout\": null,\n  \"gradient_checkpointing\": false,\n  \"hidden_act\": \"gelu\",\n  \"hidden_dropout_prob\": 0.1,\n  \"hidden_size\": 768,\n  \"initializer_range\": 0.02,\n  \"intermediate_size\": 3072,\n  \"layer_norm_eps\": 1e-12,\n  \"max_position_embeddings\": 512,\n  \"model_type\": \"bert\",\n  \"num_attention_heads\": 12,\n  \"num_hidden_layers\": 12,\n  \"pad_token_id\": 0,\n  \"position_embedding_type\": \"absolute\",\n  \"transformers_version\": \"4.23.1\",\n  \"type_vocab_size\": 2,\n  \"use_cache\": true,\n  \"vocab_size\": 30522\n}\n\nloading weights file pytorch_model.bin from cache at /Users/achinta/.cache/huggingface/hub/models--bert-base-uncased/snapshots/0a6aa9128b6194f4f3c4db429b6cb4891cdb421b/pytorch_model.bin\nSome weights of the model checkpoint at bert-base-uncased were not used when initializing BertForSequenceClassification: ['cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.weight']\n- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\nSome weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n\nimport evaluate\nimport numpy as np\n\ndef compute_metrics(eval_preds):\n    metric = evaluate.load(\"glue\", \"mrpc\")\n    logits, labels = eval_preds\n    predictions = np.argmax(logits, axis=-1)\n    return metric.compute(predictions=predictions, references=labels)\n\ntrainer = Trainer(\n    model,\n    training_args,\n    train_dataset=tokenized_datasets[\"train\"],\n    eval_dataset=tokenized_datasets[\"validation\"],\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n    compute_metrics=compute_metrics,\n)\n\ntrainer.train()\n\nwandb: Network error (ConnectTimeout), entering retry loop.\n\n\nWe get a warning after instantiating this pretrained model. This is because BERT has not been pretrained on classifying pairs of sentences, so the head of the pretrained model has been discarded and a new head suitable for sequence classification has been added instead. The warnings indicate that some weights were not used (the ones corresponding to the dropped pretraining head) and that some others were randomly initialized (the ones for the new head)."
  },
  {
    "objectID": "posts/2023-01-23-huggingface-course.html#the-datasets-library",
    "href": "posts/2023-01-23-huggingface-course.html#the-datasets-library",
    "title": "1. Transformer Models",
    "section": "5 The datasets library",
    "text": "5 The datasets library\n\n!export TOKENIZERS_PARALLELISM=true\nfrom datasets import load_dataset\n# !wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-train.json.gz\n# !wget https://github.com/crux82/squad-it/raw/master/SQuAD_it-test.json.gz\n\nsquad_it_dataset = load_dataset('json', data_files='SQuAD_it-train.json.gz', field='data')\nsquad_it_dataset\n\n# we can include train and tests data in the squad_it_dataset\ndata_files = {\"train\": \"SQuAD_it-train.json.gz\", \"test\": \"SQuAD_it-test.json.gz\"}\nsquad_it_dataset = load_dataset('json',data_files=data_files,field='data' )\nsquad_it_dataset\n\n# we give remote urls also\n\nUsing custom data configuration default-bbdcaac21d7e3d0b\nFound cached dataset json (/Users/achinta/.cache/huggingface/datasets/json/default-bbdcaac21d7e3d0b/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n\n\n\n\n\nUsing custom data configuration default-80fa3afbe58e2f42\nFound cached dataset json (/Users/achinta/.cache/huggingface/datasets/json/default-80fa3afbe58e2f42/0.0.0/0f7e3662623656454fcd2b650f34e886a7db4b9104504885bd462096cc7a9f51)\n\n\n\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['title', 'paragraphs'],\n        num_rows: 442\n    })\n    test: Dataset({\n        features: ['title', 'paragraphs'],\n        num_rows: 48\n    })\n})\n\n\n\n%%time\n# !wget \"https://archive.ics.uci.edu/ml/machine-learning-databases/00462/drugsCom_raw.zip\"\n# !unzip drugsCom_raw.zip\nfrom datasets import load_dataset\n!ls -lrth drugs*.tsv\n\ndata_files = {\"train\": \"drugsComTrain_raw.tsv\", \"test\": \"drugsComTest_raw.tsv\"}\ndrug_dataset = load_dataset(\"csv\", data_files=data_files, delimiter=\"\\t\")\ndrug_dataset\n\n-rw-r--r--  1 achinta  staff    80M Oct  2  2018 drugsComTrain_raw.tsv\n-rw-r--r--  1 achinta  staff    27M Oct  2  2018 drugsComTest_raw.tsv\n\n\nUsing custom data configuration default-4eaca5caac99961c\nFound cached dataset csv (/Users/achinta/.cache/huggingface/datasets/csv/default-4eaca5caac99961c/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317)\n\n\n\n\n\nCPU times: user 69.1 ms, sys: 17.9 ms, total: 87 ms\nWall time: 1.52 s\n\n\nDatasetDict({\n    train: Dataset({\n        features: ['Unnamed: 0', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n        num_rows: 161297\n    })\n    test: Dataset({\n        features: ['Unnamed: 0', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n        num_rows: 53766\n    })\n})\n\n\n\n# look at a sample of the data\ndrug_sample = drug_dataset[\"train\"].shuffle(seed=42).select(range(1000))\ndrug_sample[:3]\n\nLoading cached shuffled indices for dataset at /Users/achinta/.cache/huggingface/datasets/csv/default-4eaca5caac99961c/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-a77308af6ca3c149.arrow\n\n\n{'Unnamed: 0': [87571, 178045, 80482],\n 'drugName': ['Naproxen', 'Duloxetine', 'Mobic'],\n 'condition': ['Gout, Acute', 'ibromyalgia', 'Inflammatory Conditions'],\n 'review': ['\"like the previous person mention, I&#039;m a strong believer of aleve, it works faster for my gout than the prescription meds I take. No more going to the doctor for refills.....Aleve works!\"',\n  '\"I have taken Cymbalta for about a year and a half for fibromyalgia pain. It is great\\r\\nas a pain reducer and an anti-depressant, however, the side effects outweighed \\r\\nany benefit I got from it. I had trouble with restlessness, being tired constantly,\\r\\ndizziness, dry mouth, numbness and tingling in my feet, and horrible sweating. I am\\r\\nbeing weaned off of it now. Went from 60 mg to 30mg and now to 15 mg. I will be\\r\\noff completely in about a week. The fibro pain is coming back, but I would rather deal with it than the side effects.\"',\n  '\"I have been taking Mobic for over a year with no side effects other than an elevated blood pressure.  I had severe knee and ankle pain which completely went away after taking Mobic.  I attempted to stop the medication however pain returned after a few days.\"'],\n 'rating': [9.0, 3.0, 10.0],\n 'date': ['September 2, 2015', 'November 7, 2011', 'June 5, 2013'],\n 'usefulCount': [36, 13, 128]}\n\n\n\n# check that the \"Unnamed: 0\" is unique key in the dataset\nfor split in drug_dataset.keys():\n    assert len(drug_dataset[split]) == len(drug_dataset[split].unique(\"Unnamed: 0\"))\n\n# lets rename the column\ndrug_dataset = drug_dataset.rename_column(\n    original_column_name=\"Unnamed: 0\", new_column_name=\"patient_id\"\n)\ndrug_dataset\n\nDatasetDict({\n    train: Dataset({\n        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n        num_rows: 161297\n    })\n    test: Dataset({\n        features: ['patient_id', 'drugName', 'condition', 'review', 'rating', 'date', 'usefulCount'],\n        num_rows: 53766\n    })\n})\n\n\n\ndef lowercase_condition(example):\n    return {'condition': example['condition'].lower()}\n\ndef filter_nones(x):\n    return x['condition'] is not None\n\ndrug_dataset = drug_dataset.filter(lambda x: x[\"condition\"] is not None)\n\ndrug_dataset = drug_dataset.map(lowercase_condition)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\ndef compute_review_length(example):\n    return {\"review_length\": len(example[\"review\"].split())}\n\ndrug_dataset = drug_dataset.map(compute_review_length)\n\n\n\n\n\n\n\n\ndrug_dataset[\"train\"].sort(\"review_length\")[:2]\n\nLoading cached sorted indices for dataset at /Users/achinta/.cache/huggingface/datasets/csv/default-4eaca5caac99961c/0.0.0/6b34fb8fcf56f7c8ba51dc895bfa2bfbe43546f190a60fcf74bb5e8afdcc2317/cache-75752611952acc02.arrow\n\n\n{'patient_id': [103488, 23627],\n 'drugName': ['Loestrin 21 1 / 20', 'Chlorzoxazone'],\n 'condition': ['birth control', 'muscle spasm'],\n 'review': ['\"Excellent.\"', '\"useless\"'],\n 'rating': [10.0, 1.0],\n 'date': ['November 4, 2008', 'March 24, 2017'],\n 'usefulCount': [5, 2],\n 'review_length': [1, 1]}\n\n\n\nimport html\n\ntext = \"I&#039;m a transformer called BERT\"\nhtml.unescape(text)\n\ndrug_dataset = drug_dataset.map(lambda x: {\"review\": html.unescape(x[\"review\"])})\n\n\n\n\n\n\n\n\nnew_drug_dataset = drug_dataset.map(\n    lambda x: {\"review\": [html.unescape(o) for o in x[\"review\"]]}, batched=True\n)"
  },
  {
    "objectID": "posts/2024-07-14-india-urban-maps-ola.html",
    "href": "posts/2024-07-14-india-urban-maps-ola.html",
    "title": "Finding Urban Locality data for India",
    "section": "",
    "text": "There was a need to move away from Google Maps for locality data in India due to increase in Google Maps geocoding pricing. We could find very good Village data from Local Government Directory. But the urban data still consisted of government bodies in urban areas, but not the new and popular names they are referred with. For example, we may not find HSR Layout (Bangalore)\n\nData Sources considered\nThis needs to be expanded. WIP ##### India postcode data https://www.data.gov.in/resource/all-india-pincode-directory-till-last-month This contains only the postal codes. If an urban area does not have a post office, we cannot find it in this dataset\n\nimport pandas as pd\nfrom pathlib import Path\n\npostcodes = pd.read_csv(Path.home()/'Downloads/pincode.csv', low_memory=False)\nprint(f'postcodes shape - {postcodes.shape}')\nprint(f'number of unique postcodes - {postcodes[\"Pincode\"].nunique()}')\npostcodes.head(3)\n\npostcodes shape - (157126, 11)\nnumber of unique postcodes - 19300\n\n\n\n\n\n\n\n\n\nCircleName\nRegionName\nDivisionName\nOfficeName\nPincode\nOfficeType\nDelivery\nDistrict\nStateName\nLatitude\nLongitude\n\n\n\n\n0\nAndhra Pradesh Circle\nKurnool Region\nHindupur Division\nPeddakotla B.O\n515631\nBO\nDelivery\nANANTAPUR\nANDHRA PRADESH\n14.5689\n77.85624\n\n\n1\nAndhra Pradesh Circle\nKurnool Region\nHindupur Division\nPinnadhari B.O\n515631\nBO\nDelivery\nANANTAPUR\nANDHRA PRADESH\n14.5281\n77.857014\n\n\n2\nAndhra Pradesh Circle\nKurnool Region\nHindupur Division\nYerraguntapalle B.O\n515631\nBO\nDelivery\nANANTAPUR\nANDHRA PRADESH\n14.561111\n77.85715\n\n\n\n\n\n\n\n\n\nGoogle Maps vs Ola Maps\nWhen we search for ‘Goregoan, Mumbai’ in https://developers.google.com/maps/documentation/geocoding/overview#geocoding-requests, it is identified as a sublocality.\n\n\n\nGeocoding Result\n\n\nLet us search for it in Ola Maps\n\nimport os\nimport requests\nimport json\napi_key = os.environ.get('OLA_MAPS_API_KEY')\n\naddress = 'Goregoan, Mumbai'\n\nurl = \"https://api.olamaps.io/places/v1/geocode\"\nparams = {\n    \"address\": address,\n\"language\": \"EN\",\n    \"api_key\": api_key\n}\n\nresponse = requests.get(url, params=params)\nresp = response.json()\n\nprint(f'num results - {len(resp[\"geocodingResults\"])}')\nfor idx in range(len(resp[\"geocodingResults\"])):\n    print(f'{idx+1} - {resp[\"geocodingResults\"][idx][\"formatted_address\"]}')\n\n# print formatted json\n# print(json.dumps(resp['geocodingResults'][0], indent=4, sort_keys=True))\n\nnum results - 5\n1 - Lupin, Mantri Park, Goregoan East, Lupin, IGIDR, Nagri Niwara CoOperative Housing Society, Goregaon, Mumbai, Maharashtra, 400065, India\n2 - Goregoan West, Teen Dongari, Prem Nagar, Goregaon West, Mumbai, Maharashtra, 400104, India\n3 - Goregoan East, Peru Baug, Churi Wadi, Goregaon, Mumbai, Maharashtra, 400063, India\n4 - Parking Goregoan, Laxmi Rd, Ganesh Nagar, Goregaon, Mumbai, Maharashtra, 400065, India\n5 - Goregoan Properties, 138, 4, Jawahar Nagar Rd, No 9, Goregaon West, Mumbai, Maharashtra, 400104, India\n\n\nWe can see that Ola Maps returns specific addresses with matching names, but not the sublocality. We can retrieve sublocality from the returned components, but if there are no matching addresses, we will miss out sub sub-localities\n\nNeonatim hosted search\nLet us now check the hosted Neonatim search - https://nominatim.openstreetmap.org/\nWhen we search using this, we can find ‘Visalakshinagar’, but I dont find it in my local installation. So looks like some entries are not built correctly.\nSo even if we find an entry, which admin_level should be considered for an ‘urban locality’?"
  },
  {
    "objectID": "posts/2024-02-12-qdrant-cloud-run.html",
    "href": "posts/2024-02-12-qdrant-cloud-run.html",
    "title": "Run Qdrant in Google Cloud Run",
    "section": "",
    "text": "I want to minimize the cost involved in running a Qdrant vector database on Google Cloud.\nWhy Google Cloud Run for a running a vector database?\nRunning on Google Cloud Run offers the following advantages - Auto Scaling with load - We can keep the –min-instances to 0 to to stop running when there is no load.\nBut the challenge is - storage on the Cloud Run containers is ephemeral. So what would be the common persistent storage for Qdrant?\nLuckily, from gen2, Cloud Run supports mounting a cloud storage bucket as a volume, which can be accessible across the cloud run instances.\nSo here are the gcloud command to setup create the storage bucket and to update/deploy the cloud run service.\n# set the project name and region\nexport PROJECT_ID=project_xyz\nexport REGION=asia-southeast1\nexport BUCKET_NAME=bucket_name\n\n# switch to the project\ngcloud config set project $PROJECT_ID\n\n# create a cloud storage bucket\ngsutil mb -l $REGION gs://$BUCKET_NAME\n\n\n# deploy the cloud run service\ngcloud beta run deploy qdrant --image qdrant/qdrant:latest \\\n--execution-environment gen2 \\\n--add-volume=name=qdrant_storage,type=cloud-storage,bucket=$BUCKET_NAME \\\n--add-volume-mount=volume=qdrant_storage,mount-path=/qdrant/storage \\\n--allow-unauthenticated --max-instances 1 \\\n--update-env-vars QDRANT__SERVICE__HTTP_PORT=8080,QDRANT__SERVICE__API_KEY=$QDRANT__SERVICE__API_KEY \\\n--memory 512Mi \\\n--region $REGION --project $PROJECT_ID\n\n# to update the cloud run service\ngcloud beta run services update qdrant \\\n--region asia-southeast1 --project $PROJECT_ID \\\n--memory 512Mi --max-instances 1 \\"
  },
  {
    "objectID": "posts/2022-05-13-timeseries-1.html",
    "href": "posts/2022-05-13-timeseries-1.html",
    "title": "Passenger dataset",
    "section": "",
    "text": "import pandas as pd\nimport numpy as np\nfrom random import gauss\nfrom pandas.plotting import autocorrelation_plot\nimport warnings\nimport itertools\nfrom random import random\n\nimport statsmodels.formula.api as smf\nimport statsmodels.api as sm\nfrom statsmodels.tsa.ar_model import AR\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import adfuller\n\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nimport seaborn as sns\n\n\n# general settings\nclass CFG:\n    data_folder = '../input/tsdata-1/'\n    img_dim1 = 20\n    img_dim2 = 10\n    \nplt.rcParams.update({'figure.figsize': (CFG.img_dim1, CFG.img_dim2)})\n\ncan be downloaded from https://www.kaggle.com/datasets/chirag19/air-passengers\n\nseries = pd.read_csv('AirPassengers.csv')\nseries['date'] = pd.to_datetime(series['Month'])\nseries.set_index('date', inplace=True)\nseries.head(3)\n\n\n\n\n\n\n\n\nMonth\n#Passengers\n\n\ndate\n\n\n\n\n\n\n1949-01-01\n1949-01\n112\n\n\n1949-02-01\n1949-02\n118\n\n\n1949-03-01\n1949-03\n132\n\n\n\n\n\n\n\n\n!ls -lrt\n\ntotal 9576\n-rw-r--r--  1 achinta  staff  3162384 May 13 20:17 2020-02-20-test.ipynb\n-rw-r--r--  1 achinta  staff     5385 May 13 20:17 2021-08-11-ar-net.ipynb\n-rw-r--r--  1 achinta  staff  1424885 May 13 20:17 2021-11-11-linear-algebra-svd.ipynb\n-rw-r--r--  1 achinta  staff    25836 May 13 20:17 2021-11-22-01-the-machine-learning-landscape.ipynb\n-rw-r--r--  1 achinta  staff   139119 May 13 20:17 2021-11-28-sklearn-intro.ipynb\n-rw-r--r--  1 achinta  staff     2844 May 13 20:17 2021-12-23-LA-column-spaces.ipynb\n-rw-r--r--  1 achinta  staff    37424 May 13 20:17 2021-12-28-variational-inference.ipynb\n-rw-r--r--  1 achinta  staff     3807 May 13 20:17 2022-01-06-linear-regression.ipynb\n-rw-r--r--  1 achinta  staff    14865 May 13 20:17 2022-01-10-sklearn-2.ipynb\n-rw-r--r--  1 achinta  staff    11212 May 13 20:17 2022-01-16-movie-recommender-pytorch.ipynb\n-rw-r--r--  1 achinta  staff    37422 May 13 20:17 2022-03-07-product-recomendation.ipynb\n-rw-r--r--  1 achinta  staff      771 May 13 20:17 README.md\n-rw-r--r--  1 achinta  staff     6436 May 13 20:17 algos.ipynb\ndrwxr-xr-x  4 achinta  staff      128 May 13 20:17 ghtop_images\ndrwxr-xr-x  3 achinta  staff       96 May 13 20:17 my_icons\n-rw-r--r--  1 achinta  staff     2049 May 13 20:46 2022-05-13-timeseries-1.ipynb\n\n\n\n!pip install redis\n\nCollecting redis\n  Using cached redis-4.3.1-py3-none-any.whl (241 kB)\nRequirement already satisfied: packaging&gt;=20.4 in /Users/achinta/miniforge3/envs/ml/lib/python3.9/site-packages (from redis) (21.3)\nCollecting deprecated&gt;=1.2.3\n  Using cached Deprecated-1.2.13-py2.py3-none-any.whl (9.6 kB)\nCollecting async-timeout&gt;=4.0.2\n  Using cached async_timeout-4.0.2-py3-none-any.whl (5.8 kB)\nCollecting wrapt&lt;2,&gt;=1.10\n  Downloading wrapt-1.14.1-cp39-cp39-macosx_11_0_arm64.whl (35 kB)\nRequirement already satisfied: pyparsing!=3.0.5,&gt;=2.0.2 in /Users/achinta/miniforge3/envs/ml/lib/python3.9/site-packages (from packaging&gt;=20.4-&gt;redis) (3.0.9)\nInstalling collected packages: wrapt, async-timeout, deprecated, redis\nSuccessfully installed async-timeout-4.0.2 deprecated-1.2.13 redis-4.3.1 wrapt-1.14.1\n\n\n\nimport redis\n\n\nimport redis\n\nr = redis.Redis()\nr.set('foo', 'bar')\n\n\n---------------------------------------------------------------------------\nConnectionError                           Traceback (most recent call last)\nInput In [27], in &lt;cell line: 4&gt;()\n      1 import redis\n      3 r = redis.Redis()\n----&gt; 4 r.set('foo', 'bar')\n\nFile ~/miniforge3/envs/ml/lib/python3.9/site-packages/redis/commands/core.py:2208, in BasicKeyCommands.set(self, name, value, ex, px, nx, xx, keepttl, get, exat, pxat)\n   2205     pieces.append(\"GET\")\n   2206     options[\"get\"] = True\n-&gt; 2208 return self.execute_command(\"SET\", *pieces, **options)\n\nFile ~/miniforge3/envs/ml/lib/python3.9/site-packages/redis/client.py:1227, in Redis.execute_command(self, *args, **options)\n   1224 conn = self.connection or pool.get_connection(command_name, **options)\n   1226 try:\n-&gt; 1227     return conn.retry.call_with_retry(\n   1228         lambda: self._send_command_parse_response(\n   1229             conn, command_name, *args, **options\n   1230         ),\n   1231         lambda error: self._disconnect_raise(conn, error),\n   1232     )\n   1233 finally:\n   1234     if not self.connection:\n\nFile ~/miniforge3/envs/ml/lib/python3.9/site-packages/redis/retry.py:49, in Retry.call_with_retry(self, do, fail)\n     47 except self._supported_errors as error:\n     48     failures += 1\n---&gt; 49     fail(error)\n     50     if self._retries &gt;= 0 and failures &gt; self._retries:\n     51         raise error\n\nFile ~/miniforge3/envs/ml/lib/python3.9/site-packages/redis/client.py:1231, in Redis.execute_command.&lt;locals&gt;.&lt;lambda&gt;(error)\n   1224 conn = self.connection or pool.get_connection(command_name, **options)\n   1226 try:\n   1227     return conn.retry.call_with_retry(\n   1228         lambda: self._send_command_parse_response(\n   1229             conn, command_name, *args, **options\n   1230         ),\n-&gt; 1231         lambda error: self._disconnect_raise(conn, error),\n   1232     )\n   1233 finally:\n   1234     if not self.connection:\n\nFile ~/miniforge3/envs/ml/lib/python3.9/site-packages/redis/client.py:1217, in Redis._disconnect_raise(self, conn, error)\n   1212 conn.disconnect()\n   1213 if (\n   1214     conn.retry_on_error is None\n   1215     or isinstance(error, tuple(conn.retry_on_error)) is False\n   1216 ):\n-&gt; 1217     raise error\n\nFile ~/miniforge3/envs/ml/lib/python3.9/site-packages/redis/retry.py:46, in Retry.call_with_retry(self, do, fail)\n     44 while True:\n     45     try:\n---&gt; 46         return do()\n     47     except self._supported_errors as error:\n     48         failures += 1\n\nFile ~/miniforge3/envs/ml/lib/python3.9/site-packages/redis/client.py:1228, in Redis.execute_command.&lt;locals&gt;.&lt;lambda&gt;()\n   1224 conn = self.connection or pool.get_connection(command_name, **options)\n   1226 try:\n   1227     return conn.retry.call_with_retry(\n-&gt; 1228         lambda: self._send_command_parse_response(\n   1229             conn, command_name, *args, **options\n   1230         ),\n   1231         lambda error: self._disconnect_raise(conn, error),\n   1232     )\n   1233 finally:\n   1234     if not self.connection:\n\nFile ~/miniforge3/envs/ml/lib/python3.9/site-packages/redis/client.py:1204, in Redis._send_command_parse_response(self, conn, command_name, *args, **options)\n   1200 \"\"\"\n   1201 Send a command and parse the response\n   1202 \"\"\"\n   1203 conn.send_command(*args)\n-&gt; 1204 return self.parse_response(conn, command_name, **options)\n\nFile ~/miniforge3/envs/ml/lib/python3.9/site-packages/redis/client.py:1243, in Redis.parse_response(self, connection, command_name, **options)\n   1241         response = connection.read_response(disable_decoding=True)\n   1242     else:\n-&gt; 1243         response = connection.read_response()\n   1244 except ResponseError:\n   1245     if EMPTY_RESPONSE in options:\n\nFile ~/miniforge3/envs/ml/lib/python3.9/site-packages/redis/connection.py:827, in Connection.read_response(self, disable_decoding)\n    824     hosterr = \"connection\"\n    826 try:\n--&gt; 827     response = self._parser.read_response(disable_decoding=disable_decoding)\n    828 except socket.timeout:\n    829     self.disconnect()\n\nFile ~/miniforge3/envs/ml/lib/python3.9/site-packages/redis/connection.py:320, in PythonParser.read_response(self, disable_decoding)\n    319 def read_response(self, disable_decoding=False):\n--&gt; 320     raw = self._buffer.readline()\n    321     if not raw:\n    322         raise ConnectionError(SERVER_CLOSED_CONNECTION_ERROR)\n\nFile ~/miniforge3/envs/ml/lib/python3.9/site-packages/redis/connection.py:251, in SocketBuffer.readline(self)\n    248 data = buf.readline()\n    249 while not data.endswith(SYM_CRLF):\n    250     # there's more data in the socket that we need\n--&gt; 251     self._read_from_socket()\n    252     buf.seek(self.bytes_read)\n    253     data = buf.readline()\n\nFile ~/miniforge3/envs/ml/lib/python3.9/site-packages/redis/connection.py:197, in SocketBuffer._read_from_socket(self, length, timeout, raise_on_timeout)\n    195 # an empty string indicates the server shutdown the socket\n    196 if isinstance(data, bytes) and len(data) == 0:\n--&gt; 197     raise ConnectionError(SERVER_CLOSED_CONNECTION_ERROR)\n    198 buf.write(data)\n    199 data_length = len(data)\n\nConnectionError: Connection closed by server."
  },
  {
    "objectID": "posts/2022-01-06-linear-regression.html",
    "href": "posts/2022-01-06-linear-regression.html",
    "title": "Linear Regression",
    "section": "",
    "text": "Matrix Decompositions\nMatrix decomposition is the expression of a matrix as a product of matrices. Just as factorizing a number can tell us important properties of a number, so does matrix decomposition can reveal important properties.\nHere are five important matrix factorizations\n\n\\(A = LU\\)\nThis comes from elimination. Matrix L is lower triangular and U is upper triangular.\n\n\n\\(A = QR\\)\nComes from orthogonalizing the columns \\(a_1\\) to \\(a_n\\), as in ‘Gram-Schmidt’\n\n\n\\(S = Q{\\Lambda}Q^T\\)\nS is a symmetric matrix. Q has orthonormal eigen vectors as its columns. The corresponding eigen values are the digagonal of \\(\\Lambda\\)\n\nimport numpy as np\nfrom scipy import linalg \nimport random\n\n# create a symmetric matrix\na = np.random.randint(1, 10, size=(3,3))\ns = np.tril(a, -1).T + np.tril(a)\nprint(f'symmetric matrix: \\n\\n{s}')\n\n# eigen decomposition\nw, q = linalg.eigh(s)\nprint(f'\\neigen values - {w}')\n\nsymmetric matrix: \n\n[[5 6 1]\n [6 5 5]\n [1 5 3]]\n\neigen values - [-2.78571018  2.86068379 12.92502638]\n\n\n\n# lets reconstruct the matrix\nnp.linalg.multi_dot([q, np.diag(w), np.transpose(q)])\n\narray([[6., 5., 4.],\n       [5., 3., 5.],\n       [4., 5., 4.]])\n\n\n\n# Check that the columns of the matrix are orthogonal\n# select two columns randomly and check the dot prodct\ncol_idxs = random.sample(range(0, s.shape[0]), k=2)\nassert np.isclose(np.dot(q[col_idxs[0]], q[col_idxs[1]]), 0)\n\n\n# check the Euclidean norm of any of columns. It should be 1 as they are orthonormal\ncol_idx = random.choice(range(0, s.shape[0]))\nnp.linalg.norm(q[col_idx], ord=2)\n\n0.9999999999999999"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ajay’s notes",
    "section": "",
    "text": "LLM Leaderboards and benchmarks\n\n\n\n\n\n\n\n\n\n\n\nAug 20, 2024\n\n\n5 min\n\n\n\n\n\n\n\nLocal LLM Inference on Mac Mini\n\n\n\n\n\n\n\n\n\n\n\nAug 20, 2024\n\n\n2 min\n\n\n\n\n\n\n\nPaper Summary: COT Prompting Elicits Reasoning in Large Language Models\n\n\n\n\n\n\n\n\n\n\n\nAug 12, 2024\n\n\n2 min\n\n\n\n\n\n\n\nFinding Urban Locality data for India\n\n\n\n\n\n\n\n\n\n\n\nJul 14, 2024\n\n\n2 min\n\n\n\n\n\n\n\nOpen Street Maps for Geocoding locally\n\n\n\n\n\n\n\n\n\n\n\nJun 28, 2024\n\n\n1 min\n\n\n\n\n\n\n\nObject Detction Finetuning\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2024\n\n\n2 min\n\n\n\n\n\n\n\nExploring Dspy - part 1\n\n\n\n\n\n\n\n\n\n\n\nMay 27, 2024\n\n\n7 min\n\n\n\n\n\n\n\nRun Trilium server in google cloud run\n\n\n\n\n\n\n\n\n\n\n\nMay 4, 2024\n\n\n1 min\n\n\n\n\n\n\n\nRun Qdrant in Google Cloud Run\n\n\n\n\n\n\n\n\n\n\n\nFeb 12, 2024\n\n\n1 min\n\n\n\n\n\n\n\nPurpose\n\n\n\n\n\n\n\n\n\n\n\nApr 19, 2023\n\n\n3 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nFeb 19, 2023\n\n\n4 min\n\n\n\n\n\n\n\nResults\n\n\n\n\n\n\n\n\n\n\n\nFeb 15, 2023\n\n\n13 min\n\n\n\n\n\n\n\n5 The datasets library\n\n\n\n\n\n\n\n\n\n\n\nJan 30, 2023\n\n\n1 min\n\n\n\n\n\n\n\n1. Transformer Models\n\n\n\n\n\n\n\n\n\n\n\nJan 23, 2023\n\n\n2 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nNov 1, 2022\n\n\n1 min\n\n\n\n\n\n\n\nTransformers from scratch in pytorch\n\n\n\n\n\n\n\n\n\n\n\nOct 25, 2022\n\n\n2 min\n\n\n\n\n\n\n\nProperties of Eigen Values and Vectors\n\n\n\n\n\n\n\n\n\n\n\nJun 29, 2022\n\n\n1 min\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nJun 26, 2022\n\n\n1 min\n\n\n\n\n\n\n\nPassenger dataset\n\n\n\n\n\n\n\n\n\n\n\nMay 13, 2022\n\n\n1 min\n\n\n\n\n\n\n\nSatender Product Recommendation\n\n\n\n\n\nFrom SVD to Deep Learning\n\n\n\n\n\nMar 7, 2022\n\n\n2 min\n\n\n\n\n\n\n\nMovie Recommender using pytorch\n\n\n\n\n\nSimple implementation\n\n\n\n\n\nJan 16, 2022\n\n\n1 min\n\n\n\n\n\n\n\nSklearn - Adult Income Classificat\n\n\n\n\n\nBasics\n\n\n\n\n\nJan 10, 2022\n\n\n1 min\n\n\n\n\n\n\n\nLinear Regression\n\n\n\n\n\nBasics\n\n\n\n\n\nJan 6, 2022\n\n\n1 min\n\n\n\n\n\n\n\nVariational Inference\n\n\n\n\n\nUnder the hood\n\n\n\n\n\nDec 28, 2021\n\n\n3 min\n\n\n\n\n\n\n\nMIT 18.065 Linear Algebra, Lecture 1\n\n\n\n\n\nUnderstanding column spaces\n\n\n\n\n\nDec 23, 2021\n\n\n1 min\n\n\n\n\n\n\n\nsklearn intro\n\n\n\n\n\nClassification, Clustering and Regression\n\n\n\n\n\nNov 28, 2021\n\n\n1 min\n\n\n\n\n\n\n\nHands - on ML. Chapter 1\n\n\n\n\n\nClassification, Clustering and Regression\n\n\n\n\n\nNov 22, 2021\n\n\n1 min\n\n\n\n\n\n\n\nFastai Linear Algebra - chapter 1\n\n\n\n\n\nImage background removal with SGD\n\n\n\n\n\nNov 11, 2021\n\n\n1 min\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "About",
    "section": "",
    "text": "About this blog"
  },
  {
    "objectID": "posts/2021-12-28-variational-inference.html",
    "href": "posts/2021-12-28-variational-inference.html",
    "title": "Variational Inference",
    "section": "",
    "text": "Following the blog post https://willcrichton.net/notes/probabilistic-programming-under-the-hood/\n\nimport pyro.distributions as dist\nfrom pyro import sample\nimport torch\n\n\n# A fair coin flip\ncoinflip = sample(\"coinflip\", dist.Bernoulli(probs=0.5))\nprint(f'coinflip - {coinflip}')\n\n# Noisy sample\nnoisy_sample = sample(\"noisy_sample\", dist.Normal(loc=0, scale=1))\nprint(f'Noisy Sample - {noisy_sample}')\n\ncoinflip - 1.0\nNoisy Sample - -0.21278521418571472\n\n\n\ndef sleep_model():\n    # very likely to feel lazy\n    feeling_lazy = sample('feeling_lazy', dist.Bernoulli(0.9))\n    if feeling_lazy:\n        # only going to possibly ignore alarm if I am feeling lazy\n        ignore_alarm = sample('ignore_alarm', dist.Bernoulli(0.8))\n        # will sleep more if Ignore alarm\n        amount_slept = sample(f'amount_slept', dist.Normal(8 + 2*ignore_alarm, 1))\n    else:\n        amount_slept = sample('amount_slept', dist.Normal(6, 1))\n    return amount_slept\n\nprint(sleep_model())\nprint(sleep_model())\nprint(sleep_model())\n                              \n\ntensor(9.6567)\ntensor(8.2041)\ntensor(11.7966)"
  },
  {
    "objectID": "posts/2021-12-28-variational-inference.html#approximate-inference",
    "href": "posts/2021-12-28-variational-inference.html#approximate-inference",
    "title": "Variational Inference",
    "section": "Approximate Inference",
    "text": "Approximate Inference\nThe main idea is that instead of exactly computing the conditional probability distribution (or “posterior”) of interest, we can approximate it using a variety of techniques. Generally, these fall into two camps: sampling methods and variational methods. The CS 228 (Probabilistic Graphical Models at Stanford) course notes go in depth on both (sampling, Variational)\nEssentially, for sampling methods, you use algorithms that continually draw samples from a changing probability distribution until eventually they converge on the true posterior of interest. The time to convergence is not known ahead of time. For variational methods, you use a simpler function that can be optimized to match the true posterior using standard optimization techniques like gradient descent.\nWhere to use what? Please have a look at the original blog post.\n\nVariational inference 1: autodifferentiation\n\nnorm = dist.Normal(0, 1)\nx = sample('x', norm)\nx\n\ntensor(-0.8995)\n\n\nHowever, let’s say I know the value of x = 5 and I want to find a mean μ to the normal distribution that maximizes the probability of seeing that x. For that, we can use a parameter:\n\nfrom pyro import param\n\nmu = param(\"mu\", torch.tensor(0.0))\nnorm = dist.Normal(mu, 1)\nx = sample('x', norm)\n\nOur goal is to update mu such that the probability of the value 5 under the normal distribution norm is maximized.\n\nimport torch.nn as nn\nimport torch.distributions as dist\nfrom torch.optim import Adam\n\nclass NormalDistModel(nn.Module):\n    def __init__(self, mu):\n        super().__init__()\n        self.mu = nn.Parameter(torch.tensor(mu, dtype=torch.float32))\n        self.normal = dist.Normal(self.mu, 1)\n        \n    def forward(self):\n        return self.normal.log_prob(torch.tensor(5.0))\n        \n\nmodel = NormalDistModel(1)\nmodel.forward()\n\ntensor(-8.9189, grad_fn=&lt;SubBackward0&gt;)\n\n\n\n# lets now optimize the model to maximize the probabiliy of 5\noptimizer = Adam(model.parameters(), lr=0.01)\n\nmus = []\nlosses = []\nfor _ in range (1000):\n    # instead of maximizing the probablity, we minize the negative log of the probability\n    loss = -model.forward()\n    loss.backward()\n    \n    # update parameters\n    optimizer.step()\n    \n    # zero all parameter gradients so that they do not accumulate\n    optimizer.zero_grad()\n    \n    # record the mu and the and the loss\n    losses.append(loss.detach().item())\n    mus.append(model.mu.detach().item())\n    \n\n\ndf = pd.DataFrame({\"mu\": mus, \"loss\": losses})\ndf.plot(subplots=True)\n\narray([&lt;AxesSubplot:&gt;, &lt;AxesSubplot:&gt;], dtype=object)"
  },
  {
    "objectID": "posts/2021-12-23-la-column-spaces.html",
    "href": "posts/2021-12-23-la-column-spaces.html",
    "title": "MIT 18.065 Linear Algebra, Lecture 1",
    "section": "",
    "text": "How to view matrix multiplication?\n\\[\n\\begin{bmatrix}\n2 & 1 & 3 \\\\\n3 & 1 & 4 \\\\\n5 & 7 & 12\n\\end{bmatrix}{\\cdot}\n\\begin{bmatrix}\nx1 \\\\\nx2 \\\\\nx3\n\\end{bmatrix}\n\\]\nInstead of viewing it as a dot product, the output should be seen as a combination of column vectors in A\n\\[\n\\begin{bmatrix}\n2 \\\\ 3 \\\\ 5\n\\end{bmatrix}\nx1\n\\,+\\,\n\\begin{bmatrix}\n1 \\\\ 1 \\\\ 7\n\\end{bmatrix}\nx2\n\\,+\\,\n\\begin{bmatrix}\n3 \\\\ 4 \\\\ 12\n\\end{bmatrix}\nx3\n\\]\n\n\nBasis and Rank\nThe independent columns using which the other columns can be expressed as a combination of is known Basis for column space. The number of independent columns is known as Rank\n\\[\n\\begin{bmatrix}\n2 & 1 & 3 \\\\\n3 & 1 & 4 \\\\\n5 & 7 & 12\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n2 & 1 \\\\\n3 & 1 \\\\\n5 & 7\n\\end{bmatrix}\n\\begin{bmatrix}\n0 & 0 & 1 \\\\\n\\rowcolor{pink} 0 & 1 & 1 \\\\\n\\end{bmatrix}\n\\]"
  },
  {
    "objectID": "posts/2022-11-01-text-from-invoices.html",
    "href": "posts/2022-11-01-text-from-invoices.html",
    "title": "notes",
    "section": "",
    "text": "from transformers import AutoModelForTokenClassification, AutoProcessor\nfrom datasets import ClassLabel, Features, Sequence, Value, Array2D, Array3D, load_metric\nimport torch\nfrom transformers import LayoutLMv3ForTokenClassification\nfrom transformers.data.data_collator import default_data_collator\nfrom PIL import Image, ImageDraw, ImageFont\n\n\nprocesser = AutoProcessor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=True)\nmodel = AutoModelForTokenClassification.from_pretrained(\"microsoft/layoutlmv3-base\")\n\nSome weights of LayoutLMv3ForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n\n\n\ndigits = [5, 7, 2]\nfor idx in range(len(digits), 0, -1):\n    print(idx)\n    \n\n3\n2\n1\n\n\n\nfrom transformers import LayoutLMv2Model\nimport transformers\ntransformers.utils.import_utils._detectron2_available\n\nTrue\n\n\n\ntransformers.__version__\n\n'4.23.1'"
  },
  {
    "objectID": "posts/2023-02-19-deepseed.html",
    "href": "posts/2023-02-19-deepseed.html",
    "title": "notes",
    "section": "",
    "text": "This is notes from the ZeRO - Memory Optimization paper\nData Parallelism (DP) and Model Parallelism (MP) are two ways to parallelize training.\n\n\n\n\n\n\n\n\n\nData Parallel\nModel Parallel\n\n\n\n\nSplit\nData is split across multiple GPUs and each GPU contains a copy of the modes\nWe split the model across multiple GPUs. Each GPU contains a copy of the data.\n\n\nGradient Update\nGradients are averaged across GPUs and the model is updated.\n\n\n\nMemory Efficiency\nLow. Does not reduce the memory occupied by the model. Runs out of memory for models with more than 1.4B parameters.\nHigh\n\n\nCompute/communication efficiency\nHigh.\nLow. Works well within a single node, due to high inter-gpu communication\n\n\n\n\n\n\nimage from paper"
  },
  {
    "objectID": "posts/2022-10-25-transformers-from-scratch.html",
    "href": "posts/2022-10-25-transformers-from-scratch.html",
    "title": "Transformers from scratch in pytorch",
    "section": "",
    "text": "Notes from https://uvadlc-notebooks.readthedocs.io/en/latest/tutorial_notebooks/tutorial6/Transformers_and_MHAttention.html\n\n## Standard Libraries\nimport os\nfrom tracemalloc import Snapshot\nimport numpy as numpy\nimport random\nimport math\nimport json\nfrom functools import partial\nimport logging\nimport sys\n\n# imports for plotting\nimport matplotlib.pyplot as plt\nimport matplotlib_inline\nplt.set_cmap('cividis')\n%matplotlib inline\nmatplotlib_inline.backend_inline.set_matplotlib_formats()\nfrom matplotlib.colors import to_rgb\nimport matplotlib\nmatplotlib.rcParams['lines.linewidth'] = 2.0\nimport seaborn as sns\nsns.reset_orig()\n\nfrom tqdm.notebook import tqdm\n\n# pytorch\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import transforms\nimport pytorch_lightning as pl\nfrom pytorch_lightning.callbacks import LearningRateMonitor, ModelCheckpoint\n\n# others\nimport einops\n\n# path to folder where datasets should be downloaded\nDATASET_PATH = \"../data\"\nCHECKPOINT_PATH = \"../saved_models\"\n\n# setting the seed\npl.seed_everything(42)\n\n# Ensure that all operations are deterministirc on GPU\ntorch.backends.cudnn.deterministic = True\ntorch.backends.cudnn.benchmark = False\n\nlogging.basicConfig(stream=sys.stdout, level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\ndevice = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\nprint(\"Device: \", device)\n\nGlobal seed set to 42\n\n\nDevice:  cpu\n\n\n\nWhat is Attention?\nThe attention mechanism describes a weighted average of sequence of elements with the weights dynamically computed based on the input query and the element’s keys.\n As we can see above, Query, Key and Value are all just modified word embedding.\n\n\n\nimage\n\n\n(image from http://jalammar.github.io/illustrated-transformer/) #### Self-attention We use self-attention to modify each embedding of the input word as a combination of modified values from the word embedding and the weights computed. Some intuitions\n\nValues are nothing but modified word embeddings which will be weighted and given as outputs\nQuery is the modified word embedding which will search for relevant word embeddings in the sequence\nKeys are modified word embeddings which will be searched by the query to create the weights\nAs we are using dot product, we are essentially computing the cosine similarity between the query and the key. The higher the cosine similarity, the higher the weight.\n\nIf we look at the softmax scores, clearly the word at its own position will have the highest softmax score, but sometimes it’s useful to attend to another word that is relevant to the current word.\nLets look at the statement The animal didn't cross the street because it was too tired. In this case, softmax for ‘it’ will have a parts of itself, animal (more) and street (less)\nIn addition to attending to other parts of sentence, the softmax can also drown out the irrelvant words by multiplying them with a very small number.\n\n\n\nimage\n\n\n\n\nMulti Head Attention\nAn attention layer outputs a representation of the input sequence, based on the weights learnt for Query, Key and Value. We use multiple heads and combine them using a linear layer to get a better representation of the input sequence.\n\ndef scaled_dot_product(q, k, v, mask=None):\n    d_k = q.size()[-1]\n    attn_logits = torch.matmul(q, k.transpose(-2, -1))\n    attn_logits = attn_logits/math.sqrt(d_k) \n    if mask is not None:\n        attn_logits = attn_logits.masked_fill(mask==0, -9e15)\n    attention = F.softmax(attn_logits, dim=1)\n    values = torch.matmul(attention, v)\n    return values, attention\n\n\nseq_len, d_k = 3, 2\nq = torch.randn(seq_len, d_k)\nk = torch.randn(seq_len, d_k)\nv = torch.randn(seq_len, d_k)\nvalues, attention = scaled_dot_product(q, k, v)\nprint(\"Q\\n\", q.size())\nprint(\"K\\n\", k.size())\nprint(\"V\\n\", v.size())\nprint(\"Values\\n\", values.size())\nprint(\"Attention\\n\", attention.size())\n\nQ\n torch.Size([3, 2])\nK\n torch.Size([3, 2])\nV\n torch.Size([3, 2])\nValues\n torch.Size([3, 2])\nAttention\n torch.Size([3, 3])\n\n\n\nclass MultiHeadAttention(nn.Module):\n    def __init__(self, input_dim, embed_dim, num_heads, log_level=logging.INFO):\n        super().__init__()\n        assert embed_dim%num_heads == 0, \"Embedding dimension should be zero module with number of heads\"\n        self.embed_dim = embed_dim\n        self.num_heads = num_heads\n        self.head_dim = embed_dim//num_heads\n        # logging.getLogger().setLevel(logging.DEBUG)\n        self.logger = logging.getLogger(self.__class__.__name__)\n        # print(f'log_level - {log_level}')\n        self.logger.setLevel(log_level)\n\n        # stack all weight matrices 1...h together for efficiency\n        # Note that in many implemenations, you see bias=false, which is optional\n        self.qkv_proj = nn.Linear(input_dim, 3*embed_dim) \n        self.o_proj = nn.Linear(embed_dim, embed_dim)\n        self._reset_parameters()\n\n    def _reset_parameters(self):\n        # Orignial Transformer initialization\n        nn.init.xavier_uniform_(self.qkv_proj.weight)\n        self.qkv_proj.bias.data.fill_(0)\n        nn.init.xavier_uniform_(self.o_proj.weight)\n        self.o_proj.bias.data.fill_(0)\n\n    def forward(self, x, mask=None, return_attention=False):\n        batch_size, seq_length, _ = x.size()\n        qkv = self.qkv_proj(x)\n        self.logger.debug(f'x.shape - {x.size()}. qkv_proj.shape - {self.qkv_proj.weight.size()}')\n\n        # separate Q, K, V from the linear output\n        self.logger.debug(f'generated qkv.shape - {qkv.size()}')\n        qkv = qkv.reshape(batch_size, seq_length, self.num_heads, 3*self.head_dim)\n        self.logger.debug(f'reshaped qkv.shape - {qkv.size()}')\n        qkv = qkv.permute(0, 2, 1, 3) # [Batch, seqlen, Head, DIms ]\n        self.logger.debug(f'permuted qkv.shape - {qkv.size()}')\n        q, k, v = qkv.chunk(3, dim=-1)\n\n        # determine value outputs\n        values, attention = scaled_dot_product(q, k, v, mask=mask)\n        self.logger.debug(f'values.shape - {values.size()}. attension.shape - {attention.size()}')\n        values = values.permute(0, 2, 1, 3) # [Batch, seqlen, Head, dims]\n        self.logger.debug(f'values.shape after permute - {values.size()}')\n        values = values.reshape(batch_size, seq_length, self.embed_dim)\n        self.logger.debug(f'values.shape after reshape - {values.size()}')\n\n        o = self.o_proj(values)\n\n        if return_attention:\n            return o, attention\n        else:\n            return o\n\ninput_dim = 64\nembed_dim = 16\nbatch_size = 3\nseq_len = 10\nmulti_attention = MultiHeadAttention(input_dim, embed_dim, num_heads=4, log_level=logging.DEBUG)\nx = torch.randn(batch_size, seq_len, input_dim)\natt = multi_attention(x)\n\nDEBUG:MultiHeadAttention:x.shape - torch.Size([3, 10, 64]). qkv_proj.shape - torch.Size([48, 64])\nDEBUG:MultiHeadAttention:generated qkv.shape - torch.Size([3, 10, 48])\nDEBUG:MultiHeadAttention:reshaped qkv.shape - torch.Size([3, 10, 4, 12])\nDEBUG:MultiHeadAttention:permuted qkv.shape - torch.Size([3, 4, 10, 12])\nDEBUG:MultiHeadAttention:values.shape - torch.Size([3, 4, 10, 4]). attension.shape - torch.Size([3, 4, 10, 10])\nDEBUG:MultiHeadAttention:values.shape after permute - torch.Size([3, 10, 4, 4])\nDEBUG:MultiHeadAttention:values.shape after reshape - torch.Size([3, 10, 16])\n\n\n\nclass EncoderBlock(nn.Module):\n    def __init__(self, input_dim, num_heads, dim_feedforward, dropout=0.0):\n        super().__init__()\n\n        # attention layer\n        self.self_attn = MultiHeadAttention(input_dim, input_dim, num_heads)\n\n        # two layer MLP\n        self.linear_net = nn.Sequential(\n            nn.Linear(input_dim, dim_feedforward),\n            nn.Dropout(dropout),\n            nn.ReLU(inplace=True),\n            nn.Linear(dim_feedforward, input_dim)\n        )\n\n        # layers to apply inbetween main layers\n        self.norm1 = nn.LayerNorm(input_dim)\n        self.norm2 = nn.LayerNorm(input_dim)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, mask=None):\n        # Attention part\n        attn_out = self.self_attn(x, mask=mask)\n        x = x + self.dropout(attn_out)\n        x = self.norm1(x)\n\n        # MLP part\n        linear_out = self.linear_net(x)\n        x = x + self.dropout(linear_out)\n        x = self.norm2(x)\n\n        return x\n\nclass TransformerEncoder(nn.Module):\n    def __init__(self, num_layers, **block_args):\n        super().__init__()\n        self.layers = nn.ModuleList([EncoderBlock(**block_args) for _ in range(num_layers)])\n\n    def forward(self, x, mask=None):\n        for l in self.layers:\n            x = l(x, mask=mask)\n        return x\n    \n    def get_attention_maps(self, x, mask=None):\n        attention_maps = []\n        for l in self.layers:\n            _, attn_map = l.self_attn(x, mask=mask, return_attention=True)\n            attention_maps.append(attn_map)\n            x = l(x)\n        return attention_maps\n\n\nclass PositionalEncoding(nn.Module):\n    def __init__(self, d_model, max_len=5000):\n        super().__init__()\n\n        # create a matrix of seq_len, hidden_dim representing the positinal encoding for \n        pe = torch.zeros(max_len, d_model)\n\n        # position is index of the word in the sequence\n        position = torch.arange(0,  max_len, dtype=torch.float).unsqueeze(1)\n        \n        div_term = torch.exp(torch.arange(0, d_model, 2)) * -math.log(10000)/d_model\n        pe[:, 0::2] = torch.sin(position * div_term)\n        pe[:, 1::2] = torch.cos(position * div_term)\n        pe = pe.unsqueeze(0)\n\n        # register_buffer =&gt; tensor which is not a parameter, but shold be a part of the modules state\n        # used for tensors that need to be on the same device as the module\n        # persistent=False tell pytorch not to add the buffer to the state_dict\n        self.register_buffer('pe', pe, persistent=False)\n\n    def forward(self, x):\n        x = x + self.pe[:, :x.size(1)]\n        return x\n        \n        \n\n\n\n\n\\[\nf(n) =\n\\begin{cases}\nn/2,  & \\text{if $n$ is even} \\\\\n3n+1, & \\text{if $n$ is odd}\n\\end{cases}\n\\]\n\n\nPositional Encoding\nWe add a fixed signal (not trainable) to each word based on its position. The dimension of the PE signal is same is same as the word dimension.\n\\[\nPE_{(pos, i)} =\n\\begin{cases}\n    sin(\\frac{pos}{10000^{i/d_{model}}}),  & \\text{if $i$ mod 2 = 0}\\\\\n    cos(\\frac{pos}{10000^{i-1/d_{model}}}),  & \\text{otherwise}\n\\end{cases}\n\\]\nHere pos is the word position and i is the embedding position.\nFor a deeper intuition, look at - https://kazemnejad.com/blog/transformer_architecture_positional_encoding/ - https://towardsdatascience.com/master-positional-encoding-part-i-63c05d90a0c3"
  },
  {
    "objectID": "posts/2022-06-29-linear-algebra-notes.html",
    "href": "posts/2022-06-29-linear-algebra-notes.html",
    "title": "Properties of Eigen Values and Vectors",
    "section": "",
    "text": "import numpy as np\nimport seaborn as sns\n\n\nA symmetric matrix has real eigen values\n\n\n# create a symmetric matrix\ndef get_random_symmetrix_matrix(n=3):\n    a = np.random.randint(-10,10, (3,3))\n    return (a + a.transpose())/2\n\ns = get_random_symmetrix_matrix()\ns\n\narray([[-5. , -2.5, -2. ],\n       [-2.5, -9. ,  4.5],\n       [-2. ,  4.5,  3. ]])\n\n\n\nw, v = np.linalg.eig(s)\nw, v\n\n(array([  5.22047873,  -5.17812095, -11.04235778]),\n array([[-0.2587962 ,  0.91904091, -0.29730177],\n        [ 0.33248317, -0.20422367, -0.92073212],\n        [ 0.90690654,  0.3371298 ,  0.25271333]]))\n\n\n\n# check the magnitude of the first eigen vector. \nprint(np.dot(v[0], v[0]))\n\n# check the dot product. \nprint(np.dot(v[0], v[1]))\n\n# as dimension is one and dot product is close to zero, they are orthonormal\n\n1.0\n-1.520268617663237e-16\n\n\n\nPower method to find the dominant eigan value\nWe initialize a random vector x, usually 1s. We multiply ax and divide the output to make the\n\nerror = 0.001\nn = 3\n\ns = get_random_symmetrix_matrix(n)\nx = np.array([1.0] * n)\n\ndef get_dominant_eig_value(a):\n    eigs = []\n    eig_old = None\n    x = np.array([1.0] * a.shape[1])\n    while True:\n        x = np.matmul(a,x)\n        eig = np.max(np.abs(x))\n        x = x/eig\n        if eig_old and abs(eig - eig_old) &lt; error:\n            break\n        eig_old = eig\n        eigs.append(eig)\n    return (eig, eigs)\n  \ndom_eig, eigs = get_dominant_eig_value(s)\nprint(f'dominant eig is {dom_eig} in {len(eigs)} iterations with margin {error}')\n\nsns.scatterplot(x=range(len(eigs)), y=eigs)\n\ndominant eig is 11.085887005510221 in 6 iterations with margin 0.001\n\n\n\n\n\n\n\n\n\n\nnp.abs(\n\n\n  Input In [6]\n    np.abs(\n           ^\nSyntaxError: unexpected EOF while parsing"
  },
  {
    "objectID": "posts/2024-08-20-ollama-remote-mac.html",
    "href": "posts/2024-08-20-ollama-remote-mac.html",
    "title": "Local LLM Inference on Mac Mini",
    "section": "",
    "text": "I have a Mac Mini (16 GB, M1) running in my home network. I am exploring options available to run LLMs on it, so that it does not slow down my work laptop (which is a Macbook Air). I want to use the Mac GPU to maximize the inference speed.\nThe remote Mac Mini is configured as mini in /etc/hosts in my local host."
  },
  {
    "objectID": "posts/2024-08-20-ollama-remote-mac.html#ollama",
    "href": "posts/2024-08-20-ollama-remote-mac.html#ollama",
    "title": "Local LLM Inference on Mac Mini",
    "section": "Ollama",
    "text": "Ollama\n\nInstall and start Ollama\nDo these steps on the remote server\n# Install Ollama on the remote server\nbrew install ollama --cask\n\n# Set OLLAMA_HOST, so that the server can be accessible remotely \nexport OLLAMA_HOST='0.0.0.0'\n\n# Start Ollama\nollama serve\nOLLAMA_HOST can be added to the .bashrc or .zshrc to avoid setting it each time.\n\n\nOn Localhost\n\n1. Check that Ollama service is accessible\nUsing a browser, go to http://mini:11434. It should show the message “Ollama is running”\n\n\n2. Run the Web UI for Ollama\nWe can use https://github.com/open-webui/open-webui as UI for Ollama\ndocker run -d -p 3000:8080 -e OLLAMA_BASE_URL=http://mini:11434 -v open-webui:/app/backend/data --name open-webui \\\n    --restart always ghcr.io/open-webui/open-webui:main\nThe web UI can be accessible at http://localhost:3000\n\n\n\nTips\nSome tips and rants for running ollama - https://www.reddit.com/r/LocalLLaMA/comments/1e9hju5/ollama_site_pro_tips_i_wish_my_idiot_self_had/"
  },
  {
    "objectID": "posts/2024-08-20-ollama-remote-mac.html#llama.cpp-compatible-with-openai",
    "href": "posts/2024-08-20-ollama-remote-mac.html#llama.cpp-compatible-with-openai",
    "title": "Local LLM Inference on Mac Mini",
    "section": "Llama.cpp (Compatible with OpenAI)",
    "text": "Llama.cpp (Compatible with OpenAI)\nInstall and run llama.cpp server\n# install llama-cpp-python server with Metal \nCMAKE_ARGS=\"-DGGML_METAL=on\" FORCE_CMAKE=1 pip install --force-reinstall --no-cache-dir 'llama-cpp-python[server]'\n\n# start the llama.cpp server with a single model\npython3 -m llama_cpp.server --hf_model_repo_id bartowski/Meta-Llama-3.1-8B-Instruct-GGUF --model '*Q6_K_L.gguf' --chat_format llama-3 --host 0.0.0.0\nUse completion api.\n\nPythonShell\n\n\nimport openai\n\nclient = openai.OpenAI(\n    base_url = \"http://mini:8000/v1/\",\n    api_key='dummy'\n)\n\nmessages = [{\"role\": \"user\", \"content\": \"Tell me a joke\"}]\nchat_completion = client.chat.completions.create(messages=messages, model=\"dummy\")\n\nresponse_txt = chat_completion.choices[0].message.content\nprint(response_txt)\n\n\n# call chat completion to test\ncurl -s http://mini:8000/v1/chat/completions \\\n  -H \"Content-Type: application/json\" \\\n  -d '{\n   \"messages\": [\n      {\"role\": \"user\", \"content\": \"Tell me a joke\"}\n   ]\n }' | jq .\n\n\n\nNote that the api_key and model are set to be ‘dummy’. They can be any value, as they are not used.\nFrom the server logs, we can see that eval time tokens per second is 8.81."
  },
  {
    "objectID": "posts/2022-01-10-sklearn-2.html",
    "href": "posts/2022-01-10-sklearn-2.html",
    "title": "Sklearn - Adult Income Classificat",
    "section": "",
    "text": "Repeating content from http://appliedprogramming.net/machine-learning/adult-income-classification.html\n\nimport os\nimport urllib\nfrom urllib.request import urlretrieve\nfrom pathlib import Path\n\nfrom sklearn.tree import DecisionTreeClassifier, export_graphviz\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom time import time\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import roc_auc_score, classification_report\n\n\n# download the data\nbase_url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/adult'\nfilename = 'adult.data'\nurlretrieve(f'{base_url}/{filename}', f'{filename}')\n\n('adult.data', &lt;http.client.HTTPMessage at 0x7fe9c7480e10&gt;)\n\n\n\ncols = [\"Age\", \"Work-Class\", \"fnlwgt\", \"Education\", \"Education-Num\", \"Marital-Status\", \"Occupation\", \n        \"Relationship\", \"Race\", \"Sex\", \"Capital-gain\", \"Capital-loss\", \"Hours-per-week\", \"Native-Country\", \"Earnings-Raw\"]\ndf = pd.read_csv(filename, header=None, names=cols)\nprint(f'df.shape - {df.shape}')\ndf.head(3)\n\ndf.shape - (32561, 15)\n\n\n\n\n\n\n\n\n\nAge\nWork-Class\nfnlwgt\nEducation\nEducation-Num\nMarital-Status\nOccupation\nRelationship\nRace\nSex\nCapital-gain\nCapital-loss\nHours-per-week\nNative-Country\nEarnings-Raw\n\n\n\n\n0\n39\nState-gov\n77516\nBachelors\n13\nNever-married\nAdm-clerical\nNot-in-family\nWhite\nMale\n2174\n0\n40\nUnited-States\n&lt;=50K\n\n\n1\n50\nSelf-emp-not-inc\n83311\nBachelors\n13\nMarried-civ-spouse\nExec-managerial\nHusband\nWhite\nMale\n0\n0\n13\nUnited-States\n&lt;=50K\n\n\n2\n38\nPrivate\n215646\nHS-grad\n9\nDivorced\nHandlers-cleaners\nNot-in-family\nWhite\nMale\n0\n0\n40\nUnited-States\n&lt;=50K\n\n\n\n\n\n\n\n\ndf.replace([' &lt;=50K', ' &gt;50K'], [0, 1], inplace=True)\ndf.dropna(how='all', inplace=True)\n\n\nSelecting K Best features\n\nx_cols = [\"Age\", \"Education-Num\", \"Capital-gain\", \"Capital-loss\", \"Hours-per-week\"]\nx_train_np = df[x_cols].values\ny_train_np = df['Earnings-Raw'].values\n\nprint(f'x_train_np.shape - {x_train_np.shape}. y_train_np.shape - {y_train_np.shape}')\n\nx_train_np.shape - (32561, 5). y_train_np.shape - (32561,)\n\n\nNow we create our transfomer using the chi2 function and a SelectKBest transformer\n\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import chi2\n\ntransformer = SelectKBest(score_func=chi2, k=3)\n\nThis will create a new dataset with reduced number of features\n\nx_chi2_train_np = transformer.fit_transform(x_train_np, y_train_np)\nprint(f'x_chi2_train_np.shape - {x_chi2_train_np.shape}')\nprint(f'chi square scores - {transformer.scores_}')\nprint(f'selected columns are {np.argsort(transformer.scores_)[-3:]}')\n\nx_chi2_train_np.shape - (32561, 3)\nchi square scores - [0.2340371  0.33515395 0.22332882 0.15052631 0.22968907]\nselected columns are [4 0 1]\n\n\nWe could also implement other correlations such as Pearsons correlation coefficient. As the default scipy pearsonr function accepts only a one dimensional array, we will create a wrapper around it.\n\nfrom scipy.stats import pearsonr\n\ndef multivariate_pearsonr(x, y):\n    scores, pvalues = [], []\n    for column in range(x.shape[1]):\n        cur_score, cur_p = pearsonr(x[:, column], y)\n        scores.append(abs(cur_score))\n        pvalues.append(cur_p)\n    return (np.array(scores),np.array(pvalues))\n\nThe pearson value could be between -1 and 1.\n\ntransformer = SelectKBest(score_func=multivariate_pearsonr, k=3)\nx_pearson_train_np = transformer.fit_transform(x_train_np, y_train_np)\nprint(transformer.scores_)\nprint(f'selected columns are {np.argsort(transformer.scores_)[-3:]}')\n\n[0.2340371  0.33515395 0.22332882 0.15052631 0.22968907]\nselected columns are [4 0 1]\n\n\nLet us now fit the classifier\n\nfrom sklearn.tree import DecisionTreeClassifier\n\nclf = DecisionTreeClassifier()\nscores_chi2 = cross_val_score(clf, x_chi2_train_np, y_train_np, scoring='accuracy')\nscores_pearson = cross_val_score(clf, x_pearson_train_np, y_train_np, scoring='accuracy')\n\nprint(\"Chi2 performance: {0:.3f}\".format(scores_chi2.mean()))\nprint(\"Pearson performance: {0:.3f}\".format(scores_pearson.mean()))\n\nChi2 performance: 0.773\nPearson performance: 0.773\n\n\nUnlike in the blog, we got the same output for selectkbest. Hence the performance is same for both\n\n\nPrincipal Component Analysis\n\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=5)\nxd = pca.fit_transform(x_train_np)\nprint(f'xd.shape - {xd.shape}')\n\nnp.set_printoptions(precision=3, suppress=True)\npca.explained_variance_ratio_\n\nxd.shape - (32561, 5)\n\n\narray([0.997, 0.003, 0.   , 0.   , 0.   ])\n\n\nThis shows us that the first feature accounts for 99.7 percent of the variance in the dataset\n\n# fit with full dataset\nclf = DecisionTreeClassifier(random_state=14)\noriginal_scores = cross_val_score(clf, x_train_np, y_train_np, scoring='accuracy')\n\nprint(\"The average score from the original dataset is {:.4f}\".format(np.mean(original_scores)))\n\n# fit with reduced features \n\nThe average score from the original dataset is 0.8131\n\n\n\nx_train_np.shape\n\n(32561, 5)\n\n\nLets convert the categorical features into numeric values\n\ncategorical_features = []\nfor col in df.columns:\n    if df[col].dtype != np.int64:\n        categorical_features.append(col)\n        \ncategorical_features\n\n['Work-Class',\n 'Education',\n 'Marital-Status',\n 'Occupation',\n 'Relationship',\n 'Race',\n 'Sex',\n 'Native-Country']"
  },
  {
    "objectID": "posts/2021-11-22-01-the-machine-learning-landscape.html",
    "href": "posts/2021-11-22-01-the-machine-learning-landscape.html",
    "title": "Hands - on ML. Chapter 1",
    "section": "",
    "text": "import sys, os\nimport sklearn\nimport urllib.request\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport random\n\n# matplotlib\nimport matplotlib\nmatplotlib.rc('axes', labelsize=14),\nmatplotlib.rc('xtick', labelsize=12)\nmatplotlib.rc('ytick', labelsize=12)\nprint(f'sklearn_version - {sklearn.__version__}')\nimport seaborn as sns\n\nsklearn_version - 0.24.2\n\n\n\n# just copying it from github. Prepreocessing code\ndef prepare_country_stats(oecd_bli, gdp_per_capita):\n    oecd_bli = oecd_bli[oecd_bli[\"INEQUALITY\"]==\"TOT\"]\n    oecd_bli = oecd_bli.pivot(index=\"Country\", columns=\"Indicator\", values=\"Value\")\n    gdp_per_capita.rename(columns={\"2015\": \"GDP per capita\"}, inplace=True)\n    gdp_per_capita.set_index(\"Country\", inplace=True)\n    full_country_stats = pd.merge(left=oecd_bli, right=gdp_per_capita,\n                                  left_index=True, right_index=True)\n    full_country_stats.sort_values(by=\"GDP per capita\", inplace=True)\n    remove_indices = [0, 1, 6, 8, 33, 34, 35]\n    keep_indices = list(set(range(36)) - set(remove_indices))\n    return full_country_stats[[\"GDP per capita\", 'Life satisfaction']].iloc[keep_indices]\n\n\n!curl https://raw.githubusercontent.com/ageron/handson-ml2/master/oecd_bli_2015.csv\n\n404: Not Found\n\n\n\n# download the data\nDOWNLOAD_ROOT =  \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\ndatapath = Path('datasets/lifesat')\ndatapath.mkdir(exist_ok=True, parents=True )\n\nfor filename in (\"oecd_bli_2015.csv\", \"gdp_per_capita.csv\"):\n    url = '/'.join([DOWNLOAD_ROOT, 'datasets/lifesat',filename])\n    filepath = (datapath/filename).resolve()\n    print(f'downloading from {url}')\n    urllib.request.urlretrieve(url, filepath)\n\ndownloading from https://raw.githubusercontent.com/ageron/handson-ml2/master//datasets/lifesat/oecd_bli_2015.csv to /home/achinta/machine-learning/books/handson-ml2/datasets/lifesat/oecd_bli_2015.csv\ndownloading from https://raw.githubusercontent.com/ageron/handson-ml2/master//datasets/lifesat/gdp_per_capita.csv to /home/achinta/machine-learning/books/handson-ml2/datasets/lifesat/gdp_per_capita.csv\n\n\n\nPlot the data\n\noecd_bli = pd.read_csv(datapath/'oecd_bli_2015.csv', thousands=',')\ngdp_per_capita = pd.read_csv(datapath/'gdp_per_capita.csv', thousands=',', delimiter='\\t', encoding='latin1', na_values='n/a')\ncountry_stats = prepare_country_stats(oecd_bli, gdp_per_capita)\nprint(f'country stats.shape - {country_stats.shape}')\n\n# show the data in a plot\nfig, ax = plt.subplots(figsize=(8,4))\nsns.scatterplot(x=country_stats['GDP per capita'], y=country_stats['Life satisfaction'], ax=ax)\n\n# lets annotate a few examples\nidxs = random.sample(range(country_stats.shape[0]), k=5)\nfor idx in idxs:\n    row = country_stats.iloc[idx]\n    plt.annotate(row.name, xy=(row['GDP per capita'], row['Life satisfaction']), \n                 arrowprops=dict(facecolor='black', width=0.5, shrink=0.1, headwidth=5),\n                xytext=(row['GDP per capita'],row['Life satisfaction'] - 0.5 ))\n\nplt.show()\n\ncountry stats.shape - (29, 2)\n\n\n\n\n\n\n\n\n\n\n\nmodel\n\nimport sklearn.linear_model\n\nx=country_stats['GDP per capita'].values\ny=country_stats['Life satisfaction'].values\n                                                   \nmodel = sklearn.linear_model.LinearRegression()\nmodel.fit(x[:, np.newaxis], y)\n\nLinearRegression()\n\n\n\n# Make a prediction for Cyprus\nX_new = [[22587]]  # Cyprus' GDP per capita\nprint(model.predict(X_new)) # outputs [[ 5.96242338]]\n\n[5.96242338]"
  },
  {
    "objectID": "posts/2022-01-16-movie-recommender-pytorch.html",
    "href": "posts/2022-01-16-movie-recommender-pytorch.html",
    "title": "Movie Recommender using pytorch",
    "section": "",
    "text": "import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport pytorch_lightning as pl\nimport numpy as np\nimport pandas as pd\n\n\n# !wget https://files.grouplens.org/datasets/movielens/ml-100k.zip\n# !unzip ml-100k.zip\n\n\n# read movie ratings\nratings_cols = ['user_id', 'item_id', 'rating', 'timestamp']\nratings_train_df = pd.read_csv('ml-100k/u1.base', sep='\\t', header=None)\nratings_train_df.columns = ratings_cols\nprint(f'ratings_train_df.shape \\t - {ratings_train_df.shape}')\n\nratings_test_df = pd.read_csv('ml-100k/u1.test', sep='\\t', header=None)\nratings_test_df.columns = ratings_cols\nprint(f'ratings_test_shape \\t - {ratings_test_df.shape}')\n\nratings_train_df.head(2)\n\nratings_train_df.shape   - (80000, 4)\nratings_test_shape   - (20000, 4)\n\n\n\n\n\n\n\n\n\nuser_id\nitem_id\nrating\ntimestamp\n\n\n\n\n0\n1\n1\n5\n874965758\n\n\n1\n1\n2\n3\n876893171\n\n\n\n\n\n\n\n\n# read movie data\nmovies_df = pd.read_csv('ml-100k/u.item', sep='|', header=None)\nprint(f'users_df.shape - {movies_df.shape}')\nmovie_cols = ['movie_id','title', 'release_date', 'video_release_date', 'imdb_url', 'unknown',\n             'action', 'adventure', 'animation', 'childrens', 'comedy', 'crime', 'documentary', \n             'drama', 'fantasy','film-noir', 'horror', 'musical','mystery', 'romance', \n             'scifi', 'thriller', 'war', 'western']\nmovies_df.columns = movie_cols\nmovies_df.head(2)\n\nusers_df.shape - (1682, 24)\n\n\n\n\n\n\n\n\n\nmovie_id\ntitle\nrelease_date\nvideo_release_date\nimdb_url\nunknown\naction\nadventure\nanimation\nchildrens\n...\nfantasy\nfilm-noir\nhorror\nmusical\nmystery\nromance\nscifi\nthriller\nwar\nwestern\n\n\n\n\n0\n1\nToy Story (1995)\n01-Jan-1995\nNaN\nhttp://us.imdb.com/M/title-exact?Toy%20Story%2...\n0\n0\n0\n1\n1\n...\n0\n0\n0\n0\n0\n0\n0\n0\n0\n0\n\n\n1\n2\nGoldenEye (1995)\n01-Jan-1995\nNaN\nhttp://us.imdb.com/M/title-exact?GoldenEye%20(...\n0\n1\n1\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n1\n0\n0\n\n\n\n\n2 rows × 24 columns\n\n\n\n\n# read user data\nusers_df = pd.read_csv('ml-100k/u.user', sep='|', header=None)\nuser_cols = ['user_id', 'age', 'gender', 'occupation', 'zip_code']\nusers_df.columns = user_cols\nusers_df.head(2)\n\n\n\n\n\n\n\n\nuser_id\nage\ngender\noccupation\nzip_code\n\n\n\n\n0\n1\n24\nM\ntechnician\n85711\n\n\n1\n2\n53\nF\nother\n94043\n\n\n\n\n\n\n\n\nReferences\nhttps://yonigottesman.github.io/recsys/pytorch/elasticsearch/2020/02/18/fm-torch-to-recsys.html"
  },
  {
    "objectID": "posts/2024-05-27-exploring-dspy-1.html",
    "href": "posts/2024-05-27-exploring-dspy-1.html",
    "title": "Exploring Dspy - part 1",
    "section": "",
    "text": "I have a read a lot about the capabilites of the dspy library from stanford. I am trying to understand its various capabilities. Let start with the https://github.com/stanfordnlp/dspy/blob/main/intro.ipynb. My comments will be highlighted in red\n\nimport dspy\nimport os\nfrom IPython.display import display, HTML\n!pip show dspy-ai | grep Version\n\nVersion: 2.4.9\n\n\n\n\nWe are using groq inference as it is much cheaper and faster than openai\n\nlm = dspy.GROQ(api_key=os.getenv('GROQ_API_KEY'), model='llama3-8b-8192')\n# this is the retriver given in the dspy documentation\nretriever = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\ndspy.settings.configure(lm=lm, rm=retriever)\n\n\n# helper functions to print in color\ndef color_html(s, color='black'):\n    '''returns a string with the given color in html format'''\n    s = s.replace('\\n', '&lt;br&gt;')\n    return \"&lt;text style=color:{}&gt;{}&lt;/text&gt;\".format(color, s)\n\ndef cprint(s, color='black'):\n    '''prints a string with the given color'''\n    display(HTML(color_html(s, color)))\n\ndef print_prompt(lm, idx=-1):\n    cprint(lm.history[idx]['prompt'], color='blue')\n\ndef print_response(lm, idx=-1):\n    cprint(lm.history[idx]['response'], color='green')\n\nWhatever the task, the general workflow is:\n\nCollect a little bit of data. Define examples of the inputs and outputs of your program (e.g., questions and their answers). This could just be a handful of quick examples you wrote down. If large datasets exist, the more the merrier!\nWrite your program. Define the modules (i.e., sub-tasks) of your program and the way they should interact together to solve your task.\nDefine some validation logic. What makes for a good run of your program? Maybe the answers need to have a certain length or stick to a particular format? Specify the logic that checks that.\nCompile! Ask DSPy to compile your program using your data. The compiler will use your data and validation logic to optimize your program (e.g., prompts and modules) so it’s efficient and effective! We will attempt to understand what this means. How are prompts and modules optimized?\nIterate. Repeat the process by improving your data, program, validation, or by using more advanced features of the DSPy compiler.\n\n\n\n\n\n\nfrom dspy.datasets import HotPotQA\ndataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0)\n\n# tell DSPy that the question field is the one we want to use (from all the fields in the dataset)\ntrainset = [x.with_inputs('question') for x in dataset.train]\ndevset = [x.with_inputs('question') for x in dataset.dev]\n\nlen(trainset), len(devset)\n\n/Users/achinta/miniforge3/envs/deepsql/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n  table = cls._concat_blocks(blocks, axis=0)\n\n\n(20, 50)\n\n\nWe just loaded trainset(20 examples) and devset(50 examples). Lets look at some examples from the trainset.\n\ntrain_example = trainset[0]\nprint(f\"Question: {train_example.question}\")\nprint(f\"Answer: {train_example.answer}\")\n\n# select a train example and a dev example\ntrain_example = trainset[0]\ndev_example = devset[18]\n\nQuestion: At My Window was released by which American singer-songwriter?\nAnswer: John Townes Van Zandt\n\n\n\nclass BasicQA(dspy.Signature):\n    '''Answers questions with short factoid answers'''\n    question = dspy.InputField()\n    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n\n# define predictor\ngenerate_answer = dspy.Predict(BasicQA)\n# call the predictor on the particular input\npred = generate_answer(question=dev_example.question)\n\n# print the inpput and the prediction\nprint(f\"Question: {dev_example.question}\")\nprint(f\"Prediction: {pred.answer}\")\n\nQuestion: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\nPrediction: Robert Irvine\n\n\n\nlm.history[-1]\n\n{'prompt': \"Answers questions with short factoid answers\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\nReasoning: Let's think step by step in order to ${produce the answer}. We ...\\nAnswer: often between 1 and 5 words\\n\\n---\\n\\nQuestion: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\\nReasoning: Let's think step by step in order to\",\n 'response': \"Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\\nReasoning: Let's think step by step in order to figure out the nationality of the chef. He is an American chef and restaurateur, and the show is set in the United States. Therefore...\\nAnswer: American\",\n 'kwargs': {'temperature': 0.0,\n  'max_tokens': 150,\n  'top_p': 1,\n  'frequency_penalty': 0,\n  'presence_penalty': 0,\n  'n': 1,\n  'model': 'llama3-8b-8192',\n  'messages': [{'role': 'user',\n    'content': \"Answers questions with short factoid answers\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\nReasoning: Let's think step by step in order to ${produce the answer}. We ...\\nAnswer: often between 1 and 5 words\\n\\n---\\n\\nQuestion: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\\nReasoning: Let's think step by step in order to\"}]},\n 'raw_kwargs': {}}\n\n\nLets now look at the prompt and the response\n\nprint_prompt(lm)\nprint_response(lm)\n\nAnswers questions with short factoid answers---Follow the following format.Question: ${question}Answer: often between 1 and 5 words---Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?Answer:\n\n\nRobert Irvine\n\n\n Let us use chain-of-thought. We can do that by creating a ChainOfThought class from any signature. \n\n# Define the predictor. Notice we're just changing the class. The signature BasicQA is unchanged.\ngenerate_answer_with_cot = dspy.ChainOfThought(BasicQA)\n\n# call the predictor on the particular input\npred = generate_answer_with_cot(question=dev_example.question)\n\nprint(f\"Question: {dev_example.question}\")\nprint(f\"Thought: {pred.rationale.split('.', 1)[1].strip()}\")\nprint(f\"Predicted Answer: {pred.answer}\")\n\nQuestion: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\nThought: He is an American chef and restaurateur, and the show is set in the United States. Therefore...\nPredicted Answer: American\n\n\nLets now look at the prompt and the response for ChainOfThought\n\nprint(f\"number of LLM calls till now - {len(lm.history)}\")\nprint_prompt(lm)\nprint_response(lm)\n\nnumber of LLM calls till now - 2\n\n\nAnswers questions with short factoid answers---Follow the following format.Question: ${question}Reasoning: Let's think step by step in order to ${produce the answer}. We ...Answer: often between 1 and 5 words---Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?Reasoning: Let's think step by step in order to\n\n\nQuestion: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?Reasoning: Let's think step by step in order to find the answer. We know that the show is a reality TV series that helps struggling restaurants, and the chef and restaurateur is Robert Irvine. He is a British chef.Answer: British\n\n\nThe Reasoning variable is included in the prompt by the class dspy.ChainOfThought. (check the code)  How is the prompt able to generate completions for multiple output variables (say Reasoning and answer) in the same prompt?  Or is it? The prompt cleverly stops after Reasoning: Let's think step by step in order to and the response is generated for  Reasoning as well as the answer\nWhen the LLM is able to generate only plain text completion, how are we able to populate output variables in the Predictions class?\n\n\n\n\nretrieve = dspy.Retrieve(k=3)\ntopK_passages = retrieve(dev_example.question).passages\n\nfor idx, passage in enumerate(topK_passages):\n    print(f'{idx+1}]', passage, '\\n')\n\n1] Restaurant: Impossible | Restaurant: Impossible is an American reality television series, featuring chef and restaurateur Robert Irvine, that aired on Food Network from 2011 to 2016. \n\n2] Jean Joho | Jean Joho is a French-American chef and restaurateur. He is chef/proprietor of Everest in Chicago (founded in 1986), Paris Club Bistro & Bar and Studio Paris in Chicago, The Eiffel Tower Restaurant in Las Vegas, and Brasserie JO in Boston. \n\n3] List of Restaurant: Impossible episodes | This is the list of the episodes for the American cooking and reality television series \"Restaurant Impossible\", produced by Food Network. The premise of the series is that within two days and on a budget of $10,000, celebrity chef Robert Irvine renovates a failing American restaurant with the goal of helping to restore it to profitability and prominence. Irvine is assisted by a designer (usually Taniya Nayak, Cheryl Torrenueva, or Lynn Keagan, but sometimes Vanessa De Leon, Krista Watterworth, Yvette Irene, or Nicole Faccuito), along with general contractor Tom Bury, who sometimes does double duty as both general contractor and designer. After assessing the problems with the restaurant, Robert Irvine typically creates a plan for the new decor, oversees the cleaning of the restaurant, reduces the size of the menu and improves the food, develops a promotional activity, educates the restaurant's owners, or trains the staff, as needed by each restaurant. \n\n\n\n\n\n\nLet’s define our first complete program for this task. We’ll build a retrieval-augmented pipeline for answer generation.\nGiven a question, we’ll search for the top-3 passages in Wikipedia and then feed them as context for answer generation.\nLet’s start by defining this signature: context, question --&gt; answer.\n\nclass GenerateAnswer(dspy.Signature):\n    \"\"\"Answers questions with short factoid answers\"\"\"\n\n    context = dspy.InputField(desc='may contain relevant facts')\n    question = dspy.InputField()\n    answer = dspy.OutputField(desc='often between 1 and 5 words')\n\nclass RAG(dspy.Module):\n    def __init__(self, num_passages=3):\n        super().__init__()\n\n        self.retrieve = dspy.Retrieve(k=num_passages)\n        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n    \n    def forward(self, question):\n        context = self.retrieve(question).passages\n        prediction = self.generate_answer(context=context, question=question)\n        return dspy.Prediction(context=context, answer=prediction.answer)\n\nHaving defined this program, let’s now compile it. Compiling a program will update the parameters stored in each module. In our setting, this is primarily in the form of collecting and selecting good demonstrations for inclusion in your prompt(s).\nCompiling depends on three things:\n\nA training set. We’ll just use our 20 question–answer examples from trainset above.\nA metric for validation. We’ll define a quick validate_context_and_answer that checks that the predicted answer is correct. It’ll also check that the retrieved context does actually contain that answer.\nA specific teleprompter. The DSPy compiler includes a number of teleprompters that can optimize your programs.\n\nTeleprompters: Teleprompters are powerful optimizers that can take any program and learn to bootstrap and select effective prompts for its modules. Hence the name, which means “prompting at a distance”.\nDifferent teleprompters offer various tradeoffs in terms of how much they optimize cost versus quality, etc. We will use a simple default BootstrapFewShot in this notebook.\nIf you’re into analogies, you could think of this as your training data, your loss function, and your optimizer in a standard DNN supervised learning setup. Whereas SGD is a basic optimizer, there are more sophisticated (and more expensive!) ones like Adam or RMSProp.\n\nfrom dspy.teleprompt import BootstrapFewShot\n\n# Validation logic: check that the predicted answer is correct.\n# Also check that the retrieved context does actually contain that answer.\ndef validate_context_and_answer(example, pred, trace=None):\n    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n    return answer_EM and answer_PM\n\n# Set up a basic teleprompter, which will compile our RAG program.\nteleprompter = BootstrapFewShot(metric=validate_context_and_answer, metric_threshold=None)\n\n# Compile!\ncompiled_rag = teleprompter.compile(student=RAG(), trainset=trainset)\n\n  0%|          | 0/20 [00:00&lt;?, ?it/s]0.00s - Debugger warning: It seems that frozen modules are being used, which may\n0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n0.00s - to python to disable frozen modules.\n0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n 55%|█████▌    | 11/20 [01:01&lt;00:49,  5.55s/it]\n\n\n What does compiling actually do?  - Here we want to teach the student (the RAG model) to learn something from samples from the trainset.  - We make a copy of the student and the techer using reset_copy() method, which uses deepcopy and resets any parameters in studen or teacher  - Here the teacher is the compiled LabeledFewShot, which is nothing but selecting k (default=16) samples from the trainset.  - We set the metric_threshold to None, so we are just ignoring the result of validate_context_and_answer and just selecting all the examples.  - So let us now see what is the result of the compilation below. We can see all the 16 examples added as demos to the student RAG module. \n\n\ncompiled_rag.save('rag_model.json')\ncompiled_rag.dump_state()\n\n{'retrieve': {'k': 3},\n 'generate_answer': {'lm': None,\n  'traces': [],\n  'train': [],\n  'demos': [Example({'augmented': True, 'context': ['Tae Kwon Do Times | Tae Kwon Do Times is a magazine devoted to the martial art of taekwondo, and is published in the United States of America. While the title suggests that it focuses on taekwondo exclusively, the magazine also covers other Korean martial arts. \"Tae Kwon Do Times\" has published articles by a wide range of authors, including He-Young Kimm, Thomas Kurz, Scott Shaw, and Mark Van Schuyver.', \"Kwon Tae-man | Kwon Tae-man (born 1941) was an early Korean hapkido practitioner and a pioneer of the art, first in Korea and then in the United States. He formed one of the earliest dojang's for hapkido in the United States in Torrance, California, and has been featured in many magazine articles promoting the art.\", 'Hee Il Cho | Cho Hee Il (born October 13, 1940) is a prominent Korean-American master of taekwondo, holding the rank of 9th \"dan\" in the martial art. He has written 11 martial art books, produced 70 martial art training videos, and has appeared on more than 70 martial arts magazine covers. Cho won several national and international competitions as a taekwondo competitor, and has appeared in several films, including \"Fight to Win\", \"Best of the Best\", \"Bloodsport II\", and \"Bloodsport III\". He founded the Action International Martial Arts Association (AIMAA) in 1980, and is its President. Cho is a member of both \"Black Belt\" magazine\\'s Hall of Fame and \"Tae Kwon Do Times\" magazine\\'s Hall of Fame.'], 'question': 'Which magazine has published articles by Scott Shaw, Tae Kwon Do Times or Southwest Art?', 'rationale': 'produce the answer. We can look at the context provided, which mentions that \"Tae Kwon Do Times\" has published articles by a wide range of authors, including Scott Shaw. Therefore, the correct answer is:', 'answer': 'Tae Kwon Do Times'}) (input_keys=None),\n   Example({'augmented': True, 'context': ['Rosario Dawson | Rosario Isabel Dawson (born May 9, 1979) is an American actress, producer, singer, comic book writer, and political activist. She made her film debut in the 1995 teen drama \"Kids\". Her subsequent film roles include \"He Got Game\", \"Men in Black II\", \"25th Hour\", \"Rent\", \"Sin City\", \"Death Proof\", \"Seven Pounds\", \"\", and \"Top Five\". Dawson has also provided voice-over work for Disney and DC.', 'Sarai Gonzalez | Sarai Isaura Gonzalez (born 2005) is an American Latina child actress who made her professional debut at the age of 11 on the Spanish-language \"\"Soy Yo\"\" (\"That\\'s Me\") music video by Bomba Estéreo. Cast as a \"nerdy\" tween with a \"sassy\" and \"confident\" attitude, her performance turned her into a \"Latina icon\" for \"female empowerment, identity and self-worth\". She subsequently appeared in two get out the vote videos for Latinos in advance of the 2016 United States elections.', 'Gabriela (2001 film) | Gabriela is a 2001 American romance film, starring Seidy Lopez in the title role alongside Jaime Gomez as her admirer Mike. The film has been cited as an inspiration behind the Premiere Weekend Club, which supports Latino film-making.'], 'question': 'Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?', 'rationale': 'produce the answer. We can look at the context provided, which mentions Rosario Dawson, an American actress who made her film debut in the 1995 teen drama \"Kids\".', 'answer': 'Rosario Dawson'}) (input_keys=None),\n   Example({'augmented': True, 'context': ['Battle of Kursk | The Battle of Kursk was a Second World War engagement between German and Soviet forces on the Eastern Front near Kursk (450 km south-west of Moscow) in the Soviet Union during July and August 1943. The battle began with the launch of the German offensive, Operation Citadel (German: \"Unternehmen Zitadelle\" ), on 5 July, which had the objective of pinching off the Kursk salient with attacks on the base of the salient from north and south simultaneously. After the German offensive stalled on the northern side of the salient, on 12 July the Soviets commenced their Kursk Strategic Offensive Operation with the launch of Operation Kutuzov (Russian: Кутузов ) against the rear of the German forces in the northern side. On the southern side, the Soviets also launched powerful counterattacks the same day, one of which led to a large armoured clash, the Battle of Prokhorovka. On 3 August, the Soviets began the second phase of the Kursk Strategic Offensive Operation with the launch of Operation Polkovodets Rumyantsev (Russian: Полководец Румянцев ) against the German forces in the southern side of the Kursk salient.', 'Operation Mars | Operation Mars, also known as the Second Rzhev-Sychevka Offensive Operation (Russian: Вторая Ржевско-Сычёвская наступательная операция), was the codename for an offensive launched by Soviet forces against German forces during World War II. It took place between 25 November and 20 December 1942 around the Rzhev salient in the vicinity of Moscow.', 'Kholm Pocket | The Kholm Pocket (German: \"Kessel von Cholm\" ; Russian: Холмский котёл ) was the name given for the encirclement of German troops by the Red Army around Kholm south of Leningrad, during World War II on the Eastern Front, from 23 January 1942 until 5 May 1942. A much larger pocket was simultaneously surrounded in Demyansk, about 100 km to the northeast. These were the results of German retreat following their defeat during the Battle of Moscow.'], 'question': 'What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?', 'rationale': 'produce the answer. We can look at the context provided, which describes the Battle of Kursk. According to the text, the German offensive was launched on 5 July, and it had the objective of pinching off the Kursk salient. The text also mentions that the German offensive was called \"Operation Citadel\" or \"Unternehmen Zitadelle\" in German.', 'answer': 'Operation Citadel'}) (input_keys=None),\n   Example({'augmented': True, 'context': ['Kerry Condon | Kerry Condon (born 4 January 1983) is an Irish television and film actress, best known for her role as Octavia of the Julii in the HBO/BBC series \"Rome,\" as Stacey Ehrmantraut in AMC\\'s \"Better Call Saul\" and as the voice of F.R.I.D.A.Y. in various films in the Marvel Cinematic Universe. She is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\"', 'Corona Riccardo | Corona Riccardo (c. 1878October 15, 1917) was an Italian born American actress who had a brief Broadway stage career before leaving to become a wife and mother. Born in Naples she came to acting in 1894 playing a Mexican girl in a play at the Empire Theatre. Wilson Barrett engaged her for a role in his play \"The Sign of the Cross\" which he took on tour of the United States. Riccardo played the role of Ancaria and later played Berenice in the same play. Robert B. Mantell in 1898 who struck by her beauty also cast her in two Shakespeare plays, \"Romeo and Juliet\" and \"Othello\". Author Lewis Strang writing in 1899 said Riccardo was the most promising actress in America at the time. Towards the end of 1898 Mantell chose her for another Shakespeare part, Ophelia im Hamlet. Afterwards she was due to join Augustin Daly\\'s Theatre Company but Daly died in 1899. In 1899 she gained her biggest fame by playing Iras in the first stage production of Ben-Hur.', 'Judi Dench | Dame Judith Olivia \"Judi\" Dench, {\\'1\\': \", \\'2\\': \", \\'3\\': \", \\'4\\': \"} (born 9 December 1934) is an English actress and author. Dench made her professional debut in 1957 with the Old Vic Company. Over the following few years, she performed in several of Shakespeare\\'s plays in such roles as Ophelia in \"Hamlet\", Juliet in \"Romeo and Juliet\", and Lady Macbeth in \"Macbeth\". Although most of her work during this period was in theatre, she also branched into film work and won a BAFTA Award as Most Promising Newcomer. She drew strong reviews for her leading role in the musical \"Cabaret\" in 1968.'], 'question': 'Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?', 'rationale': 'find the answer. We can look at the context provided, which mentions three actresses: Kerry Condon, Corona Riccardo, and Judi Dench. Among them, Kerry Condon is the one who is the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\"', 'answer': 'Kerry Condon'}) (input_keys=None),\n   Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys=None),\n   Example({'question': '\"Everything Has Changed\" is a song from an album released under which record label ?', 'answer': 'Big Machine Records'}) (input_keys=None),\n   Example({'question': 'The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?', 'answer': '1950'}) (input_keys=None),\n   Example({'question': 'Which Pakistani cricket umpire who won 3 consecutive ICC umpire of the year awards in 2009, 2010, and 2011 will be in the ICC World Twenty20?', 'answer': 'Aleem Sarwar Dar'}) (input_keys=None),\n   Example({'question': 'Having the combination of excellent foot speed and bat speed helped Eric Davis, create what kind of outfield for the Los Angeles Dodgers? ', 'answer': '\"Outfield of Dreams\"'}) (input_keys=None),\n   Example({'question': 'Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?', 'answer': 'Aleksandr Danilovich Aleksandrov'}) (input_keys=None),\n   Example({'question': 'The Organisation that allows a community to influence their operation or use and to enjoy the benefits arisingwas founded in what year?', 'answer': '2010'}) (input_keys=None),\n   Example({'question': 'Tombstone stared an actor born May 17, 1955 known as who?', 'answer': 'Bill Paxton'}) (input_keys=None),\n   Example({'question': 'In what year was the club founded that played Manchester City in the 1972 FA Charity Shield', 'answer': '1874'}) (input_keys=None),\n   Example({'question': 'which  American actor was Candace Kita  guest starred with ', 'answer': 'Bill Murray'}) (input_keys=None),\n   Example({'question': 'Which is taller, the Empire State Building or the Bank of America Tower?', 'answer': 'The Empire State Building'}) (input_keys=None),\n   Example({'question': 'Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?', 'answer': 'Buena Vista Distribution'}) (input_keys=None)],\n  'signature_instructions': 'Answers questions with short factoid answers',\n  'signature_prefix': 'Answer:',\n  'extended_signature_instructions': 'Answers questions with short factoid answers',\n  'extended_signature_prefix': 'Answer:'}}\n\n\nLet us now use the compiled model and see whats happening. As the prompt size is large, the llama 7b model is unable to give the right answer. It is ignoring the instructions. So let us use a 70b model. \n\nlm = dspy.GROQ(api_key=os.getenv('GROQ_API_KEY'), model='llama3-70b-8192')\ndspy.settings.configure(lm=lm, rm=retriever)\n\ncompiled_rag = RAG()\ncompiled_rag.load('rag_model.json')\n\nmy_question = \"What castle did David Gregory inherit?\"\n\n# Get the prediction. This contains `pred.context` and `pred.answer`.\npred = compiled_rag(my_question)\n\n# Print the contexts and the answer.\nprint(f\"Question: {my_question}\")\nprint(f\"Predicted Answer: {pred.answer}\")\nprint(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")\n\nprint_prompt(lm)\nprint_response(lm)\n\nQuestion: What castle did David Gregory inherit?\nPredicted Answer: Kinnairdy Castle\nRetrieved Contexts (truncated): ['David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinn...', 'Gregory Tarchaneiotes | Gregory Tarchaneiotes (Greek: Γρηγόριος Ταρχανειώτης , Italian: \"Gregorio Tracanioto\" or \"Tracamoto\" ) was a \"protospatharius\" and the long-reigning catepan of Italy from 998 t...', 'David Gregory (mathematician) | David Gregory (originally spelt Gregorie) FRS (? 1659 – 10 October 1708) was a Scottish mathematician and astronomer. He was professor of mathematics at the University ...']\n\n\nAnswers questions with short factoid answers---Question: At My Window was released by which American singer-songwriter?Answer: John Townes Van ZandtQuestion: \"Everything Has Changed\" is a song from an album released under which record label ?Answer: Big Machine RecordsQuestion: The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?Answer: 1950Question: Which Pakistani cricket umpire who won 3 consecutive ICC umpire of the year awards in 2009, 2010, and 2011 will be in the ICC World Twenty20?Answer: Aleem Sarwar DarQuestion: Having the combination of excellent foot speed and bat speed helped Eric Davis, create what kind of outfield for the Los Angeles Dodgers?Answer: \"Outfield of Dreams\"Question: Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?Answer: Aleksandr Danilovich AleksandrovQuestion: The Organisation that allows a community to influence their operation or use and to enjoy the benefits arisingwas founded in what year?Answer: 2010Question: Tombstone stared an actor born May 17, 1955 known as who?Answer: Bill PaxtonQuestion: In what year was the club founded that played Manchester City in the 1972 FA Charity ShieldAnswer: 1874Question: which American actor was Candace Kita guest starred withAnswer: Bill MurrayQuestion: Which is taller, the Empire State Building or the Bank of America Tower?Answer: The Empire State BuildingQuestion: Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?Answer: Buena Vista Distribution---Follow the following format.Context: may contain relevant factsQuestion: ${question}Reasoning: Let's think step by step in order to ${produce the answer}. We ...Answer: often between 1 and 5 words---Context:[1] «Tae Kwon Do Times | Tae Kwon Do Times is a magazine devoted to the martial art of taekwondo, and is published in the United States of America. While the title suggests that it focuses on taekwondo exclusively, the magazine also covers other Korean martial arts. \"Tae Kwon Do Times\" has published articles by a wide range of authors, including He-Young Kimm, Thomas Kurz, Scott Shaw, and Mark Van Schuyver.»[2] «Kwon Tae-man | Kwon Tae-man (born 1941) was an early Korean hapkido practitioner and a pioneer of the art, first in Korea and then in the United States. He formed one of the earliest dojang's for hapkido in the United States in Torrance, California, and has been featured in many magazine articles promoting the art.»[3] «Hee Il Cho | Cho Hee Il (born October 13, 1940) is a prominent Korean-American master of taekwondo, holding the rank of 9th \"dan\" in the martial art. He has written 11 martial art books, produced 70 martial art training videos, and has appeared on more than 70 martial arts magazine covers. Cho won several national and international competitions as a taekwondo competitor, and has appeared in several films, including \"Fight to Win\", \"Best of the Best\", \"Bloodsport II\", and \"Bloodsport III\". He founded the Action International Martial Arts Association (AIMAA) in 1980, and is its President. Cho is a member of both \"Black Belt\" magazine's Hall of Fame and \"Tae Kwon Do Times\" magazine's Hall of Fame.»Question: Which magazine has published articles by Scott Shaw, Tae Kwon Do Times or Southwest Art?Reasoning: Let's think step by step in order to produce the answer. We can look at the context provided, which mentions that \"Tae Kwon Do Times\" has published articles by a wide range of authors, including Scott Shaw. Therefore, the correct answer is:Answer: Tae Kwon Do Times---Context:[1] «Rosario Dawson | Rosario Isabel Dawson (born May 9, 1979) is an American actress, producer, singer, comic book writer, and political activist. She made her film debut in the 1995 teen drama \"Kids\". Her subsequent film roles include \"He Got Game\", \"Men in Black II\", \"25th Hour\", \"Rent\", \"Sin City\", \"Death Proof\", \"Seven Pounds\", \"\", and \"Top Five\". Dawson has also provided voice-over work for Disney and DC.»[2] «Sarai Gonzalez | Sarai Isaura Gonzalez (born 2005) is an American Latina child actress who made her professional debut at the age of 11 on the Spanish-language \"\"Soy Yo\"\" (\"That's Me\") music video by Bomba Estéreo. Cast as a \"nerdy\" tween with a \"sassy\" and \"confident\" attitude, her performance turned her into a \"Latina icon\" for \"female empowerment, identity and self-worth\". She subsequently appeared in two get out the vote videos for Latinos in advance of the 2016 United States elections.»[3] «Gabriela (2001 film) | Gabriela is a 2001 American romance film, starring Seidy Lopez in the title role alongside Jaime Gomez as her admirer Mike. The film has been cited as an inspiration behind the Premiere Weekend Club, which supports Latino film-making.»Question: Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?Reasoning: Let's think step by step in order to produce the answer. We can look at the context provided, which mentions Rosario Dawson, an American actress who made her film debut in the 1995 teen drama \"Kids\".Answer: Rosario Dawson---Context:[1] «Battle of Kursk | The Battle of Kursk was a Second World War engagement between German and Soviet forces on the Eastern Front near Kursk (450 km south-west of Moscow) in the Soviet Union during July and August 1943. The battle began with the launch of the German offensive, Operation Citadel (German: \"Unternehmen Zitadelle\" ), on 5 July, which had the objective of pinching off the Kursk salient with attacks on the base of the salient from north and south simultaneously. After the German offensive stalled on the northern side of the salient, on 12 July the Soviets commenced their Kursk Strategic Offensive Operation with the launch of Operation Kutuzov (Russian: Кутузов ) against the rear of the German forces in the northern side. On the southern side, the Soviets also launched powerful counterattacks the same day, one of which led to a large armoured clash, the Battle of Prokhorovka. On 3 August, the Soviets began the second phase of the Kursk Strategic Offensive Operation with the launch of Operation Polkovodets Rumyantsev (Russian: Полководец Румянцев ) against the German forces in the southern side of the Kursk salient.»[2] «Operation Mars | Operation Mars, also known as the Second Rzhev-Sychevka Offensive Operation (Russian: Вторая Ржевско-Сычёвская наступательная операция), was the codename for an offensive launched by Soviet forces against German forces during World War II. It took place between 25 November and 20 December 1942 around the Rzhev salient in the vicinity of Moscow.»[3] «Kholm Pocket | The Kholm Pocket (German: \"Kessel von Cholm\" ; Russian: Холмский котёл ) was the name given for the encirclement of German troops by the Red Army around Kholm south of Leningrad, during World War II on the Eastern Front, from 23 January 1942 until 5 May 1942. A much larger pocket was simultaneously surrounded in Demyansk, about 100 km to the northeast. These were the results of German retreat following their defeat during the Battle of Moscow.»Question: What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?Reasoning: Let's think step by step in order to produce the answer. We can look at the context provided, which describes the Battle of Kursk. According to the text, the German offensive was launched on 5 July, and it had the objective of pinching off the Kursk salient. The text also mentions that the German offensive was called \"Operation Citadel\" or \"Unternehmen Zitadelle\" in German.Answer: Operation Citadel---Context:[1] «Kerry Condon | Kerry Condon (born 4 January 1983) is an Irish television and film actress, best known for her role as Octavia of the Julii in the HBO/BBC series \"Rome,\" as Stacey Ehrmantraut in AMC's \"Better Call Saul\" and as the voice of F.R.I.D.A.Y. in various films in the Marvel Cinematic Universe. She is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\"»[2] «Corona Riccardo | Corona Riccardo (c. 1878October 15, 1917) was an Italian born American actress who had a brief Broadway stage career before leaving to become a wife and mother. Born in Naples she came to acting in 1894 playing a Mexican girl in a play at the Empire Theatre. Wilson Barrett engaged her for a role in his play \"The Sign of the Cross\" which he took on tour of the United States. Riccardo played the role of Ancaria and later played Berenice in the same play. Robert B. Mantell in 1898 who struck by her beauty also cast her in two Shakespeare plays, \"Romeo and Juliet\" and \"Othello\". Author Lewis Strang writing in 1899 said Riccardo was the most promising actress in America at the time. Towards the end of 1898 Mantell chose her for another Shakespeare part, Ophelia im Hamlet. Afterwards she was due to join Augustin Daly's Theatre Company but Daly died in 1899. In 1899 she gained her biggest fame by playing Iras in the first stage production of Ben-Hur.»[3] «Judi Dench | Dame Judith Olivia \"Judi\" Dench, {'1': \", '2': \", '3': \", '4': \"} (born 9 December 1934) is an English actress and author. Dench made her professional debut in 1957 with the Old Vic Company. Over the following few years, she performed in several of Shakespeare's plays in such roles as Ophelia in \"Hamlet\", Juliet in \"Romeo and Juliet\", and Lady Macbeth in \"Macbeth\". Although most of her work during this period was in theatre, she also branched into film work and won a BAFTA Award as Most Promising Newcomer. She drew strong reviews for her leading role in the musical \"Cabaret\" in 1968.»Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?Reasoning: Let's think step by step in order to find the answer. We can look at the context provided, which mentions three actresses: Kerry Condon, Corona Riccardo, and Judi Dench. Among them, Kerry Condon is the one who is the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\"Answer: Kerry Condon---Context:[1] «David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory's use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.»[2] «Gregory Tarchaneiotes | Gregory Tarchaneiotes (Greek: Γρηγόριος Ταρχανειώτης , Italian: \"Gregorio Tracanioto\" or \"Tracamoto\" ) was a \"protospatharius\" and the long-reigning catepan of Italy from 998 to 1006. In December 999, and again on February 2, 1002, he reinstituted and confirmed the possessions of the abbey and monks of Monte Cassino in Ascoli. In 1004, he fortified and expanded the castle of Dragonara on the Fortore. He gave it three circular towers and one square one. He also strengthened Lucera.»[3] «David Gregory (mathematician) | David Gregory (originally spelt Gregorie) FRS (? 1659 – 10 October 1708) was a Scottish mathematician and astronomer. He was professor of mathematics at the University of Edinburgh, Savilian Professor of Astronomy at the University of Oxford, and a commentator on Isaac Newton's \"Principia\".»Question: What castle did David Gregory inherit?Reasoning: Let's think step by step in order to\n\n\nproduce the answer. We can look at the context provided, which mentions David Gregory, a Scottish physician and inventor. According to the text, he inherited Kinnairdy Castle in 1664.Answer: Kinnairdy Castle\n\n\nTODO: How did the prompt use 12 examples and 6 contexts?\n\n\n\nFrom exploring the harder questions in the training/dev sets, it becomes clear that a single search query is often not enough for this task. For instance, this can be seen when a question ask about, say, the birth city of the writer of “Right Back At It Again”. A search query identifies the author correctly as “Jeremy McKinnon”, but it wouldn’t figure out when he was born.\nThe standard approach for this challenge in the retrieval-augmented NLP literature is to build multi-hop search systems, like GoldEn (Qi et al., 2019) and Baleen (Khattab et al., 2021). These systems read the retrieved results and then generate additional queries to gather additional information if necessary. Using DSPy, we can easily simulate such systems in a few lines of code.\nWe’ll still use the GenerateAnswer signature from the RAG implementation above. All we need now is a signature for the “hop” behavior: taking some partial context and a question, generate a search query to find missing information.\n\nclass GenerateSearchQuery(dspy.Signature):\n    \"\"\"Write a simple search query that will help answer a complex question.\"\"\"\n\n    context = dspy.InputField(desc=\"may contain relevant facts\")\n    question = dspy.InputField()\n    query = dspy.OutputField()\n\nfrom dsp.utils import deduplicate\n\nclass SimplifiedBaleen(dspy.Module):\n    def __init__(self, passages_per_hop=3, max_hops=2):\n        super().__init__()\n\n        self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n        self.max_hops = max_hops\n    \n    def forward(self, question):\n        context = []\n        \n        for hop in range(self.max_hops):\n            query = self.generate_query[hop](context=context, question=question).query\n            passages = self.retrieve(query).passages\n            context = deduplicate(context + passages)\n\n        pred = self.generate_answer(context=context, question=question)\n        return dspy.Prediction(context=context, answer=pred.answer)\n\nAs we can see, the __init__ method defines a few key sub-modules:\n\ngenerate_query: For each hop, we will have one dspy.ChainOfThought predictor with the GenerateSearchQuery signature.\nretrieve: This module will do the actual search, using the generated queries.\ngenerate_answer: This dspy.Predict module will be used after all the search steps. It has a GenerateAnswer, to actually produce an answer.\n\nThe forward method uses these sub-modules in simple control flow.\n\nFirst, we’ll loop up to self.max_hops times.\nIn each iteration, we’ll generate a search query using the predictor at self.generate_query[hop].\nWe’ll retrieve the top-k passages using that query.\nWe’ll add the (deduplicated) passages to our accumulator of context.\nAfter the loop, we’ll use self.generate_answer to produce an answer.\nWe’ll return a prediction with the retrieved context and predicted answer.\n\n\n\nWe will also compile this program shortly. But, before that, we can try it out in a “zero-shot” setting (i.e., without any compilation).\nUsing a program in zero-shot (uncompiled) setting doesn’t mean that quality will be bad. It just means that we’re bottlenecked directly by the reliability of the underlying LM to understand our sub-tasks from minimal instructions.\nThis is often just fine when using the most expensive/powerful models (e.g., GPT-4) on the easiest and most standard tasks (e.g., answering simple questions about popular entities).\nHowever, a zero-shot approach quickly falls short for more specialized tasks, for novel domains/settings, and for more efficient (or open) models. DSPy can help you in all of these settings.\n\nmy_question = \"How many storeys are in the castle that David Gregory inherited?\"\n\n# Get the prediction. This contains `pred.context` and `pred.answer`.\nuncompiled_baleen = SimplifiedBaleen()  # uncompiled (i.e., zero-shot) program\npred = uncompiled_baleen(my_question)\n\n# Print the contexts and the answer.\nprint(f\"Question: {my_question}\")\nprint(f\"Predicted Answer: {pred.answer}\")\nprint(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")\n\nQuestion: How many storeys are in the castle that David Gregory inherited?\nPredicted Answer: Context: David Gregory inherited Kinnairdy Castle in 1664.\n\nQuestion: How many storeys are in the castle that David Gregory inherited?\n\nReasoning: Let's think step by step in order to find the number of storeys in Kinnairdy Castle. We know that David Gregory inherited Kinnairdy Castle, and according to the context, Kinn\nRetrieved Contexts (truncated): ['David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinn...', 'Gregory Tarchaneiotes | Gregory Tarchaneiotes (Greek: Γρηγόριος Ταρχανειώτης , Italian: \"Gregorio Tracanioto\" or \"Tracamoto\" ) was a \"protospatharius\" and the long-reigning catepan of Italy from 998 t...', 'Gregory Parsloe-Parsloe | Sir Gregory Parsloe-Parsloe, 7th Baronet is a fictional character from the Blandings stories of P. G. Wodehouse. The seventh Baronet, who resides at Matchingham Hall, he is t...', 'Kinnairdy Castle | Kinnairdy Castle is a tower house, having five storeys and a garret, two miles south of Aberchirder, Aberdeenshire, Scotland. The alternative name is Old Kinnairdy....', 'Kinnaird Castle, Brechin | Kinnaird Castle is a 15th-century castle in Angus, Scotland. The castle has been home to the Carnegie family, the Earl of Southesk, for more than 600 years....', 'Kinnaird Head | Kinnaird Head (Scottish Gaelic: \"An Ceann Àrd\" , \"high headland\") is a headland projecting into the North Sea, within the town of Fraserburgh, Aberdeenshire on the east coast of Scotla...']\n\n\nLet’s inspect the last three calls to the LM (i.e., generating the first hop’s query, generating the second hop’s query, and generating the answer).\n\nprint_prompt(lm, -3)\nprint_response(lm, -3)\n\nWrite a simple search query that will help answer a complex question.---Follow the following format.Context: may contain relevant factsQuestion: ${question}Reasoning: Let's think step by step in order to ${produce the query}. We ...Query: ${query}---Context:[1] «David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory's use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.»[2] «Gregory Tarchaneiotes | Gregory Tarchaneiotes (Greek: Γρηγόριος Ταρχανειώτης , Italian: \"Gregorio Tracanioto\" or \"Tracamoto\" ) was a \"protospatharius\" and the long-reigning catepan of Italy from 998 to 1006. In December 999, and again on February 2, 1002, he reinstituted and confirmed the possessions of the abbey and monks of Monte Cassino in Ascoli. In 1004, he fortified and expanded the castle of Dragonara on the Fortore. He gave it three circular towers and one square one. He also strengthened Lucera.»[3] «Gregory Parsloe-Parsloe | Sir Gregory Parsloe-Parsloe, 7th Baronet is a fictional character from the Blandings stories of P. G. Wodehouse. The seventh Baronet, who resides at Matchingham Hall, he is the son of the Very Reverend Dean Parsloe-Parsloe and is the rival and enemy of Lord Emsworth, master of Blandings Castle.»Question: How many storeys are in the castle that David Gregory inherited?Reasoning: Let's think step by step in order to\n\n\nHere's the answer:Context: [1] «David Gregory (physician) | ... He inherited Kinnairdy Castle in 1664. ...»Question: How many storeys are in the castle that David Gregory inherited?Reasoning: Let's think step by step in order to find the answer. We need to find information about Kinnairdy Castle, specifically the number of storeys it has. However, the provided context does not mention the number of storeys. We need to search for external information about Kinnairdy Castle.Query: `Kinnairdy Castle architecture` or `Kinnairdy Castle layout`\n\n\n\nprint_prompt(lm, -2)\nprint_response(lm, -2)\n\nAnswers questions with short factoid answers---Follow the following format.Context: may contain relevant factsQuestion: ${question}Reasoning: Let's think step by step in order to ${produce the answer}. We ...Answer: often between 1 and 5 words---Context:[1] «David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory's use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.»[2] «Gregory Tarchaneiotes | Gregory Tarchaneiotes (Greek: Γρηγόριος Ταρχανειώτης , Italian: \"Gregorio Tracanioto\" or \"Tracamoto\" ) was a \"protospatharius\" and the long-reigning catepan of Italy from 998 to 1006. In December 999, and again on February 2, 1002, he reinstituted and confirmed the possessions of the abbey and monks of Monte Cassino in Ascoli. In 1004, he fortified and expanded the castle of Dragonara on the Fortore. He gave it three circular towers and one square one. He also strengthened Lucera.»[3] «Gregory Parsloe-Parsloe | Sir Gregory Parsloe-Parsloe, 7th Baronet is a fictional character from the Blandings stories of P. G. Wodehouse. The seventh Baronet, who resides at Matchingham Hall, he is the son of the Very Reverend Dean Parsloe-Parsloe and is the rival and enemy of Lord Emsworth, master of Blandings Castle.»[4] «Kinnairdy Castle | Kinnairdy Castle is a tower house, having five storeys and a garret, two miles south of Aberchirder, Aberdeenshire, Scotland. The alternative name is Old Kinnairdy.»[5] «Kinnaird Castle, Brechin | Kinnaird Castle is a 15th-century castle in Angus, Scotland. The castle has been home to the Carnegie family, the Earl of Southesk, for more than 600 years.»[6] «Kinnaird Head | Kinnaird Head (Scottish Gaelic: \"An Ceann Àrd\" , \"high headland\") is a headland projecting into the North Sea, within the town of Fraserburgh, Aberdeenshire on the east coast of Scotland. The 16th-century Kinnaird Castle was converted in 1787 for use as the Kinnaird Head Lighthouse, the first lighthouse in Scotland to be lit by the Commissioners of Northern Lights. Kinnaird Castle and the nearby Winetower were described by W. Douglas Simpson as two of the nine castles of the Knuckle, referring to the rocky headland of north-east Aberdeenshire. Both buildings are category A listed buildings.»Question: How many storeys are in the castle that David Gregory inherited?Reasoning: Let's think step by step in order to\n\n\nAnswer: Five\n\n\n\nprint_prompt(lm, -1)\nprint_response(lm, -1)\n\nAnswers questions with short factoid answers---Follow the following format.Context: may contain relevant factsQuestion: ${question}Reasoning: Let's think step by step in order to ${produce the answer}. We ...Answer: often between 1 and 5 words---Context:[1] «David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory's use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.»[2] «Gregory Tarchaneiotes | Gregory Tarchaneiotes (Greek: Γρηγόριος Ταρχανειώτης , Italian: \"Gregorio Tracanioto\" or \"Tracamoto\" ) was a \"protospatharius\" and the long-reigning catepan of Italy from 998 to 1006. In December 999, and again on February 2, 1002, he reinstituted and confirmed the possessions of the abbey and monks of Monte Cassino in Ascoli. In 1004, he fortified and expanded the castle of Dragonara on the Fortore. He gave it three circular towers and one square one. He also strengthened Lucera.»[3] «Gregory Parsloe-Parsloe | Sir Gregory Parsloe-Parsloe, 7th Baronet is a fictional character from the Blandings stories of P. G. Wodehouse. The seventh Baronet, who resides at Matchingham Hall, he is the son of the Very Reverend Dean Parsloe-Parsloe and is the rival and enemy of Lord Emsworth, master of Blandings Castle.»[4] «Kinnairdy Castle | Kinnairdy Castle is a tower house, having five storeys and a garret, two miles south of Aberchirder, Aberdeenshire, Scotland. The alternative name is Old Kinnairdy.»[5] «Kinnaird Castle, Brechin | Kinnaird Castle is a 15th-century castle in Angus, Scotland. The castle has been home to the Carnegie family, the Earl of Southesk, for more than 600 years.»[6] «Kinnaird Head | Kinnaird Head (Scottish Gaelic: \"An Ceann Àrd\" , \"high headland\") is a headland projecting into the North Sea, within the town of Fraserburgh, Aberdeenshire on the east coast of Scotland. The 16th-century Kinnaird Castle was converted in 1787 for use as the Kinnaird Head Lighthouse, the first lighthouse in Scotland to be lit by the Commissioners of Northern Lights. Kinnaird Castle and the nearby Winetower were described by W. Douglas Simpson as two of the nine castles of the Knuckle, referring to the rocky headland of north-east Aberdeenshire. Both buildings are category A listed buildings.»Question: How many storeys are in the castle that David Gregory inherited?Reasoning: Let's think step by step in order to Answer: FiveAnswer:\n\n\nContext: David Gregory inherited Kinnairdy Castle in 1664.Question: How many storeys are in the castle that David Gregory inherited?Reasoning: Let's think step by step in order to find the number of storeys in Kinnairdy Castle. We know that David Gregory inherited Kinnairdy Castle, and according to the context, Kinn\n\n\n\n\n\nNow is the time to compile our multi-hop (SimplifiedBaleen) program.\nWe will first define our validation logic, which will simply require that:\n\nThe predicted answer matches the gold answer.\nThe retrieved context contains the gold answer.\nNone of the generated queries is rambling (i.e., none exceeds 100 characters in length).\nNone of the generated queries is roughly repeated (i.e., none is within 0.8 or higher F1 score of earlier queries).\n\n\ndef validate_context_and_answer_and_hops(example, pred, trace=None):\n    if not dspy.evaluate.answer_exact_match(example, pred): return False\n    if not dspy.evaluate.answer_passage_match(example, pred): return False\n\n    hops = [example.question] + [outputs.query for *_, outputs in trace if 'query' in outputs]\n\n    if max([len(h) for h in hops]) &gt; 100: return False\n    if any(dspy.evaluate.answer_exact_match_str(hops[idx], hops[:idx], frac=0.8) for idx in range(2, len(hops))): return False\n\n    return True\n\n\nlm = dspy.GROQ(api_key=os.getenv('GROQ_API_KEY'), model='llama3-70b-8192')\ndspy.settings.configure(lm=lm, rm=retriever)\n\nteleprompter = BootstrapFewShot(metric=validate_context_and_answer_and_hops)\ncompiled_baleen = teleprompter.compile(SimplifiedBaleen(), teacher=SimplifiedBaleen(passages_per_hop=2), trainset=trainset)\n\n100%|██████████| 20/20 [13:25&lt;00:00, 40.28s/it]\n\n\n\ncompiled_baleen.save('baleen_model.json')\ncompiled_baleen.dump_state()\n\n{'generate_query[0]': {'lm': None,\n  'traces': [],\n  'train': [],\n  'demos': [Example({'augmented': True, 'context': [], 'question': 'Tombstone stared an actor born May 17, 1955 known as who?', 'rationale': \"Here's the completed response:\\n\\nContext: N/A\\n\\nQuestion: Tombstone starred an actor born May 17, 1955 known as who?\\n\\nReasoning: Let's think step by step in order to find the answer. We know the actor's birthdate, May 17, 1955, and the movie they starred in, Tombstone. We can use this information to search for the actor's name.\", 'query': '\"Tombstone movie cast born May 17 1955\"'}) (input_keys=None),\n   Example({'question': 'Which is taller, the Empire State Building or the Bank of America Tower?', 'answer': 'The Empire State Building'}) (input_keys=None),\n   Example({'question': 'Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?', 'answer': 'Rosario Dawson'}) (input_keys=None),\n   Example({'question': 'Samantha Cristoforetti and Mark Shuttleworth are both best known for being first in their field to go where? ', 'answer': 'space'}) (input_keys=None),\n   Example({'question': 'The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?', 'answer': '1950'}) (input_keys=None),\n   Example({'question': 'What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?', 'answer': 'Operation Citadel'}) (input_keys=None),\n   Example({'question': 'Which of these publications was most recently published, Who Put the Bomp or Self?', 'answer': 'Self'}) (input_keys=None),\n   Example({'question': 'Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?', 'answer': 'Buena Vista Distribution'}) (input_keys=None),\n   Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys=None),\n   Example({'question': 'Which Pakistani cricket umpire who won 3 consecutive ICC umpire of the year awards in 2009, 2010, and 2011 will be in the ICC World Twenty20?', 'answer': 'Aleem Sarwar Dar'}) (input_keys=None),\n   Example({'question': 'Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?', 'answer': 'Aleksandr Danilovich Aleksandrov'}) (input_keys=None),\n   Example({'question': 'This American guitarist best known for her work with the Iron Maidens is an ancestor of a composer who was known as what?', 'answer': 'The Waltz King'}) (input_keys=None),\n   Example({'question': 'The Organisation that allows a community to influence their operation or use and to enjoy the benefits arisingwas founded in what year?', 'answer': '2010'}) (input_keys=None),\n   Example({'question': 'On the coast of what ocean is the birthplace of Diogal Sakho?', 'answer': 'Atlantic'}) (input_keys=None),\n   Example({'question': 'which  American actor was Candace Kita  guest starred with ', 'answer': 'Bill Murray'}) (input_keys=None),\n   Example({'question': 'Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?', 'answer': 'Kerry Condon'}) (input_keys=None)],\n  'signature_instructions': 'Write a simple search query that will help answer a complex question.',\n  'signature_prefix': 'Query:',\n  'extended_signature_instructions': 'Write a simple search query that will help answer a complex question.',\n  'extended_signature_prefix': 'Query:'},\n 'generate_query[1]': {'lm': None,\n  'traces': [],\n  'train': [],\n  'demos': [Example({'augmented': True, 'context': ['Wyatt Earp: Return to Tombstone | Wyatt Earp: Return to Tombstone is a 1994 independent film starring Hugh O\\'Brian as Wyatt Earp, featuring new footage mixed with colorized sequences from O\\'Brian\\'s 1955-1961 television series \"The Life and Legend of Wyatt Earp\". The supporting cast for the new footage includes Bruce Boxleitner, Paul Brinegar, Harry Carey, Jr., Bo Hopkins, and Don Meredith. The colorized flashback archival footage from the original television series features Douglas Fowley as Doc Holliday and Lloyd Corrigan as Ned Buntline. The movie was directed by Paul Landres and Frank McDonald.', 'Michael Biehn | Michael Connell Biehn (born July 31, 1956) is an American actor, primarily known for his military roles in science fiction films directed by James Cameron; as Sgt. Kyle Reese in \"The Terminator\" (1984), Cpl. Dwayne Hicks in \"Aliens\" (1986) and Lt. Coffey in \"The Abyss\" (1989). He was nominated for the Saturn Award for Best Actor for \"Aliens.\" His other films include \"The Fan\" (1981), \"K2\" (1991), \"Tombstone\" (1993), \"The Rock\" (1996), \"\" (2001) and \"Planet Terror\" (2007). On television, he has appeared in \"Hill Street Blues\" (1984) and \"Adventure Inc.\" (2002-03).'], 'question': 'Tombstone stared an actor born May 17, 1955 known as who?', 'rationale': 'Here is the answer:\\n\\nContext: [1] and [2] provide information about two different movies, \"Wyatt Earp: Return to Tombstone\" and \"Tombstone\", as well as an actor, Michael Biehn.\\n\\nQuestion: Tombstone stared an actor born May 17, 1955 known as who?\\n\\nReasoning: Let\\'s think step by step in order to find the answer. We know that the question is asking about the movie \"Tombstone\", and we want to find the actor born on May 17, 1955 who starred in it.', 'query': '`Tombstone movie 1993 cast born May 17, 1955`\\n\\nThis query should return the answer: Val Kil'}) (input_keys=None),\n   Example({'question': 'Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?', 'answer': 'Aleksandr Danilovich Aleksandrov'}) (input_keys=None),\n   Example({'question': 'On the coast of what ocean is the birthplace of Diogal Sakho?', 'answer': 'Atlantic'}) (input_keys=None),\n   Example({'question': 'What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?', 'answer': 'Operation Citadel'}) (input_keys=None),\n   Example({'question': 'Which Pakistani cricket umpire who won 3 consecutive ICC umpire of the year awards in 2009, 2010, and 2011 will be in the ICC World Twenty20?', 'answer': 'Aleem Sarwar Dar'}) (input_keys=None),\n   Example({'question': 'Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?', 'answer': 'Kerry Condon'}) (input_keys=None),\n   Example({'question': 'Samantha Cristoforetti and Mark Shuttleworth are both best known for being first in their field to go where? ', 'answer': 'space'}) (input_keys=None),\n   Example({'question': 'which  American actor was Candace Kita  guest starred with ', 'answer': 'Bill Murray'}) (input_keys=None),\n   Example({'question': 'Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?', 'answer': 'Rosario Dawson'}) (input_keys=None),\n   Example({'question': 'Which of these publications was most recently published, Who Put the Bomp or Self?', 'answer': 'Self'}) (input_keys=None),\n   Example({'question': 'Which is taller, the Empire State Building or the Bank of America Tower?', 'answer': 'The Empire State Building'}) (input_keys=None),\n   Example({'question': 'This American guitarist best known for her work with the Iron Maidens is an ancestor of a composer who was known as what?', 'answer': 'The Waltz King'}) (input_keys=None),\n   Example({'question': 'The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?', 'answer': '1950'}) (input_keys=None),\n   Example({'question': 'The Organisation that allows a community to influence their operation or use and to enjoy the benefits arisingwas founded in what year?', 'answer': '2010'}) (input_keys=None),\n   Example({'question': 'Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?', 'answer': 'Buena Vista Distribution'}) (input_keys=None),\n   Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys=None)],\n  'signature_instructions': 'Write a simple search query that will help answer a complex question.',\n  'signature_prefix': 'Query:',\n  'extended_signature_instructions': 'Write a simple search query that will help answer a complex question.',\n  'extended_signature_prefix': 'Query:'},\n 'retrieve': {'k': 3},\n 'generate_answer': {'lm': None,\n  'traces': [],\n  'train': [],\n  'demos': [Example({'augmented': True, 'context': ['Wyatt Earp: Return to Tombstone | Wyatt Earp: Return to Tombstone is a 1994 independent film starring Hugh O\\'Brian as Wyatt Earp, featuring new footage mixed with colorized sequences from O\\'Brian\\'s 1955-1961 television series \"The Life and Legend of Wyatt Earp\". The supporting cast for the new footage includes Bruce Boxleitner, Paul Brinegar, Harry Carey, Jr., Bo Hopkins, and Don Meredith. The colorized flashback archival footage from the original television series features Douglas Fowley as Doc Holliday and Lloyd Corrigan as Ned Buntline. The movie was directed by Paul Landres and Frank McDonald.', 'Michael Biehn | Michael Connell Biehn (born July 31, 1956) is an American actor, primarily known for his military roles in science fiction films directed by James Cameron; as Sgt. Kyle Reese in \"The Terminator\" (1984), Cpl. Dwayne Hicks in \"Aliens\" (1986) and Lt. Coffey in \"The Abyss\" (1989). He was nominated for the Saturn Award for Best Actor for \"Aliens.\" His other films include \"The Fan\" (1981), \"K2\" (1991), \"Tombstone\" (1993), \"The Rock\" (1996), \"\" (2001) and \"Planet Terror\" (2007). On television, he has appeared in \"Hill Street Blues\" (1984) and \"Adventure Inc.\" (2002-03).', 'Tombstone (film) | Tombstone is a 1993 American Western film directed by George P. Cosmatos, written by Kevin Jarre (who was also the original director, but was replaced early in production), and starring Kurt Russell and Val Kilmer, with Sam Elliott, Bill Paxton, Powers Boothe, Michael Biehn, and Dana Delany in supporting roles, as well as narration by Robert Mitchum.'], 'question': 'Tombstone stared an actor born May 17, 1955 known as who?', 'rationale': \"Reasoning: Let's think step by step in order to find the answer. We know that the question is asking about an actor born on May 17, 1955, who starred in the movie Tombstone. From the context, we can see that the movie Tombstone (1993) starred Kurt Russell and Val Kilmer, among others. However, none of them were born on May 17, 1955. But, we can see that Michael Biehn was also in the movie, and according to his bio, he was born on July 31, 1956, which doesn't match the birthdate we're looking for. So, we need to look further.\", 'answer': 'Bill Paxton'}) (input_keys=None),\n   Example({'question': 'which  American actor was Candace Kita  guest starred with ', 'answer': 'Bill Murray'}) (input_keys=None),\n   Example({'question': 'Samantha Cristoforetti and Mark Shuttleworth are both best known for being first in their field to go where? ', 'answer': 'space'}) (input_keys=None),\n   Example({'question': 'Which is taller, the Empire State Building or the Bank of America Tower?', 'answer': 'The Empire State Building'}) (input_keys=None),\n   Example({'question': 'This American guitarist best known for her work with the Iron Maidens is an ancestor of a composer who was known as what?', 'answer': 'The Waltz King'}) (input_keys=None),\n   Example({'question': 'Which Pakistani cricket umpire who won 3 consecutive ICC umpire of the year awards in 2009, 2010, and 2011 will be in the ICC World Twenty20?', 'answer': 'Aleem Sarwar Dar'}) (input_keys=None),\n   Example({'question': 'Which of these publications was most recently published, Who Put the Bomp or Self?', 'answer': 'Self'}) (input_keys=None),\n   Example({'question': 'Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?', 'answer': 'Rosario Dawson'}) (input_keys=None),\n   Example({'question': 'The Organisation that allows a community to influence their operation or use and to enjoy the benefits arisingwas founded in what year?', 'answer': '2010'}) (input_keys=None),\n   Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys=None),\n   Example({'question': 'Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?', 'answer': 'Kerry Condon'}) (input_keys=None),\n   Example({'question': 'What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?', 'answer': 'Operation Citadel'}) (input_keys=None),\n   Example({'question': 'Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?', 'answer': 'Aleksandr Danilovich Aleksandrov'}) (input_keys=None),\n   Example({'question': 'Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?', 'answer': 'Buena Vista Distribution'}) (input_keys=None),\n   Example({'question': 'The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?', 'answer': '1950'}) (input_keys=None),\n   Example({'question': 'On the coast of what ocean is the birthplace of Diogal Sakho?', 'answer': 'Atlantic'}) (input_keys=None)],\n  'signature_instructions': 'Answers questions with short factoid answers',\n  'signature_prefix': 'Answer:',\n  'extended_signature_instructions': 'Answers questions with short factoid answers',\n  'extended_signature_prefix': 'Answer:'}}\n\n\n\nfrom dspy.evaluate.evaluate import Evaluate\n\n# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\nevaluate_on_hotpotqa = Evaluate(devset=devset, num_threads=1, display_progress=True, display_table=5)\n\ndef gold_passages_retrieved(example, pred, trace=None):\n    gold_titles = set(map(dspy.evaluate.normalize_text, example['gold_titles']))\n    found_titles = set(map(dspy.evaluate.normalize_text, [c.split(' | ')[0] for c in pred.context]))\n\n    return gold_titles.issubset(found_titles)\n\ncompiled_rag_retrieval_score = evaluate_on_hotpotqa(compiled_rag, metric=gold_passages_retrieved)\n\n\n# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\nmetric = dspy.evaluate.answer_exact_match\nevaluate_on_hotpotqa(compiled_rag, metric=metric)"
  },
  {
    "objectID": "posts/2024-05-27-exploring-dspy-1.html#purpose",
    "href": "posts/2024-05-27-exploring-dspy-1.html#purpose",
    "title": "Exploring Dspy - part 1",
    "section": "",
    "text": "I have a read a lot about the capabilites of the dspy library from stanford. I am trying to understand its various capabilities. Let start with the https://github.com/stanfordnlp/dspy/blob/main/intro.ipynb. My comments will be highlighted in red\n\nimport dspy\nimport os\nfrom IPython.display import display, HTML\n!pip show dspy-ai | grep Version\n\nVersion: 2.4.9\n\n\n\n\nWe are using groq inference as it is much cheaper and faster than openai\n\nlm = dspy.GROQ(api_key=os.getenv('GROQ_API_KEY'), model='llama3-8b-8192')\n# this is the retriver given in the dspy documentation\nretriever = dspy.ColBERTv2(url='http://20.102.90.50:2017/wiki17_abstracts')\ndspy.settings.configure(lm=lm, rm=retriever)\n\n\n# helper functions to print in color\ndef color_html(s, color='black'):\n    '''returns a string with the given color in html format'''\n    s = s.replace('\\n', '&lt;br&gt;')\n    return \"&lt;text style=color:{}&gt;{}&lt;/text&gt;\".format(color, s)\n\ndef cprint(s, color='black'):\n    '''prints a string with the given color'''\n    display(HTML(color_html(s, color)))\n\ndef print_prompt(lm, idx=-1):\n    cprint(lm.history[idx]['prompt'], color='blue')\n\ndef print_response(lm, idx=-1):\n    cprint(lm.history[idx]['response'], color='green')\n\nWhatever the task, the general workflow is:\n\nCollect a little bit of data. Define examples of the inputs and outputs of your program (e.g., questions and their answers). This could just be a handful of quick examples you wrote down. If large datasets exist, the more the merrier!\nWrite your program. Define the modules (i.e., sub-tasks) of your program and the way they should interact together to solve your task.\nDefine some validation logic. What makes for a good run of your program? Maybe the answers need to have a certain length or stick to a particular format? Specify the logic that checks that.\nCompile! Ask DSPy to compile your program using your data. The compiler will use your data and validation logic to optimize your program (e.g., prompts and modules) so it’s efficient and effective! We will attempt to understand what this means. How are prompts and modules optimized?\nIterate. Repeat the process by improving your data, program, validation, or by using more advanced features of the DSPy compiler.\n\n\n\n\n\n\nfrom dspy.datasets import HotPotQA\ndataset = HotPotQA(train_seed=1, train_size=20, eval_seed=2023, dev_size=50, test_size=0)\n\n# tell DSPy that the question field is the one we want to use (from all the fields in the dataset)\ntrainset = [x.with_inputs('question') for x in dataset.train]\ndevset = [x.with_inputs('question') for x in dataset.dev]\n\nlen(trainset), len(devset)\n\n/Users/achinta/miniforge3/envs/deepsql/lib/python3.11/site-packages/datasets/table.py:1421: FutureWarning: promote has been superseded by mode='default'.\n  table = cls._concat_blocks(blocks, axis=0)\n\n\n(20, 50)\n\n\nWe just loaded trainset(20 examples) and devset(50 examples). Lets look at some examples from the trainset.\n\ntrain_example = trainset[0]\nprint(f\"Question: {train_example.question}\")\nprint(f\"Answer: {train_example.answer}\")\n\n# select a train example and a dev example\ntrain_example = trainset[0]\ndev_example = devset[18]\n\nQuestion: At My Window was released by which American singer-songwriter?\nAnswer: John Townes Van Zandt\n\n\n\nclass BasicQA(dspy.Signature):\n    '''Answers questions with short factoid answers'''\n    question = dspy.InputField()\n    answer = dspy.OutputField(desc=\"often between 1 and 5 words\")\n\n# define predictor\ngenerate_answer = dspy.Predict(BasicQA)\n# call the predictor on the particular input\npred = generate_answer(question=dev_example.question)\n\n# print the inpput and the prediction\nprint(f\"Question: {dev_example.question}\")\nprint(f\"Prediction: {pred.answer}\")\n\nQuestion: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\nPrediction: Robert Irvine\n\n\n\nlm.history[-1]\n\n{'prompt': \"Answers questions with short factoid answers\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\nReasoning: Let's think step by step in order to ${produce the answer}. We ...\\nAnswer: often between 1 and 5 words\\n\\n---\\n\\nQuestion: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\\nReasoning: Let's think step by step in order to\",\n 'response': \"Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\\nReasoning: Let's think step by step in order to figure out the nationality of the chef. He is an American chef and restaurateur, and the show is set in the United States. Therefore...\\nAnswer: American\",\n 'kwargs': {'temperature': 0.0,\n  'max_tokens': 150,\n  'top_p': 1,\n  'frequency_penalty': 0,\n  'presence_penalty': 0,\n  'n': 1,\n  'model': 'llama3-8b-8192',\n  'messages': [{'role': 'user',\n    'content': \"Answers questions with short factoid answers\\n\\n---\\n\\nFollow the following format.\\n\\nQuestion: ${question}\\nReasoning: Let's think step by step in order to ${produce the answer}. We ...\\nAnswer: often between 1 and 5 words\\n\\n---\\n\\nQuestion: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\\nReasoning: Let's think step by step in order to\"}]},\n 'raw_kwargs': {}}\n\n\nLets now look at the prompt and the response\n\nprint_prompt(lm)\nprint_response(lm)\n\nAnswers questions with short factoid answers---Follow the following format.Question: ${question}Answer: often between 1 and 5 words---Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?Answer:\n\n\nRobert Irvine\n\n\n Let us use chain-of-thought. We can do that by creating a ChainOfThought class from any signature. \n\n# Define the predictor. Notice we're just changing the class. The signature BasicQA is unchanged.\ngenerate_answer_with_cot = dspy.ChainOfThought(BasicQA)\n\n# call the predictor on the particular input\npred = generate_answer_with_cot(question=dev_example.question)\n\nprint(f\"Question: {dev_example.question}\")\nprint(f\"Thought: {pred.rationale.split('.', 1)[1].strip()}\")\nprint(f\"Predicted Answer: {pred.answer}\")\n\nQuestion: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?\nThought: He is an American chef and restaurateur, and the show is set in the United States. Therefore...\nPredicted Answer: American\n\n\nLets now look at the prompt and the response for ChainOfThought\n\nprint(f\"number of LLM calls till now - {len(lm.history)}\")\nprint_prompt(lm)\nprint_response(lm)\n\nnumber of LLM calls till now - 2\n\n\nAnswers questions with short factoid answers---Follow the following format.Question: ${question}Reasoning: Let's think step by step in order to ${produce the answer}. We ...Answer: often between 1 and 5 words---Question: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?Reasoning: Let's think step by step in order to\n\n\nQuestion: What is the nationality of the chef and restaurateur featured in Restaurant: Impossible?Reasoning: Let's think step by step in order to find the answer. We know that the show is a reality TV series that helps struggling restaurants, and the chef and restaurateur is Robert Irvine. He is a British chef.Answer: British\n\n\nThe Reasoning variable is included in the prompt by the class dspy.ChainOfThought. (check the code)  How is the prompt able to generate completions for multiple output variables (say Reasoning and answer) in the same prompt?  Or is it? The prompt cleverly stops after Reasoning: Let's think step by step in order to and the response is generated for  Reasoning as well as the answer\nWhen the LLM is able to generate only plain text completion, how are we able to populate output variables in the Predictions class?\n\n\n\n\nretrieve = dspy.Retrieve(k=3)\ntopK_passages = retrieve(dev_example.question).passages\n\nfor idx, passage in enumerate(topK_passages):\n    print(f'{idx+1}]', passage, '\\n')\n\n1] Restaurant: Impossible | Restaurant: Impossible is an American reality television series, featuring chef and restaurateur Robert Irvine, that aired on Food Network from 2011 to 2016. \n\n2] Jean Joho | Jean Joho is a French-American chef and restaurateur. He is chef/proprietor of Everest in Chicago (founded in 1986), Paris Club Bistro & Bar and Studio Paris in Chicago, The Eiffel Tower Restaurant in Las Vegas, and Brasserie JO in Boston. \n\n3] List of Restaurant: Impossible episodes | This is the list of the episodes for the American cooking and reality television series \"Restaurant Impossible\", produced by Food Network. The premise of the series is that within two days and on a budget of $10,000, celebrity chef Robert Irvine renovates a failing American restaurant with the goal of helping to restore it to profitability and prominence. Irvine is assisted by a designer (usually Taniya Nayak, Cheryl Torrenueva, or Lynn Keagan, but sometimes Vanessa De Leon, Krista Watterworth, Yvette Irene, or Nicole Faccuito), along with general contractor Tom Bury, who sometimes does double duty as both general contractor and designer. After assessing the problems with the restaurant, Robert Irvine typically creates a plan for the new decor, oversees the cleaning of the restaurant, reduces the size of the menu and improves the food, develops a promotional activity, educates the restaurant's owners, or trains the staff, as needed by each restaurant. \n\n\n\n\n\n\nLet’s define our first complete program for this task. We’ll build a retrieval-augmented pipeline for answer generation.\nGiven a question, we’ll search for the top-3 passages in Wikipedia and then feed them as context for answer generation.\nLet’s start by defining this signature: context, question --&gt; answer.\n\nclass GenerateAnswer(dspy.Signature):\n    \"\"\"Answers questions with short factoid answers\"\"\"\n\n    context = dspy.InputField(desc='may contain relevant facts')\n    question = dspy.InputField()\n    answer = dspy.OutputField(desc='often between 1 and 5 words')\n\nclass RAG(dspy.Module):\n    def __init__(self, num_passages=3):\n        super().__init__()\n\n        self.retrieve = dspy.Retrieve(k=num_passages)\n        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n    \n    def forward(self, question):\n        context = self.retrieve(question).passages\n        prediction = self.generate_answer(context=context, question=question)\n        return dspy.Prediction(context=context, answer=prediction.answer)\n\nHaving defined this program, let’s now compile it. Compiling a program will update the parameters stored in each module. In our setting, this is primarily in the form of collecting and selecting good demonstrations for inclusion in your prompt(s).\nCompiling depends on three things:\n\nA training set. We’ll just use our 20 question–answer examples from trainset above.\nA metric for validation. We’ll define a quick validate_context_and_answer that checks that the predicted answer is correct. It’ll also check that the retrieved context does actually contain that answer.\nA specific teleprompter. The DSPy compiler includes a number of teleprompters that can optimize your programs.\n\nTeleprompters: Teleprompters are powerful optimizers that can take any program and learn to bootstrap and select effective prompts for its modules. Hence the name, which means “prompting at a distance”.\nDifferent teleprompters offer various tradeoffs in terms of how much they optimize cost versus quality, etc. We will use a simple default BootstrapFewShot in this notebook.\nIf you’re into analogies, you could think of this as your training data, your loss function, and your optimizer in a standard DNN supervised learning setup. Whereas SGD is a basic optimizer, there are more sophisticated (and more expensive!) ones like Adam or RMSProp.\n\nfrom dspy.teleprompt import BootstrapFewShot\n\n# Validation logic: check that the predicted answer is correct.\n# Also check that the retrieved context does actually contain that answer.\ndef validate_context_and_answer(example, pred, trace=None):\n    answer_EM = dspy.evaluate.answer_exact_match(example, pred)\n    answer_PM = dspy.evaluate.answer_passage_match(example, pred)\n    return answer_EM and answer_PM\n\n# Set up a basic teleprompter, which will compile our RAG program.\nteleprompter = BootstrapFewShot(metric=validate_context_and_answer, metric_threshold=None)\n\n# Compile!\ncompiled_rag = teleprompter.compile(student=RAG(), trainset=trainset)\n\n  0%|          | 0/20 [00:00&lt;?, ?it/s]0.00s - Debugger warning: It seems that frozen modules are being used, which may\n0.00s - make the debugger miss breakpoints. Please pass -Xfrozen_modules=off\n0.00s - to python to disable frozen modules.\n0.00s - Note: Debugging will proceed. Set PYDEVD_DISABLE_FILE_VALIDATION=1 to disable this validation.\n 55%|█████▌    | 11/20 [01:01&lt;00:49,  5.55s/it]\n\n\n What does compiling actually do?  - Here we want to teach the student (the RAG model) to learn something from samples from the trainset.  - We make a copy of the student and the techer using reset_copy() method, which uses deepcopy and resets any parameters in studen or teacher  - Here the teacher is the compiled LabeledFewShot, which is nothing but selecting k (default=16) samples from the trainset.  - We set the metric_threshold to None, so we are just ignoring the result of validate_context_and_answer and just selecting all the examples.  - So let us now see what is the result of the compilation below. We can see all the 16 examples added as demos to the student RAG module. \n\n\ncompiled_rag.save('rag_model.json')\ncompiled_rag.dump_state()\n\n{'retrieve': {'k': 3},\n 'generate_answer': {'lm': None,\n  'traces': [],\n  'train': [],\n  'demos': [Example({'augmented': True, 'context': ['Tae Kwon Do Times | Tae Kwon Do Times is a magazine devoted to the martial art of taekwondo, and is published in the United States of America. While the title suggests that it focuses on taekwondo exclusively, the magazine also covers other Korean martial arts. \"Tae Kwon Do Times\" has published articles by a wide range of authors, including He-Young Kimm, Thomas Kurz, Scott Shaw, and Mark Van Schuyver.', \"Kwon Tae-man | Kwon Tae-man (born 1941) was an early Korean hapkido practitioner and a pioneer of the art, first in Korea and then in the United States. He formed one of the earliest dojang's for hapkido in the United States in Torrance, California, and has been featured in many magazine articles promoting the art.\", 'Hee Il Cho | Cho Hee Il (born October 13, 1940) is a prominent Korean-American master of taekwondo, holding the rank of 9th \"dan\" in the martial art. He has written 11 martial art books, produced 70 martial art training videos, and has appeared on more than 70 martial arts magazine covers. Cho won several national and international competitions as a taekwondo competitor, and has appeared in several films, including \"Fight to Win\", \"Best of the Best\", \"Bloodsport II\", and \"Bloodsport III\". He founded the Action International Martial Arts Association (AIMAA) in 1980, and is its President. Cho is a member of both \"Black Belt\" magazine\\'s Hall of Fame and \"Tae Kwon Do Times\" magazine\\'s Hall of Fame.'], 'question': 'Which magazine has published articles by Scott Shaw, Tae Kwon Do Times or Southwest Art?', 'rationale': 'produce the answer. We can look at the context provided, which mentions that \"Tae Kwon Do Times\" has published articles by a wide range of authors, including Scott Shaw. Therefore, the correct answer is:', 'answer': 'Tae Kwon Do Times'}) (input_keys=None),\n   Example({'augmented': True, 'context': ['Rosario Dawson | Rosario Isabel Dawson (born May 9, 1979) is an American actress, producer, singer, comic book writer, and political activist. She made her film debut in the 1995 teen drama \"Kids\". Her subsequent film roles include \"He Got Game\", \"Men in Black II\", \"25th Hour\", \"Rent\", \"Sin City\", \"Death Proof\", \"Seven Pounds\", \"\", and \"Top Five\". Dawson has also provided voice-over work for Disney and DC.', 'Sarai Gonzalez | Sarai Isaura Gonzalez (born 2005) is an American Latina child actress who made her professional debut at the age of 11 on the Spanish-language \"\"Soy Yo\"\" (\"That\\'s Me\") music video by Bomba Estéreo. Cast as a \"nerdy\" tween with a \"sassy\" and \"confident\" attitude, her performance turned her into a \"Latina icon\" for \"female empowerment, identity and self-worth\". She subsequently appeared in two get out the vote videos for Latinos in advance of the 2016 United States elections.', 'Gabriela (2001 film) | Gabriela is a 2001 American romance film, starring Seidy Lopez in the title role alongside Jaime Gomez as her admirer Mike. The film has been cited as an inspiration behind the Premiere Weekend Club, which supports Latino film-making.'], 'question': 'Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?', 'rationale': 'produce the answer. We can look at the context provided, which mentions Rosario Dawson, an American actress who made her film debut in the 1995 teen drama \"Kids\".', 'answer': 'Rosario Dawson'}) (input_keys=None),\n   Example({'augmented': True, 'context': ['Battle of Kursk | The Battle of Kursk was a Second World War engagement between German and Soviet forces on the Eastern Front near Kursk (450 km south-west of Moscow) in the Soviet Union during July and August 1943. The battle began with the launch of the German offensive, Operation Citadel (German: \"Unternehmen Zitadelle\" ), on 5 July, which had the objective of pinching off the Kursk salient with attacks on the base of the salient from north and south simultaneously. After the German offensive stalled on the northern side of the salient, on 12 July the Soviets commenced their Kursk Strategic Offensive Operation with the launch of Operation Kutuzov (Russian: Кутузов ) against the rear of the German forces in the northern side. On the southern side, the Soviets also launched powerful counterattacks the same day, one of which led to a large armoured clash, the Battle of Prokhorovka. On 3 August, the Soviets began the second phase of the Kursk Strategic Offensive Operation with the launch of Operation Polkovodets Rumyantsev (Russian: Полководец Румянцев ) against the German forces in the southern side of the Kursk salient.', 'Operation Mars | Operation Mars, also known as the Second Rzhev-Sychevka Offensive Operation (Russian: Вторая Ржевско-Сычёвская наступательная операция), was the codename for an offensive launched by Soviet forces against German forces during World War II. It took place between 25 November and 20 December 1942 around the Rzhev salient in the vicinity of Moscow.', 'Kholm Pocket | The Kholm Pocket (German: \"Kessel von Cholm\" ; Russian: Холмский котёл ) was the name given for the encirclement of German troops by the Red Army around Kholm south of Leningrad, during World War II on the Eastern Front, from 23 January 1942 until 5 May 1942. A much larger pocket was simultaneously surrounded in Demyansk, about 100 km to the northeast. These were the results of German retreat following their defeat during the Battle of Moscow.'], 'question': 'What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?', 'rationale': 'produce the answer. We can look at the context provided, which describes the Battle of Kursk. According to the text, the German offensive was launched on 5 July, and it had the objective of pinching off the Kursk salient. The text also mentions that the German offensive was called \"Operation Citadel\" or \"Unternehmen Zitadelle\" in German.', 'answer': 'Operation Citadel'}) (input_keys=None),\n   Example({'augmented': True, 'context': ['Kerry Condon | Kerry Condon (born 4 January 1983) is an Irish television and film actress, best known for her role as Octavia of the Julii in the HBO/BBC series \"Rome,\" as Stacey Ehrmantraut in AMC\\'s \"Better Call Saul\" and as the voice of F.R.I.D.A.Y. in various films in the Marvel Cinematic Universe. She is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\"', 'Corona Riccardo | Corona Riccardo (c. 1878October 15, 1917) was an Italian born American actress who had a brief Broadway stage career before leaving to become a wife and mother. Born in Naples she came to acting in 1894 playing a Mexican girl in a play at the Empire Theatre. Wilson Barrett engaged her for a role in his play \"The Sign of the Cross\" which he took on tour of the United States. Riccardo played the role of Ancaria and later played Berenice in the same play. Robert B. Mantell in 1898 who struck by her beauty also cast her in two Shakespeare plays, \"Romeo and Juliet\" and \"Othello\". Author Lewis Strang writing in 1899 said Riccardo was the most promising actress in America at the time. Towards the end of 1898 Mantell chose her for another Shakespeare part, Ophelia im Hamlet. Afterwards she was due to join Augustin Daly\\'s Theatre Company but Daly died in 1899. In 1899 she gained her biggest fame by playing Iras in the first stage production of Ben-Hur.', 'Judi Dench | Dame Judith Olivia \"Judi\" Dench, {\\'1\\': \", \\'2\\': \", \\'3\\': \", \\'4\\': \"} (born 9 December 1934) is an English actress and author. Dench made her professional debut in 1957 with the Old Vic Company. Over the following few years, she performed in several of Shakespeare\\'s plays in such roles as Ophelia in \"Hamlet\", Juliet in \"Romeo and Juliet\", and Lady Macbeth in \"Macbeth\". Although most of her work during this period was in theatre, she also branched into film work and won a BAFTA Award as Most Promising Newcomer. She drew strong reviews for her leading role in the musical \"Cabaret\" in 1968.'], 'question': 'Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?', 'rationale': 'find the answer. We can look at the context provided, which mentions three actresses: Kerry Condon, Corona Riccardo, and Judi Dench. Among them, Kerry Condon is the one who is the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\"', 'answer': 'Kerry Condon'}) (input_keys=None),\n   Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys=None),\n   Example({'question': '\"Everything Has Changed\" is a song from an album released under which record label ?', 'answer': 'Big Machine Records'}) (input_keys=None),\n   Example({'question': 'The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?', 'answer': '1950'}) (input_keys=None),\n   Example({'question': 'Which Pakistani cricket umpire who won 3 consecutive ICC umpire of the year awards in 2009, 2010, and 2011 will be in the ICC World Twenty20?', 'answer': 'Aleem Sarwar Dar'}) (input_keys=None),\n   Example({'question': 'Having the combination of excellent foot speed and bat speed helped Eric Davis, create what kind of outfield for the Los Angeles Dodgers? ', 'answer': '\"Outfield of Dreams\"'}) (input_keys=None),\n   Example({'question': 'Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?', 'answer': 'Aleksandr Danilovich Aleksandrov'}) (input_keys=None),\n   Example({'question': 'The Organisation that allows a community to influence their operation or use and to enjoy the benefits arisingwas founded in what year?', 'answer': '2010'}) (input_keys=None),\n   Example({'question': 'Tombstone stared an actor born May 17, 1955 known as who?', 'answer': 'Bill Paxton'}) (input_keys=None),\n   Example({'question': 'In what year was the club founded that played Manchester City in the 1972 FA Charity Shield', 'answer': '1874'}) (input_keys=None),\n   Example({'question': 'which  American actor was Candace Kita  guest starred with ', 'answer': 'Bill Murray'}) (input_keys=None),\n   Example({'question': 'Which is taller, the Empire State Building or the Bank of America Tower?', 'answer': 'The Empire State Building'}) (input_keys=None),\n   Example({'question': 'Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?', 'answer': 'Buena Vista Distribution'}) (input_keys=None)],\n  'signature_instructions': 'Answers questions with short factoid answers',\n  'signature_prefix': 'Answer:',\n  'extended_signature_instructions': 'Answers questions with short factoid answers',\n  'extended_signature_prefix': 'Answer:'}}\n\n\nLet us now use the compiled model and see whats happening. As the prompt size is large, the llama 7b model is unable to give the right answer. It is ignoring the instructions. So let us use a 70b model. \n\nlm = dspy.GROQ(api_key=os.getenv('GROQ_API_KEY'), model='llama3-70b-8192')\ndspy.settings.configure(lm=lm, rm=retriever)\n\ncompiled_rag = RAG()\ncompiled_rag.load('rag_model.json')\n\nmy_question = \"What castle did David Gregory inherit?\"\n\n# Get the prediction. This contains `pred.context` and `pred.answer`.\npred = compiled_rag(my_question)\n\n# Print the contexts and the answer.\nprint(f\"Question: {my_question}\")\nprint(f\"Predicted Answer: {pred.answer}\")\nprint(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")\n\nprint_prompt(lm)\nprint_response(lm)\n\nQuestion: What castle did David Gregory inherit?\nPredicted Answer: Kinnairdy Castle\nRetrieved Contexts (truncated): ['David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinn...', 'Gregory Tarchaneiotes | Gregory Tarchaneiotes (Greek: Γρηγόριος Ταρχανειώτης , Italian: \"Gregorio Tracanioto\" or \"Tracamoto\" ) was a \"protospatharius\" and the long-reigning catepan of Italy from 998 t...', 'David Gregory (mathematician) | David Gregory (originally spelt Gregorie) FRS (? 1659 – 10 October 1708) was a Scottish mathematician and astronomer. He was professor of mathematics at the University ...']\n\n\nAnswers questions with short factoid answers---Question: At My Window was released by which American singer-songwriter?Answer: John Townes Van ZandtQuestion: \"Everything Has Changed\" is a song from an album released under which record label ?Answer: Big Machine RecordsQuestion: The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?Answer: 1950Question: Which Pakistani cricket umpire who won 3 consecutive ICC umpire of the year awards in 2009, 2010, and 2011 will be in the ICC World Twenty20?Answer: Aleem Sarwar DarQuestion: Having the combination of excellent foot speed and bat speed helped Eric Davis, create what kind of outfield for the Los Angeles Dodgers?Answer: \"Outfield of Dreams\"Question: Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?Answer: Aleksandr Danilovich AleksandrovQuestion: The Organisation that allows a community to influence their operation or use and to enjoy the benefits arisingwas founded in what year?Answer: 2010Question: Tombstone stared an actor born May 17, 1955 known as who?Answer: Bill PaxtonQuestion: In what year was the club founded that played Manchester City in the 1972 FA Charity ShieldAnswer: 1874Question: which American actor was Candace Kita guest starred withAnswer: Bill MurrayQuestion: Which is taller, the Empire State Building or the Bank of America Tower?Answer: The Empire State BuildingQuestion: Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?Answer: Buena Vista Distribution---Follow the following format.Context: may contain relevant factsQuestion: ${question}Reasoning: Let's think step by step in order to ${produce the answer}. We ...Answer: often between 1 and 5 words---Context:[1] «Tae Kwon Do Times | Tae Kwon Do Times is a magazine devoted to the martial art of taekwondo, and is published in the United States of America. While the title suggests that it focuses on taekwondo exclusively, the magazine also covers other Korean martial arts. \"Tae Kwon Do Times\" has published articles by a wide range of authors, including He-Young Kimm, Thomas Kurz, Scott Shaw, and Mark Van Schuyver.»[2] «Kwon Tae-man | Kwon Tae-man (born 1941) was an early Korean hapkido practitioner and a pioneer of the art, first in Korea and then in the United States. He formed one of the earliest dojang's for hapkido in the United States in Torrance, California, and has been featured in many magazine articles promoting the art.»[3] «Hee Il Cho | Cho Hee Il (born October 13, 1940) is a prominent Korean-American master of taekwondo, holding the rank of 9th \"dan\" in the martial art. He has written 11 martial art books, produced 70 martial art training videos, and has appeared on more than 70 martial arts magazine covers. Cho won several national and international competitions as a taekwondo competitor, and has appeared in several films, including \"Fight to Win\", \"Best of the Best\", \"Bloodsport II\", and \"Bloodsport III\". He founded the Action International Martial Arts Association (AIMAA) in 1980, and is its President. Cho is a member of both \"Black Belt\" magazine's Hall of Fame and \"Tae Kwon Do Times\" magazine's Hall of Fame.»Question: Which magazine has published articles by Scott Shaw, Tae Kwon Do Times or Southwest Art?Reasoning: Let's think step by step in order to produce the answer. We can look at the context provided, which mentions that \"Tae Kwon Do Times\" has published articles by a wide range of authors, including Scott Shaw. Therefore, the correct answer is:Answer: Tae Kwon Do Times---Context:[1] «Rosario Dawson | Rosario Isabel Dawson (born May 9, 1979) is an American actress, producer, singer, comic book writer, and political activist. She made her film debut in the 1995 teen drama \"Kids\". Her subsequent film roles include \"He Got Game\", \"Men in Black II\", \"25th Hour\", \"Rent\", \"Sin City\", \"Death Proof\", \"Seven Pounds\", \"\", and \"Top Five\". Dawson has also provided voice-over work for Disney and DC.»[2] «Sarai Gonzalez | Sarai Isaura Gonzalez (born 2005) is an American Latina child actress who made her professional debut at the age of 11 on the Spanish-language \"\"Soy Yo\"\" (\"That's Me\") music video by Bomba Estéreo. Cast as a \"nerdy\" tween with a \"sassy\" and \"confident\" attitude, her performance turned her into a \"Latina icon\" for \"female empowerment, identity and self-worth\". She subsequently appeared in two get out the vote videos for Latinos in advance of the 2016 United States elections.»[3] «Gabriela (2001 film) | Gabriela is a 2001 American romance film, starring Seidy Lopez in the title role alongside Jaime Gomez as her admirer Mike. The film has been cited as an inspiration behind the Premiere Weekend Club, which supports Latino film-making.»Question: Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?Reasoning: Let's think step by step in order to produce the answer. We can look at the context provided, which mentions Rosario Dawson, an American actress who made her film debut in the 1995 teen drama \"Kids\".Answer: Rosario Dawson---Context:[1] «Battle of Kursk | The Battle of Kursk was a Second World War engagement between German and Soviet forces on the Eastern Front near Kursk (450 km south-west of Moscow) in the Soviet Union during July and August 1943. The battle began with the launch of the German offensive, Operation Citadel (German: \"Unternehmen Zitadelle\" ), on 5 July, which had the objective of pinching off the Kursk salient with attacks on the base of the salient from north and south simultaneously. After the German offensive stalled on the northern side of the salient, on 12 July the Soviets commenced their Kursk Strategic Offensive Operation with the launch of Operation Kutuzov (Russian: Кутузов ) against the rear of the German forces in the northern side. On the southern side, the Soviets also launched powerful counterattacks the same day, one of which led to a large armoured clash, the Battle of Prokhorovka. On 3 August, the Soviets began the second phase of the Kursk Strategic Offensive Operation with the launch of Operation Polkovodets Rumyantsev (Russian: Полководец Румянцев ) against the German forces in the southern side of the Kursk salient.»[2] «Operation Mars | Operation Mars, also known as the Second Rzhev-Sychevka Offensive Operation (Russian: Вторая Ржевско-Сычёвская наступательная операция), was the codename for an offensive launched by Soviet forces against German forces during World War II. It took place between 25 November and 20 December 1942 around the Rzhev salient in the vicinity of Moscow.»[3] «Kholm Pocket | The Kholm Pocket (German: \"Kessel von Cholm\" ; Russian: Холмский котёл ) was the name given for the encirclement of German troops by the Red Army around Kholm south of Leningrad, during World War II on the Eastern Front, from 23 January 1942 until 5 May 1942. A much larger pocket was simultaneously surrounded in Demyansk, about 100 km to the northeast. These were the results of German retreat following their defeat during the Battle of Moscow.»Question: What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?Reasoning: Let's think step by step in order to produce the answer. We can look at the context provided, which describes the Battle of Kursk. According to the text, the German offensive was launched on 5 July, and it had the objective of pinching off the Kursk salient. The text also mentions that the German offensive was called \"Operation Citadel\" or \"Unternehmen Zitadelle\" in German.Answer: Operation Citadel---Context:[1] «Kerry Condon | Kerry Condon (born 4 January 1983) is an Irish television and film actress, best known for her role as Octavia of the Julii in the HBO/BBC series \"Rome,\" as Stacey Ehrmantraut in AMC's \"Better Call Saul\" and as the voice of F.R.I.D.A.Y. in various films in the Marvel Cinematic Universe. She is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\"»[2] «Corona Riccardo | Corona Riccardo (c. 1878October 15, 1917) was an Italian born American actress who had a brief Broadway stage career before leaving to become a wife and mother. Born in Naples she came to acting in 1894 playing a Mexican girl in a play at the Empire Theatre. Wilson Barrett engaged her for a role in his play \"The Sign of the Cross\" which he took on tour of the United States. Riccardo played the role of Ancaria and later played Berenice in the same play. Robert B. Mantell in 1898 who struck by her beauty also cast her in two Shakespeare plays, \"Romeo and Juliet\" and \"Othello\". Author Lewis Strang writing in 1899 said Riccardo was the most promising actress in America at the time. Towards the end of 1898 Mantell chose her for another Shakespeare part, Ophelia im Hamlet. Afterwards she was due to join Augustin Daly's Theatre Company but Daly died in 1899. In 1899 she gained her biggest fame by playing Iras in the first stage production of Ben-Hur.»[3] «Judi Dench | Dame Judith Olivia \"Judi\" Dench, {'1': \", '2': \", '3': \", '4': \"} (born 9 December 1934) is an English actress and author. Dench made her professional debut in 1957 with the Old Vic Company. Over the following few years, she performed in several of Shakespeare's plays in such roles as Ophelia in \"Hamlet\", Juliet in \"Romeo and Juliet\", and Lady Macbeth in \"Macbeth\". Although most of her work during this period was in theatre, she also branched into film work and won a BAFTA Award as Most Promising Newcomer. She drew strong reviews for her leading role in the musical \"Cabaret\" in 1968.»Question: Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?Reasoning: Let's think step by step in order to find the answer. We can look at the context provided, which mentions three actresses: Kerry Condon, Corona Riccardo, and Judi Dench. Among them, Kerry Condon is the one who is the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\"Answer: Kerry Condon---Context:[1] «David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory's use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.»[2] «Gregory Tarchaneiotes | Gregory Tarchaneiotes (Greek: Γρηγόριος Ταρχανειώτης , Italian: \"Gregorio Tracanioto\" or \"Tracamoto\" ) was a \"protospatharius\" and the long-reigning catepan of Italy from 998 to 1006. In December 999, and again on February 2, 1002, he reinstituted and confirmed the possessions of the abbey and monks of Monte Cassino in Ascoli. In 1004, he fortified and expanded the castle of Dragonara on the Fortore. He gave it three circular towers and one square one. He also strengthened Lucera.»[3] «David Gregory (mathematician) | David Gregory (originally spelt Gregorie) FRS (? 1659 – 10 October 1708) was a Scottish mathematician and astronomer. He was professor of mathematics at the University of Edinburgh, Savilian Professor of Astronomy at the University of Oxford, and a commentator on Isaac Newton's \"Principia\".»Question: What castle did David Gregory inherit?Reasoning: Let's think step by step in order to\n\n\nproduce the answer. We can look at the context provided, which mentions David Gregory, a Scottish physician and inventor. According to the text, he inherited Kinnairdy Castle in 1664.Answer: Kinnairdy Castle\n\n\nTODO: How did the prompt use 12 examples and 6 contexts?\n\n\n\nFrom exploring the harder questions in the training/dev sets, it becomes clear that a single search query is often not enough for this task. For instance, this can be seen when a question ask about, say, the birth city of the writer of “Right Back At It Again”. A search query identifies the author correctly as “Jeremy McKinnon”, but it wouldn’t figure out when he was born.\nThe standard approach for this challenge in the retrieval-augmented NLP literature is to build multi-hop search systems, like GoldEn (Qi et al., 2019) and Baleen (Khattab et al., 2021). These systems read the retrieved results and then generate additional queries to gather additional information if necessary. Using DSPy, we can easily simulate such systems in a few lines of code.\nWe’ll still use the GenerateAnswer signature from the RAG implementation above. All we need now is a signature for the “hop” behavior: taking some partial context and a question, generate a search query to find missing information.\n\nclass GenerateSearchQuery(dspy.Signature):\n    \"\"\"Write a simple search query that will help answer a complex question.\"\"\"\n\n    context = dspy.InputField(desc=\"may contain relevant facts\")\n    question = dspy.InputField()\n    query = dspy.OutputField()\n\nfrom dsp.utils import deduplicate\n\nclass SimplifiedBaleen(dspy.Module):\n    def __init__(self, passages_per_hop=3, max_hops=2):\n        super().__init__()\n\n        self.generate_query = [dspy.ChainOfThought(GenerateSearchQuery) for _ in range(max_hops)]\n        self.retrieve = dspy.Retrieve(k=passages_per_hop)\n        self.generate_answer = dspy.ChainOfThought(GenerateAnswer)\n        self.max_hops = max_hops\n    \n    def forward(self, question):\n        context = []\n        \n        for hop in range(self.max_hops):\n            query = self.generate_query[hop](context=context, question=question).query\n            passages = self.retrieve(query).passages\n            context = deduplicate(context + passages)\n\n        pred = self.generate_answer(context=context, question=question)\n        return dspy.Prediction(context=context, answer=pred.answer)\n\nAs we can see, the __init__ method defines a few key sub-modules:\n\ngenerate_query: For each hop, we will have one dspy.ChainOfThought predictor with the GenerateSearchQuery signature.\nretrieve: This module will do the actual search, using the generated queries.\ngenerate_answer: This dspy.Predict module will be used after all the search steps. It has a GenerateAnswer, to actually produce an answer.\n\nThe forward method uses these sub-modules in simple control flow.\n\nFirst, we’ll loop up to self.max_hops times.\nIn each iteration, we’ll generate a search query using the predictor at self.generate_query[hop].\nWe’ll retrieve the top-k passages using that query.\nWe’ll add the (deduplicated) passages to our accumulator of context.\nAfter the loop, we’ll use self.generate_answer to produce an answer.\nWe’ll return a prediction with the retrieved context and predicted answer.\n\n\n\nWe will also compile this program shortly. But, before that, we can try it out in a “zero-shot” setting (i.e., without any compilation).\nUsing a program in zero-shot (uncompiled) setting doesn’t mean that quality will be bad. It just means that we’re bottlenecked directly by the reliability of the underlying LM to understand our sub-tasks from minimal instructions.\nThis is often just fine when using the most expensive/powerful models (e.g., GPT-4) on the easiest and most standard tasks (e.g., answering simple questions about popular entities).\nHowever, a zero-shot approach quickly falls short for more specialized tasks, for novel domains/settings, and for more efficient (or open) models. DSPy can help you in all of these settings.\n\nmy_question = \"How many storeys are in the castle that David Gregory inherited?\"\n\n# Get the prediction. This contains `pred.context` and `pred.answer`.\nuncompiled_baleen = SimplifiedBaleen()  # uncompiled (i.e., zero-shot) program\npred = uncompiled_baleen(my_question)\n\n# Print the contexts and the answer.\nprint(f\"Question: {my_question}\")\nprint(f\"Predicted Answer: {pred.answer}\")\nprint(f\"Retrieved Contexts (truncated): {[c[:200] + '...' for c in pred.context]}\")\n\nQuestion: How many storeys are in the castle that David Gregory inherited?\nPredicted Answer: Context: David Gregory inherited Kinnairdy Castle in 1664.\n\nQuestion: How many storeys are in the castle that David Gregory inherited?\n\nReasoning: Let's think step by step in order to find the number of storeys in Kinnairdy Castle. We know that David Gregory inherited Kinnairdy Castle, and according to the context, Kinn\nRetrieved Contexts (truncated): ['David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinn...', 'Gregory Tarchaneiotes | Gregory Tarchaneiotes (Greek: Γρηγόριος Ταρχανειώτης , Italian: \"Gregorio Tracanioto\" or \"Tracamoto\" ) was a \"protospatharius\" and the long-reigning catepan of Italy from 998 t...', 'Gregory Parsloe-Parsloe | Sir Gregory Parsloe-Parsloe, 7th Baronet is a fictional character from the Blandings stories of P. G. Wodehouse. The seventh Baronet, who resides at Matchingham Hall, he is t...', 'Kinnairdy Castle | Kinnairdy Castle is a tower house, having five storeys and a garret, two miles south of Aberchirder, Aberdeenshire, Scotland. The alternative name is Old Kinnairdy....', 'Kinnaird Castle, Brechin | Kinnaird Castle is a 15th-century castle in Angus, Scotland. The castle has been home to the Carnegie family, the Earl of Southesk, for more than 600 years....', 'Kinnaird Head | Kinnaird Head (Scottish Gaelic: \"An Ceann Àrd\" , \"high headland\") is a headland projecting into the North Sea, within the town of Fraserburgh, Aberdeenshire on the east coast of Scotla...']\n\n\nLet’s inspect the last three calls to the LM (i.e., generating the first hop’s query, generating the second hop’s query, and generating the answer).\n\nprint_prompt(lm, -3)\nprint_response(lm, -3)\n\nWrite a simple search query that will help answer a complex question.---Follow the following format.Context: may contain relevant factsQuestion: ${question}Reasoning: Let's think step by step in order to ${produce the query}. We ...Query: ${query}---Context:[1] «David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory's use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.»[2] «Gregory Tarchaneiotes | Gregory Tarchaneiotes (Greek: Γρηγόριος Ταρχανειώτης , Italian: \"Gregorio Tracanioto\" or \"Tracamoto\" ) was a \"protospatharius\" and the long-reigning catepan of Italy from 998 to 1006. In December 999, and again on February 2, 1002, he reinstituted and confirmed the possessions of the abbey and monks of Monte Cassino in Ascoli. In 1004, he fortified and expanded the castle of Dragonara on the Fortore. He gave it three circular towers and one square one. He also strengthened Lucera.»[3] «Gregory Parsloe-Parsloe | Sir Gregory Parsloe-Parsloe, 7th Baronet is a fictional character from the Blandings stories of P. G. Wodehouse. The seventh Baronet, who resides at Matchingham Hall, he is the son of the Very Reverend Dean Parsloe-Parsloe and is the rival and enemy of Lord Emsworth, master of Blandings Castle.»Question: How many storeys are in the castle that David Gregory inherited?Reasoning: Let's think step by step in order to\n\n\nHere's the answer:Context: [1] «David Gregory (physician) | ... He inherited Kinnairdy Castle in 1664. ...»Question: How many storeys are in the castle that David Gregory inherited?Reasoning: Let's think step by step in order to find the answer. We need to find information about Kinnairdy Castle, specifically the number of storeys it has. However, the provided context does not mention the number of storeys. We need to search for external information about Kinnairdy Castle.Query: `Kinnairdy Castle architecture` or `Kinnairdy Castle layout`\n\n\n\nprint_prompt(lm, -2)\nprint_response(lm, -2)\n\nAnswers questions with short factoid answers---Follow the following format.Context: may contain relevant factsQuestion: ${question}Reasoning: Let's think step by step in order to ${produce the answer}. We ...Answer: often between 1 and 5 words---Context:[1] «David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory's use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.»[2] «Gregory Tarchaneiotes | Gregory Tarchaneiotes (Greek: Γρηγόριος Ταρχανειώτης , Italian: \"Gregorio Tracanioto\" or \"Tracamoto\" ) was a \"protospatharius\" and the long-reigning catepan of Italy from 998 to 1006. In December 999, and again on February 2, 1002, he reinstituted and confirmed the possessions of the abbey and monks of Monte Cassino in Ascoli. In 1004, he fortified and expanded the castle of Dragonara on the Fortore. He gave it three circular towers and one square one. He also strengthened Lucera.»[3] «Gregory Parsloe-Parsloe | Sir Gregory Parsloe-Parsloe, 7th Baronet is a fictional character from the Blandings stories of P. G. Wodehouse. The seventh Baronet, who resides at Matchingham Hall, he is the son of the Very Reverend Dean Parsloe-Parsloe and is the rival and enemy of Lord Emsworth, master of Blandings Castle.»[4] «Kinnairdy Castle | Kinnairdy Castle is a tower house, having five storeys and a garret, two miles south of Aberchirder, Aberdeenshire, Scotland. The alternative name is Old Kinnairdy.»[5] «Kinnaird Castle, Brechin | Kinnaird Castle is a 15th-century castle in Angus, Scotland. The castle has been home to the Carnegie family, the Earl of Southesk, for more than 600 years.»[6] «Kinnaird Head | Kinnaird Head (Scottish Gaelic: \"An Ceann Àrd\" , \"high headland\") is a headland projecting into the North Sea, within the town of Fraserburgh, Aberdeenshire on the east coast of Scotland. The 16th-century Kinnaird Castle was converted in 1787 for use as the Kinnaird Head Lighthouse, the first lighthouse in Scotland to be lit by the Commissioners of Northern Lights. Kinnaird Castle and the nearby Winetower were described by W. Douglas Simpson as two of the nine castles of the Knuckle, referring to the rocky headland of north-east Aberdeenshire. Both buildings are category A listed buildings.»Question: How many storeys are in the castle that David Gregory inherited?Reasoning: Let's think step by step in order to\n\n\nAnswer: Five\n\n\n\nprint_prompt(lm, -1)\nprint_response(lm, -1)\n\nAnswers questions with short factoid answers---Follow the following format.Context: may contain relevant factsQuestion: ${question}Reasoning: Let's think step by step in order to ${produce the answer}. We ...Answer: often between 1 and 5 words---Context:[1] «David Gregory (physician) | David Gregory (20 December 1625 – 1720) was a Scottish physician and inventor. His surname is sometimes spelt as Gregorie, the original Scottish spelling. He inherited Kinnairdy Castle in 1664. Three of his twenty-nine children became mathematics professors. He is credited with inventing a military cannon that Isaac Newton described as \"being destructive to the human species\". Copies and details of the model no longer exist. Gregory's use of a barometer to predict farming-related weather conditions led him to be accused of witchcraft by Presbyterian ministers from Aberdeen, although he was never convicted.»[2] «Gregory Tarchaneiotes | Gregory Tarchaneiotes (Greek: Γρηγόριος Ταρχανειώτης , Italian: \"Gregorio Tracanioto\" or \"Tracamoto\" ) was a \"protospatharius\" and the long-reigning catepan of Italy from 998 to 1006. In December 999, and again on February 2, 1002, he reinstituted and confirmed the possessions of the abbey and monks of Monte Cassino in Ascoli. In 1004, he fortified and expanded the castle of Dragonara on the Fortore. He gave it three circular towers and one square one. He also strengthened Lucera.»[3] «Gregory Parsloe-Parsloe | Sir Gregory Parsloe-Parsloe, 7th Baronet is a fictional character from the Blandings stories of P. G. Wodehouse. The seventh Baronet, who resides at Matchingham Hall, he is the son of the Very Reverend Dean Parsloe-Parsloe and is the rival and enemy of Lord Emsworth, master of Blandings Castle.»[4] «Kinnairdy Castle | Kinnairdy Castle is a tower house, having five storeys and a garret, two miles south of Aberchirder, Aberdeenshire, Scotland. The alternative name is Old Kinnairdy.»[5] «Kinnaird Castle, Brechin | Kinnaird Castle is a 15th-century castle in Angus, Scotland. The castle has been home to the Carnegie family, the Earl of Southesk, for more than 600 years.»[6] «Kinnaird Head | Kinnaird Head (Scottish Gaelic: \"An Ceann Àrd\" , \"high headland\") is a headland projecting into the North Sea, within the town of Fraserburgh, Aberdeenshire on the east coast of Scotland. The 16th-century Kinnaird Castle was converted in 1787 for use as the Kinnaird Head Lighthouse, the first lighthouse in Scotland to be lit by the Commissioners of Northern Lights. Kinnaird Castle and the nearby Winetower were described by W. Douglas Simpson as two of the nine castles of the Knuckle, referring to the rocky headland of north-east Aberdeenshire. Both buildings are category A listed buildings.»Question: How many storeys are in the castle that David Gregory inherited?Reasoning: Let's think step by step in order to Answer: FiveAnswer:\n\n\nContext: David Gregory inherited Kinnairdy Castle in 1664.Question: How many storeys are in the castle that David Gregory inherited?Reasoning: Let's think step by step in order to find the number of storeys in Kinnairdy Castle. We know that David Gregory inherited Kinnairdy Castle, and according to the context, Kinn\n\n\n\n\n\nNow is the time to compile our multi-hop (SimplifiedBaleen) program.\nWe will first define our validation logic, which will simply require that:\n\nThe predicted answer matches the gold answer.\nThe retrieved context contains the gold answer.\nNone of the generated queries is rambling (i.e., none exceeds 100 characters in length).\nNone of the generated queries is roughly repeated (i.e., none is within 0.8 or higher F1 score of earlier queries).\n\n\ndef validate_context_and_answer_and_hops(example, pred, trace=None):\n    if not dspy.evaluate.answer_exact_match(example, pred): return False\n    if not dspy.evaluate.answer_passage_match(example, pred): return False\n\n    hops = [example.question] + [outputs.query for *_, outputs in trace if 'query' in outputs]\n\n    if max([len(h) for h in hops]) &gt; 100: return False\n    if any(dspy.evaluate.answer_exact_match_str(hops[idx], hops[:idx], frac=0.8) for idx in range(2, len(hops))): return False\n\n    return True\n\n\nlm = dspy.GROQ(api_key=os.getenv('GROQ_API_KEY'), model='llama3-70b-8192')\ndspy.settings.configure(lm=lm, rm=retriever)\n\nteleprompter = BootstrapFewShot(metric=validate_context_and_answer_and_hops)\ncompiled_baleen = teleprompter.compile(SimplifiedBaleen(), teacher=SimplifiedBaleen(passages_per_hop=2), trainset=trainset)\n\n100%|██████████| 20/20 [13:25&lt;00:00, 40.28s/it]\n\n\n\ncompiled_baleen.save('baleen_model.json')\ncompiled_baleen.dump_state()\n\n{'generate_query[0]': {'lm': None,\n  'traces': [],\n  'train': [],\n  'demos': [Example({'augmented': True, 'context': [], 'question': 'Tombstone stared an actor born May 17, 1955 known as who?', 'rationale': \"Here's the completed response:\\n\\nContext: N/A\\n\\nQuestion: Tombstone starred an actor born May 17, 1955 known as who?\\n\\nReasoning: Let's think step by step in order to find the answer. We know the actor's birthdate, May 17, 1955, and the movie they starred in, Tombstone. We can use this information to search for the actor's name.\", 'query': '\"Tombstone movie cast born May 17 1955\"'}) (input_keys=None),\n   Example({'question': 'Which is taller, the Empire State Building or the Bank of America Tower?', 'answer': 'The Empire State Building'}) (input_keys=None),\n   Example({'question': 'Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?', 'answer': 'Rosario Dawson'}) (input_keys=None),\n   Example({'question': 'Samantha Cristoforetti and Mark Shuttleworth are both best known for being first in their field to go where? ', 'answer': 'space'}) (input_keys=None),\n   Example({'question': 'The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?', 'answer': '1950'}) (input_keys=None),\n   Example({'question': 'What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?', 'answer': 'Operation Citadel'}) (input_keys=None),\n   Example({'question': 'Which of these publications was most recently published, Who Put the Bomp or Self?', 'answer': 'Self'}) (input_keys=None),\n   Example({'question': 'Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?', 'answer': 'Buena Vista Distribution'}) (input_keys=None),\n   Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys=None),\n   Example({'question': 'Which Pakistani cricket umpire who won 3 consecutive ICC umpire of the year awards in 2009, 2010, and 2011 will be in the ICC World Twenty20?', 'answer': 'Aleem Sarwar Dar'}) (input_keys=None),\n   Example({'question': 'Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?', 'answer': 'Aleksandr Danilovich Aleksandrov'}) (input_keys=None),\n   Example({'question': 'This American guitarist best known for her work with the Iron Maidens is an ancestor of a composer who was known as what?', 'answer': 'The Waltz King'}) (input_keys=None),\n   Example({'question': 'The Organisation that allows a community to influence their operation or use and to enjoy the benefits arisingwas founded in what year?', 'answer': '2010'}) (input_keys=None),\n   Example({'question': 'On the coast of what ocean is the birthplace of Diogal Sakho?', 'answer': 'Atlantic'}) (input_keys=None),\n   Example({'question': 'which  American actor was Candace Kita  guest starred with ', 'answer': 'Bill Murray'}) (input_keys=None),\n   Example({'question': 'Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?', 'answer': 'Kerry Condon'}) (input_keys=None)],\n  'signature_instructions': 'Write a simple search query that will help answer a complex question.',\n  'signature_prefix': 'Query:',\n  'extended_signature_instructions': 'Write a simple search query that will help answer a complex question.',\n  'extended_signature_prefix': 'Query:'},\n 'generate_query[1]': {'lm': None,\n  'traces': [],\n  'train': [],\n  'demos': [Example({'augmented': True, 'context': ['Wyatt Earp: Return to Tombstone | Wyatt Earp: Return to Tombstone is a 1994 independent film starring Hugh O\\'Brian as Wyatt Earp, featuring new footage mixed with colorized sequences from O\\'Brian\\'s 1955-1961 television series \"The Life and Legend of Wyatt Earp\". The supporting cast for the new footage includes Bruce Boxleitner, Paul Brinegar, Harry Carey, Jr., Bo Hopkins, and Don Meredith. The colorized flashback archival footage from the original television series features Douglas Fowley as Doc Holliday and Lloyd Corrigan as Ned Buntline. The movie was directed by Paul Landres and Frank McDonald.', 'Michael Biehn | Michael Connell Biehn (born July 31, 1956) is an American actor, primarily known for his military roles in science fiction films directed by James Cameron; as Sgt. Kyle Reese in \"The Terminator\" (1984), Cpl. Dwayne Hicks in \"Aliens\" (1986) and Lt. Coffey in \"The Abyss\" (1989). He was nominated for the Saturn Award for Best Actor for \"Aliens.\" His other films include \"The Fan\" (1981), \"K2\" (1991), \"Tombstone\" (1993), \"The Rock\" (1996), \"\" (2001) and \"Planet Terror\" (2007). On television, he has appeared in \"Hill Street Blues\" (1984) and \"Adventure Inc.\" (2002-03).'], 'question': 'Tombstone stared an actor born May 17, 1955 known as who?', 'rationale': 'Here is the answer:\\n\\nContext: [1] and [2] provide information about two different movies, \"Wyatt Earp: Return to Tombstone\" and \"Tombstone\", as well as an actor, Michael Biehn.\\n\\nQuestion: Tombstone stared an actor born May 17, 1955 known as who?\\n\\nReasoning: Let\\'s think step by step in order to find the answer. We know that the question is asking about the movie \"Tombstone\", and we want to find the actor born on May 17, 1955 who starred in it.', 'query': '`Tombstone movie 1993 cast born May 17, 1955`\\n\\nThis query should return the answer: Val Kil'}) (input_keys=None),\n   Example({'question': 'Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?', 'answer': 'Aleksandr Danilovich Aleksandrov'}) (input_keys=None),\n   Example({'question': 'On the coast of what ocean is the birthplace of Diogal Sakho?', 'answer': 'Atlantic'}) (input_keys=None),\n   Example({'question': 'What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?', 'answer': 'Operation Citadel'}) (input_keys=None),\n   Example({'question': 'Which Pakistani cricket umpire who won 3 consecutive ICC umpire of the year awards in 2009, 2010, and 2011 will be in the ICC World Twenty20?', 'answer': 'Aleem Sarwar Dar'}) (input_keys=None),\n   Example({'question': 'Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?', 'answer': 'Kerry Condon'}) (input_keys=None),\n   Example({'question': 'Samantha Cristoforetti and Mark Shuttleworth are both best known for being first in their field to go where? ', 'answer': 'space'}) (input_keys=None),\n   Example({'question': 'which  American actor was Candace Kita  guest starred with ', 'answer': 'Bill Murray'}) (input_keys=None),\n   Example({'question': 'Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?', 'answer': 'Rosario Dawson'}) (input_keys=None),\n   Example({'question': 'Which of these publications was most recently published, Who Put the Bomp or Self?', 'answer': 'Self'}) (input_keys=None),\n   Example({'question': 'Which is taller, the Empire State Building or the Bank of America Tower?', 'answer': 'The Empire State Building'}) (input_keys=None),\n   Example({'question': 'This American guitarist best known for her work with the Iron Maidens is an ancestor of a composer who was known as what?', 'answer': 'The Waltz King'}) (input_keys=None),\n   Example({'question': 'The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?', 'answer': '1950'}) (input_keys=None),\n   Example({'question': 'The Organisation that allows a community to influence their operation or use and to enjoy the benefits arisingwas founded in what year?', 'answer': '2010'}) (input_keys=None),\n   Example({'question': 'Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?', 'answer': 'Buena Vista Distribution'}) (input_keys=None),\n   Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys=None)],\n  'signature_instructions': 'Write a simple search query that will help answer a complex question.',\n  'signature_prefix': 'Query:',\n  'extended_signature_instructions': 'Write a simple search query that will help answer a complex question.',\n  'extended_signature_prefix': 'Query:'},\n 'retrieve': {'k': 3},\n 'generate_answer': {'lm': None,\n  'traces': [],\n  'train': [],\n  'demos': [Example({'augmented': True, 'context': ['Wyatt Earp: Return to Tombstone | Wyatt Earp: Return to Tombstone is a 1994 independent film starring Hugh O\\'Brian as Wyatt Earp, featuring new footage mixed with colorized sequences from O\\'Brian\\'s 1955-1961 television series \"The Life and Legend of Wyatt Earp\". The supporting cast for the new footage includes Bruce Boxleitner, Paul Brinegar, Harry Carey, Jr., Bo Hopkins, and Don Meredith. The colorized flashback archival footage from the original television series features Douglas Fowley as Doc Holliday and Lloyd Corrigan as Ned Buntline. The movie was directed by Paul Landres and Frank McDonald.', 'Michael Biehn | Michael Connell Biehn (born July 31, 1956) is an American actor, primarily known for his military roles in science fiction films directed by James Cameron; as Sgt. Kyle Reese in \"The Terminator\" (1984), Cpl. Dwayne Hicks in \"Aliens\" (1986) and Lt. Coffey in \"The Abyss\" (1989). He was nominated for the Saturn Award for Best Actor for \"Aliens.\" His other films include \"The Fan\" (1981), \"K2\" (1991), \"Tombstone\" (1993), \"The Rock\" (1996), \"\" (2001) and \"Planet Terror\" (2007). On television, he has appeared in \"Hill Street Blues\" (1984) and \"Adventure Inc.\" (2002-03).', 'Tombstone (film) | Tombstone is a 1993 American Western film directed by George P. Cosmatos, written by Kevin Jarre (who was also the original director, but was replaced early in production), and starring Kurt Russell and Val Kilmer, with Sam Elliott, Bill Paxton, Powers Boothe, Michael Biehn, and Dana Delany in supporting roles, as well as narration by Robert Mitchum.'], 'question': 'Tombstone stared an actor born May 17, 1955 known as who?', 'rationale': \"Reasoning: Let's think step by step in order to find the answer. We know that the question is asking about an actor born on May 17, 1955, who starred in the movie Tombstone. From the context, we can see that the movie Tombstone (1993) starred Kurt Russell and Val Kilmer, among others. However, none of them were born on May 17, 1955. But, we can see that Michael Biehn was also in the movie, and according to his bio, he was born on July 31, 1956, which doesn't match the birthdate we're looking for. So, we need to look further.\", 'answer': 'Bill Paxton'}) (input_keys=None),\n   Example({'question': 'which  American actor was Candace Kita  guest starred with ', 'answer': 'Bill Murray'}) (input_keys=None),\n   Example({'question': 'Samantha Cristoforetti and Mark Shuttleworth are both best known for being first in their field to go where? ', 'answer': 'space'}) (input_keys=None),\n   Example({'question': 'Which is taller, the Empire State Building or the Bank of America Tower?', 'answer': 'The Empire State Building'}) (input_keys=None),\n   Example({'question': 'This American guitarist best known for her work with the Iron Maidens is an ancestor of a composer who was known as what?', 'answer': 'The Waltz King'}) (input_keys=None),\n   Example({'question': 'Which Pakistani cricket umpire who won 3 consecutive ICC umpire of the year awards in 2009, 2010, and 2011 will be in the ICC World Twenty20?', 'answer': 'Aleem Sarwar Dar'}) (input_keys=None),\n   Example({'question': 'Which of these publications was most recently published, Who Put the Bomp or Self?', 'answer': 'Self'}) (input_keys=None),\n   Example({'question': 'Which American actress who made their film debut in the 1995 teen drama \"Kids\" was the co-founder of Voto Latino?', 'answer': 'Rosario Dawson'}) (input_keys=None),\n   Example({'question': 'The Organisation that allows a community to influence their operation or use and to enjoy the benefits arisingwas founded in what year?', 'answer': '2010'}) (input_keys=None),\n   Example({'question': 'At My Window was released by which American singer-songwriter?', 'answer': 'John Townes Van Zandt'}) (input_keys=None),\n   Example({'question': 'Who acted in the shot film The Shore and is also the youngest actress ever to play Ophelia in a Royal Shakespeare Company production of \"Hamlet.\" ?', 'answer': 'Kerry Condon'}) (input_keys=None),\n   Example({'question': 'What is the code name for the German offensive that started this Second World War engagement on the Eastern Front (a few hundred kilometers from Moscow) between Soviet and German forces, which included 102nd Infantry Division?', 'answer': 'Operation Citadel'}) (input_keys=None),\n   Example({'question': 'Who is older, Aleksandr Danilovich Aleksandrov or Anatoly Fomenko?', 'answer': 'Aleksandr Danilovich Aleksandrov'}) (input_keys=None),\n   Example({'question': 'Which company distributed this 1977 American animated film produced by Walt Disney Productions for which Sherman Brothers wrote songs?', 'answer': 'Buena Vista Distribution'}) (input_keys=None),\n   Example({'question': 'The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?', 'answer': '1950'}) (input_keys=None),\n   Example({'question': 'On the coast of what ocean is the birthplace of Diogal Sakho?', 'answer': 'Atlantic'}) (input_keys=None)],\n  'signature_instructions': 'Answers questions with short factoid answers',\n  'signature_prefix': 'Answer:',\n  'extended_signature_instructions': 'Answers questions with short factoid answers',\n  'extended_signature_prefix': 'Answer:'}}\n\n\n\nfrom dspy.evaluate.evaluate import Evaluate\n\n# Set up the `evaluate_on_hotpotqa` function. We'll use this many times below.\nevaluate_on_hotpotqa = Evaluate(devset=devset, num_threads=1, display_progress=True, display_table=5)\n\ndef gold_passages_retrieved(example, pred, trace=None):\n    gold_titles = set(map(dspy.evaluate.normalize_text, example['gold_titles']))\n    found_titles = set(map(dspy.evaluate.normalize_text, [c.split(' | ')[0] for c in pred.context]))\n\n    return gold_titles.issubset(found_titles)\n\ncompiled_rag_retrieval_score = evaluate_on_hotpotqa(compiled_rag, metric=gold_passages_retrieved)\n\n\n# Evaluate the `compiled_rag` program with the `answer_exact_match` metric.\nmetric = dspy.evaluate.answer_exact_match\nevaluate_on_hotpotqa(compiled_rag, metric=metric)"
  },
  {
    "objectID": "posts/2021-11-11-linear-algebra-svd.html",
    "href": "posts/2021-11-11-linear-algebra-svd.html",
    "title": "Fastai Linear Algebra - chapter 1",
    "section": "",
    "text": "# !pip install imageio-ffmpeg moviepy imageio\n\nimport imageio\nimport moviepy.editor as mpe\nimport numpy as np\nimport scipy\nfrom pathlib import Path\nfrom PIL import Image\n\n%matplotlib inline\nimport matplotlib.pyplot as plt\n \nnp.set_printoptions(precision=4, suppress=True)\n\n\n# download video from https://github.com/momonala/image-processing-projects/blob/master/background_removal/video/Video_003/Video_003.avi\n!curl -o Video_003.avi https://raw.githubusercontent.com/momonala/image-processing-projects/master/background_removal/video/Video_003/Video_003.avi\n\n  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n                                 Dload  Upload   Total   Spent    Left  Speed\n100 1241k  100 1241k    0     0  3505k      0 --:--:-- --:--:-- --:--:-- 3495k\n\n\n\nvideo = mpe.VideoFileClip(\"Video_003.avi\")\nprint(f'fps - {video.fps} and duration is {video.duration}')\n\nfps - 7.0 and duration is 113.57\n\n\n\nclip = video.subclip(0, 50).ipython_display(width=300)\nclip\n\nMoviepy - Building video __temp__.mp4.\nMoviepy - Writing video __temp__.mp4\n\n\n\n                                                                \n\n\nMoviepy - Done !\nMoviepy - video ready __temp__.mp4\n\n\nSorry, seems like your browser doesn't support HTML5 audio/video\n\n\n\nHelper Methods\n\ndef resize(img_array, dims):\n    return np.array(Image.fromarray(img_array).resize(size=dims))\n\n\n\ndef rgb2gray(rgb):\n    # return np.dot(rgb[...,:3], [0.299, 0.587, 0.114])\n    return np.dot(rgb[...,:3], [0.2989, 0.5870, 0.1140])\n\n\n\nFormat the Data\nAn image from 1 moment in time is 120 pixels by 160 pixels (when scaled). We can unroll that picture into a single tall column. So instead of having a 2D picture that is 120×160, we have a 1×19,200 column\nThis isn’t very human-readable, but it’s handy because it lets us stack the images from different times on top of one another, to put a video all into 1 matrix. If we took the video image every hundredth of a second for 100 seconds (so 10,000 different images, each from a different point in time), we’d have a 10,000×19,200 matrix, representing the video!\n\nscale = 0.5 # adjust scale to change resolution of image\ndims = (int(240 * scale), int(320 * scale))\nprint(f'dims - {dims}')\nfps = video.fps\nfps\n\ndims - (120, 160)\n\n\n7.0\n\n\n\nclip = video.subclip(0, 1000)\nframe = clip.get_frame(100/fps)\n# frame[..., :3]\ngray = rgb2gray(frame)\ngray.shape\nresized = resize(gray, dims)\nprint(resized.shape)\n\n(160, 120)\n\n\n\n%%time\ndef create_data_matrix_from_video(clip, fps=5, scale=0.5):\n    # get dimension of each frame\n    dims = clip.get_frame(0).shape[:2]\n    \n    # get scaled dimensions\n    dims = [int(o*scale) for o in dims]\n    print(dims)\n    return np.vstack([resize(rgb2gray(clip.get_frame(i/float(fps))), dims).astype(int).flatten() for i in range(int(fps) * int(clip.duration))]).T\n\nM = create_data_matrix_from_video(video.subclip(0,100), fps, scale)\nprint(M.shape, M.dtype)\n\n[120, 160]\n(19200, 700) int64\nCPU times: user 2.21 s, sys: 163 ms, total: 2.38 s\nWall time: 2.86 s\n\n\n\n\nSVD\nSVD for a matrix A is given by\n\\[\nA_{(m,n)} = U_{(m,m)}{\\cdot}Sigma_{(m,n)}{\\cdot}V^T_{(n,n)}\n\\]\n\nU is called left singular matrix\nSigma is called sing\n\nSigma is a diagonal matrix. Lets check with an example\n\nfrom scipy.linalg import svd\nfrom typing import Tuple\n\ndef compute_svd(shape: Tuple, full_matrices=True):\n    A = np.random.randn(*shape)\n    U, s, VT = svd(A, full_matrices=full_matrices)\n    print(f'{A.shape} Matrix with full_matrices {full_matrices}, decomposes into', U.shape, s.shape, VT.shape)\n    return U, s, VT\n\ndef reconstruct(U, s, VT):\n    m = U.shape[0]\n    n = VT.shape[0]\n    \n    sigma = np.zeros((m,n))\n    if m &gt; n:\n        sigma[:n, :] = np.diag(s) \n    else: \n        sigma[:, :m] = np.diag(s)\n    return np.linalg.multi_dot([U, sigma, VT])\n        \n    \n\n_, _, _ = compute_svd((2,3), full_matrices=True)\n_, _, _ = compute_svd((3,2), full_matrices=True)\n\n\n_, _, _ = compute_svd((3,10), full_matrices=True)\n_, _, _ = compute_svd((3,10), full_matrices=False)\n\n(2, 3) Matrix with full_matrices True, decomposes into (2, 2) (2,) (3, 3)\n(3, 2) Matrix with full_matrices True, decomposes into (3, 3) (2,) (2, 2)\n(3, 10) Matrix with full_matrices True, decomposes into (3, 3) (3,) (10, 10)\n(3, 10) Matrix with full_matrices False, decomposes into (3, 3) (3,) (3, 10)\n\n\n\nCheck that we are able to reconstruct the matrix\n\nA = np.random.randn(4, 3)\nU, s, VT = svd(A, full_matrices=full_matrices)\nA_recons = reconstruct(U, s, VT)\nnp.allclose(A, A_recons)\n\nTrue\n\n\n\n\nPseudoinverse\n\nMatrix inversion is not defined for matrices that are not square. […] When A has more columns than rows, then solving a linear equation using the pseudoinverse provides one of the many possible solutions.\n\n\n%%time\nU, s, V = np.linalg.svd(M, full_matrices=False)\nprint(M.shape, U.shape, s.shape, V.shape)\n\n(3, 2) (3, 2) (2,) (2, 2)\nCPU times: user 358 µs, sys: 468 µs, total: 826 µs\nWall time: 810 µs\n\n\n\n%%time\nfrom scipy.linalg import svd\nU, s, VT = svd(M)\nprint(M.shape, U.shape, s.shape, VT.shape)\n\n(19200, 700) (19200, 19200) (700,) (700, 700)\nCPU times: user 2min 6s, sys: 2.86 s, total: 2min 8s\nWall time: 1min 11s\n\n\n\nM = np.random.randn(3,2)\nU, s, VT = svd(M)\nprint(M.shape, U.shape, s.shape, VT.shape)\n\n(3, 2) (3, 3) (2,) (2, 2)"
  },
  {
    "objectID": "posts/2022-06-26-quantile-plot.html",
    "href": "posts/2022-06-26-quantile-plot.html",
    "title": "notes",
    "section": "",
    "text": "We will try to understand a quantile plot.\nLets us generate n numbers from a uniform distribution. We will then compare those numbers with uniform and normal distribution\n\nimport numpy as np\nimport seaborn as sns\n\n\nn = 9\na = np.sort(np.random.uniform(1, 10, size=n))\na\n\narray([1.14572246, 4.51022338, 5.33175385, 5.82544947, 7.14328162,\n       8.45844914, 8.84241316, 9.01455406, 9.84060727])\n\n\n\nquantiles = [k/(n+1) for k in range(1, n+1)]\nquantiles \n\n[0.1, 0.2, 0.3, 0.4, 0.5, 0.6, 0.7, 0.8, 0.9]\n\n\nIf we take the quntiles of a, they will be equally spaced. Now lets divide the area under the target distribution with which we are comparing and read the corresponding values of the random variable.\nIf the array values and the corresponding values from the distribtution are proportional (ie, straight we have a straight line in a plot), then the array is close to the distribution\n\nfrom scipy.stats import norm, uniform\n\n\ndist = norm()\ndist_vals = dist.ppf(quantiles)\nprint(dist_vals)\nax = sns.scatterplot(x=a,y=dist_vals)\nax.set_title('compare with normal dist')\n\n[-1.28155157 -0.84162123 -0.52440051 -0.2533471   0.          0.2533471\n  0.52440051  0.84162123  1.28155157]\n\n\nText(0.5, 1.0, 'compare with normal dist')\n\n\n\n\n\n\n\n\n\n\ndist = uniform()\ndist_vals = dist.ppf(quantiles)\nprint(dist_vals)\nax = sns.scatterplot(x=a,y=dist_vals)\nax.set_title('compare with uniform dist')\n\n[0.1 0.2 0.3 0.4 0.5 0.6 0.7 0.8 0.9]\n\n\nText(0.5, 1.0, 'compare with uniform dist')"
  },
  {
    "objectID": "posts/2022-03-07-product-recomendation.html",
    "href": "posts/2022-03-07-product-recomendation.html",
    "title": "Satender Product Recommendation",
    "section": "",
    "text": "# Download the data\n#!kaggle competitions download -c santander-product-recommendation\n#!mv santander-product-recommendation.zip data/\n# !cd data;unzip santander-product-recommendation.zip;unzip train_ver2.csv.zip;unzip test_ver2.csv.zip\n!ls -lrth data\n\ntotal 2.7G\n-rw-r--r-- 1 achinta achinta 106M Oct 27  2016 test_ver2.csv\n-rwxrwxrwx 1 achinta achinta 2.2G Oct 27  2016 train_ver2.csv\n-rw-rw-r-- 1 achinta achinta  13M Dec 11  2019 test_ver2.csv.zip\n-rw-rw-r-- 1 achinta achinta 2.3M Dec 11  2019 sample_submission.csv.zip\n-rw-rw-r-- 1 achinta achinta 215M Dec 11  2019 train_ver2.csv.zip\n-rw-rw-r-- 1 achinta achinta 229M Mar  7 10:30 santander-product-recommendation.zip\n\n\n\n! wc -l data/train_ver2.csv\n\n13647310 data/train_ver2.csv\n\n\nSo we have 13.6M rows in the training dataset\n\nSVD\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.linalg import sqrtm\nfrom copy import deepcopy\n\n\ntrain_10k = pd.read_csv('data/train_ver2.csv', nrows=10000)\nprint(f'columns- {train_10k.columns}')\n\ncolumns- Index(['fecha_dato', 'ncodpers', 'ind_empleado', 'pais_residencia', 'sexo',\n       'age', 'fecha_alta', 'ind_nuevo', 'antiguedad', 'indrel',\n       'ult_fec_cli_1t', 'indrel_1mes', 'tiprel_1mes', 'indresi', 'indext',\n       'conyuemp', 'canal_entrada', 'indfall', 'tipodom', 'cod_prov',\n       'nomprov', 'ind_actividad_cliente', 'renta', 'segmento',\n       'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1',\n       'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1',\n       'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1',\n       'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1',\n       'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1',\n       'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1'],\n      dtype='object')\n\n\nHere are the columns we will be using in the SVD approach. We are ignoring the categorical features. (I am not sure if they can be used in SVD)\n\n\n\nColumn\nDescription\n\n\n\n\nfetcha_dato\nMonth of Purchase\n\n\nnocdepers\nCustmomer Code\n\n\nind__(xyz)__ult1\nProducts on which we have to predict sales upon\n\n\n\n\n\n\n\n\n\n\n\n\n%%time\ntrain_dates = pd.read_csv(f'data/train_ver2.csv', usecols=['fecha_dato'])\ntest_dates = pd.read_csv(f'data/test_ver2.csv', usecols=['fecha_dato'])\nprint(f'train data has {train_dates.shape[0]/1e6}M rows')\nprint(f'test  data has {test_dates.shape[0]/1e3}K rows')\n\nprint(f'train months {sorted(train_dates.fecha_dato.unique())}')\nprint(f'test months {sorted(test_dates.fecha_dato.unique())}')\n\ntrain data has 13.647309M rows\ntest  data has 929.615K rows\ntrain months ['2015-01-28', '2015-02-28', '2015-03-28', '2015-04-28', '2015-05-28', '2015-06-28', '2015-07-28', '2015-08-28', '2015-09-28', '2015-10-28', '2015-11-28', '2015-12-28', '2016-01-28', '2016-02-28', '2016-03-28', '2016-04-28', '2016-05-28']\ntest months ['2016-06-28']\nCPU times: user 11.6 s, sys: 676 ms, total: 12.3 s\nWall time: 12.3 s\n\n\n\ntrain_10k.head(2)\n\n\n\n\n\n\n\n\nfecha_dato\nncodpers\nind_empleado\npais_residencia\nsexo\nage\nfecha_alta\nind_nuevo\nantiguedad\nindrel\n...\nind_hip_fin_ult1\nind_plan_fin_ult1\nind_pres_fin_ult1\nind_reca_fin_ult1\nind_tjcr_fin_ult1\nind_valo_fin_ult1\nind_viv_fin_ult1\nind_nomina_ult1\nind_nom_pens_ult1\nind_recibo_ult1\n\n\n\n\n0\n2015-01-28\n1375586\nN\nES\nH\n35\n2015-01-12\n0.0\n6\n1.0\n...\n0\n0\n0\n0\n0\n0\n0\n0.0\n0.0\n0\n\n\n1\n2015-01-28\n1050611\nN\nES\nV\n23\n2012-08-10\n0.0\n35\n1.0\n...\n0\n0\n0\n0\n0\n0\n0\n0.0\n0.0\n0\n\n\n\n\n2 rows × 48 columns\n\n\n\n\nsvd_cols = ['fecha_dato', 'ncodpers', 'ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1','ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1',\n       'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1','ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1','ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1',\n       'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1','ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1','ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n\n\n%%time\ntrain = pd.read_csv('data/train_ver2.csv', usecols=svd_cols)\nprint(f'train.shape - {train.shape}')\n\n\n%%time\n\n#read one month of data\ntrain1 = train[train.fecha_dato == '2015-01-28'].drop('fecha_dato', axis=1).copy()\nprint(f'train1.shape - {train1.shape} and true.shape - {true.shape}')\n\ntrain1.shape - (625457, 25) and true.shape - (625457, 25)\nCPU times: user 695 ms, sys: 163 ms, total: 858 ms\nWall time: 851 ms\n\n\n\nusers = true['ncodpers'].tolist()\ntrue.drop('ncodpers', axis=1, inplace=True)\n\nitems = true.columns.tolist()\nprint(items)\n\nu = {}\nfor i in range(len(users)):\n    u[users[i]] = i\n\n['ind_ahor_fin_ult1', 'ind_aval_fin_ult1', 'ind_cco_fin_ult1', 'ind_cder_fin_ult1', 'ind_cno_fin_ult1', 'ind_ctju_fin_ult1', 'ind_ctma_fin_ult1', 'ind_ctop_fin_ult1', 'ind_ctpp_fin_ult1', 'ind_deco_fin_ult1', 'ind_deme_fin_ult1', 'ind_dela_fin_ult1', 'ind_ecue_fin_ult1', 'ind_fond_fin_ult1', 'ind_hip_fin_ult1', 'ind_plan_fin_ult1', 'ind_pres_fin_ult1', 'ind_reca_fin_ult1', 'ind_tjcr_fin_ult1', 'ind_valo_fin_ult1', 'ind_viv_fin_ult1', 'ind_nomina_ult1', 'ind_nom_pens_ult1', 'ind_recibo_ult1']\n\n\n\ntrueMat = np.array(true)\n\n\nusers = train['ncodpers'].tolist()\nprint(len(users))\nu = {}\n\n13647309\n\n\n\nfor i in range(len(users)):\n    u[users[i]] = i\n\n\ntrain1.index = train1['ncodpers'].tolist()\ntrain1.drop('ncodpers', axis=1, inplace=True)\ntrain1.head()\n\n\n\n\n\n\n\n\nind_ahor_fin_ult1\nind_aval_fin_ult1\nind_cco_fin_ult1\nind_cder_fin_ult1\nind_cno_fin_ult1\nind_ctju_fin_ult1\nind_ctma_fin_ult1\nind_ctop_fin_ult1\nind_ctpp_fin_ult1\nind_deco_fin_ult1\n...\nind_hip_fin_ult1\nind_plan_fin_ult1\nind_pres_fin_ult1\nind_reca_fin_ult1\nind_tjcr_fin_ult1\nind_valo_fin_ult1\nind_viv_fin_ult1\nind_nomina_ult1\nind_nom_pens_ult1\nind_recibo_ult1\n\n\n\n\n1375586\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0.0\n0.0\n0\n\n\n1050611\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0.0\n0.0\n0\n\n\n1050612\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0.0\n0.0\n0\n\n\n1050613\n0\n0\n0\n0\n0\n0\n0\n0\n0\n1\n...\n0\n0\n0\n0\n0\n0\n0\n0.0\n0.0\n0\n\n\n1050614\n0\n0\n1\n0\n0\n0\n0\n0\n0\n0\n...\n0\n0\n0\n0\n0\n0\n0\n0.0\n0.0\n0\n\n\n\n\n5 rows × 24 columns\n\n\n\n\n%%time\ntrain1 = train1.reindex(users)\nprint(f'train1.shape{train1.shape}')\ntrain1.head(3)\n\ntrain1.shape(13647309, 24)\nCPU times: user 2.87 s, sys: 6.77 s, total: 9.64 s\nWall time: 9.83 s\n\n\n\n\n\n\n\n\n\nind_ahor_fin_ult1\nind_aval_fin_ult1\nind_cco_fin_ult1\nind_cder_fin_ult1\nind_cno_fin_ult1\nind_ctju_fin_ult1\nind_ctma_fin_ult1\nind_ctop_fin_ult1\nind_ctpp_fin_ult1\nind_deco_fin_ult1\n...\nind_hip_fin_ult1\nind_plan_fin_ult1\nind_pres_fin_ult1\nind_reca_fin_ult1\nind_tjcr_fin_ult1\nind_valo_fin_ult1\nind_viv_fin_ult1\nind_nomina_ult1\nind_nom_pens_ult1\nind_recibo_ult1\n\n\n\n\n1375586\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1050611\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n1050612\n0.0\n0.0\n1.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n...\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n0.0\n\n\n\n\n3 rows × 24 columns\n\n\n\n\n\nsvd\n\n%%time\nutilMat = np.array(train1)\nmask = np.isnan(utilMat)\nmask_zero = \n\nCPU times: user 1.37 s, sys: 11.2 s, total: 12.5 s\nWall time: 12.7 s\n\n\n\nnp.where(utilMat)\n\n(array([       0,        1,        2, ..., 13647308, 13647308, 13647308]),\n array([ 2,  2,  2, ..., 21, 22, 23]))\n\n\n\nprint(np.sum(mask))\nprint(utilMat.shape[0] * utilMat.shape[1])\n\n75917862\n327535416\n\n\n\n%%time\nmasked_arr=np.ma.masked_array(utilMat, mask)\nitem_means=np.mean(masked_arr, axis=0)\nprint(f'masked_arr.shape - {masked_arr.shape}')\nprint(f'item_means.shape - {item_means.shape}')\n\nmasked_arr.shape - (13647309, 24)\nitem_means.shape - (24,)\nCPU times: user 2.36 s, sys: 9.37 s, total: 11.7 s\nWall time: 11.9 s\n\n\n\nprint(item_means)\n\n[0.00014086538076379747 3.0805360857621244e-05 0.7842677689708568\n 0.00048544670825167844 0.09478923983051138 0.01233997902565028\n 0.013272341897923052 0.17154113021149453 0.058354032374049944\n 0.0022137895858424282 0.002612161079038354 0.057973781681358506\n 0.0969037465041161 0.02239120557495011 0.00805860610224633\n 0.012010752692274092 0.0034949301815093824 0.060178987730119864\n 0.05746153526288704 0.0327036577694172 0.005214594149384828\n 0.0630621993029027 0.07005819202959135 0.1539579452461892]\n\n\n\nmasked_arr\n\nmasked_array(\n  data=[[0.0, 0.0, 1.0, ..., 0.0, 0.0, 0.0],\n        [0.0, 0.0, 1.0, ..., 0.0, 0.0, 0.0],\n        [0.0, 0.0, 1.0, ..., 0.0, 0.0, 0.0],\n        ...,\n        [0.0, 0.0, 1.0, ..., 0.0, 0.0, 0.0],\n        [0.0, 0.0, 1.0, ..., 0.0, 0.0, 0.0],\n        [--, --, --, ..., --, --, --]],\n  mask=[[False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        ...,\n        [False, False, False, ..., False, False, False],\n        [False, False, False, ..., False, False, False],\n        [ True,  True,  True, ...,  True,  True,  True]],\n  fill_value=1e+20)\n\n\n\n%%time\nutilMat2 = masked_arr.filled(item_means)\nprint(f'utilMat2.shape - {utilMat2.shape}')\n\nutilMat2.shape - (13647309, 24)\nCPU times: user 1.73 s, sys: 7.63 s, total: 9.36 s\nWall time: 9.89 s\n\n\n\nutilMat2\n\narray([[0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       ...,\n       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [0.00000000e+00, 0.00000000e+00, 1.00000000e+00, ...,\n        0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n       [1.40865381e-04, 3.08053609e-05, 7.84267769e-01, ...,\n        6.30621993e-02, 7.00581920e-02, 1.53957945e-01]])\n\n\n\n%%time\nx = np.tile(item_means, (utilMat2.shape[0],1))\nprint(f'x.shape - {x.shape}')\n\nx.shape - (13647309, 24)\nCPU times: user 452 ms, sys: 5.99 s, total: 6.44 s\nWall time: 7.17 s\n\n\n\na = np.array([[1,0],[2,3]])\na\n\narray([[1, 0],\n       [2, 3]])\n\n\n\nmask = np.isnan(a)\nmask\n\narray([[False, False],\n       [False, False]])"
  }
]